<?xml version="1.0" ?>
<SmellBaseline>
  <Blacklist></Blacklist>
  <Whitelist>
    <ID>ComplexCondition:CordaClassResolver.kt$CordaClassResolver$type.isPrimitive || type == Any::class.java || type == String::class.java || (!type.isEnum &amp;&amp; isAbstract(type.modifiers))</ID>
    <ID>ComplexCondition:FlowMessaging.kt$FlowMessagingImpl$(exception is KryoException || exception is NotSerializableException) &amp;&amp; message is ExistingSessionMessage &amp;&amp; message.payload is ErrorSessionMessage</ID>
    <ID>ComplexCondition:TopLevelTransition.kt$TopLevelTransition$currentState.isTransactionTracked &amp;&amp; checkpoint.flowState is FlowState.Started &amp;&amp; checkpoint.flowState.flowIORequest is FlowIORequest.WaitForLedgerCommit &amp;&amp; checkpoint.flowState.flowIORequest.hash == event.transaction.id</ID>
    <ID>ComplexMethod:AbstractNode.kt$AbstractNode$private fun installCordaServices()</ID>
    <ID>ComplexMethod:ActionExecutorImpl.kt$ActionExecutorImpl$@Suspendable override fun executeAction(fiber: FlowFiber, action: Action)</ID>
    <ID>ComplexMethod:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase$private fun set(key: K, value: V, logWarning: Boolean, store: (K, V) -&gt; V?): Boolean</ID>
    <ID>ComplexMethod:CheckpointDumper.kt$CheckpointDumper$fun dump()</ID>
    <ID>ComplexMethod:CheckpointDumper.kt$CheckpointDumper$private fun FlowIORequest&lt;*&gt;.toSuspendedOn(suspendedTimestamp: Instant, now: Instant): SuspendedOn</ID>
    <ID>ComplexMethod:ConfigUtilities.kt$// TODO Move this to KeyStoreConfigHelpers. fun MutualSslConfiguration.configureDevKeyAndTrustStores(myLegalName: CordaX500Name, signingCertificateStore: FileBasedCertificateStoreSupplier, certificatesDirectory: Path, cryptoService: CryptoService? = null)</ID>
    <ID>ComplexMethod:FlowMonitor.kt$FlowMonitor$private fun warningMessageForFlowWaitingOnIo(request: FlowIORequest&lt;*&gt;, flow: FlowStateMachineImpl&lt;*&gt;, now: Instant): String</ID>
    <ID>ComplexMethod:FlowStateMachineImpl.kt$FlowStateMachineImpl$ @Suspendable private fun processEventsUntilFlowIsResumed(isDbTransactionOpenOnEntry: Boolean, isDbTransactionOpenOnExit: Boolean): Any?</ID>
    <ID>ComplexMethod:GenerateRpcSslCertsCli.kt$GenerateRpcSslCerts$private fun generateRpcSslCertificates(conf: NodeConfiguration)</ID>
    <ID>ComplexMethod:HTTPNetworkRegistrationService.kt$HTTPNetworkRegistrationService$@Throws(CertificateRequestException::class) override fun retrieveCertificates(requestId: String): CertificateResponse</ID>
    <ID>ComplexMethod:HibernateQueryCriteriaParser.kt$HibernateAttachmentQueryCriteriaParser$override fun parseCriteria(criteria: AttachmentQueryCriteria.AttachmentsQueryCriteria): Collection&lt;Predicate&gt;</ID>
    <ID>ComplexMethod:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$override fun parseCriteria(criteria: CommonQueryCriteria): Collection&lt;Predicate&gt;</ID>
    <ID>ComplexMethod:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$override fun parseCriteria(criteria: QueryCriteria.VaultQueryCriteria): Collection&lt;Predicate&gt;</ID>
    <ID>ComplexMethod:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$private fun &lt;O, R&gt; parseAggregateFunction(root: Root&lt;O&gt;, expression: CriteriaExpression.AggregateFunctionExpression&lt;O, R&gt;): Expression&lt;out Any?&gt;?</ID>
    <ID>ComplexMethod:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$private fun parse(sorting: Sort)</ID>
    <ID>ComplexMethod:Kryo.kt$ImmutableClassSerializer$override fun read(kryo: Kryo, input: Input, type: Class&lt;T&gt;): T</ID>
    <ID>ComplexMethod:Kryo.kt$ImmutableClassSerializer$override fun write(kryo: Kryo, output: Output, obj: T)</ID>
    <ID>ComplexMethod:MigrationNamedCacheFactory.kt$MigrationNamedCacheFactory$private fun &lt;K, V&gt; configuredForNamed(caffeine: Caffeine&lt;K, V&gt;, name: String): Caffeine&lt;K, V&gt;</ID>
    <ID>ComplexMethod:NetworkMapUpdater.kt$NetworkMapUpdater$fun updateNetworkMapCache(): Duration</ID>
    <ID>ComplexMethod:NetworkParametersReader.kt$NetworkParametersReader$fun read(): NetworkParametersAndSigned</ID>
    <ID>ComplexMethod:NetworkRegistrationHelper.kt$NetworkRegistrationHelper$ private fun pollServerForCertificates(requestId: String): List&lt;X509Certificate&gt;</ID>
    <ID>ComplexMethod:Node.kt$Node$override fun startMessagingService(rpcOps: RPCOps, nodeInfo: NodeInfo, myNotaryIdentity: PartyAndCertificate?, networkParameters: NetworkParameters)</ID>
    <ID>ComplexMethod:NodeNamedCache.kt$DefaultNamedCacheFactory$open protected fun &lt;K, V&gt; configuredForNamed(caffeine: Caffeine&lt;K, V&gt;, name: String): Caffeine&lt;K, V&gt;</ID>
    <ID>ComplexMethod:NodeVaultService.kt$NodeVaultService$@Throws(VaultQueryException::class) private fun &lt;T : ContractState&gt; _queryBy(criteria: QueryCriteria, paging_: PageSpecification, sorting: Sort, contractStateType: Class&lt;out T&gt;, skipPagingChecks: Boolean): Vault.Page&lt;T&gt;</ID>
    <ID>ComplexMethod:NodeVaultService.kt$NodeVaultService$private fun makeUpdates(batch: Iterable&lt;CoreTransaction&gt;, statesToRecord: StatesToRecord, previouslySeen: Boolean): List&lt;Vault.Update&lt;ContractState&gt;&gt;</ID>
    <ID>ComplexMethod:ObjectDiffer.kt$ObjectDiffer$fun diff(a: Any?, b: Any?): DiffTree?</ID>
    <ID>ComplexMethod:PersistentNetworkMapCache.kt$PersistentNetworkMapCache$override fun addNodes(nodes: List&lt;NodeInfo&gt;)</ID>
    <ID>ComplexMethod:RPCServer.kt$RPCServer$private fun clientArtemisMessageHandler(artemisMessage: ClientMessage)</ID>
    <ID>ComplexMethod:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$override fun retryFlowFromSafePoint(currentState: StateMachineState)</ID>
    <ID>ComplexMethod:StartedFlowTransition.kt$StartedFlowTransition$override fun transition(): TransitionResult</ID>
    <ID>ComplexMethod:StartedFlowTransition.kt$StartedFlowTransition$private fun collectRelevantErrorsToThrow(flowIORequest: FlowIORequest&lt;*&gt;, checkpoint: Checkpoint): List&lt;Throwable&gt;</ID>
    <ID>ComplexMethod:TopLevelTransition.kt$TopLevelTransition$override fun transition(): TransitionResult</ID>
    <ID>ConstructorParameterNaming:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase.Transactional.InFlight$private val _readerValueLoader: () -&gt; T?</ID>
    <ID>ConstructorParameterNaming:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase.Transactional.InFlight$private val _writerValueLoader: () -&gt; T = { throw IllegalAccessException("No value loader provided") }</ID>
    <ID>ConstructorParameterNaming:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase.Transactional.Unknown$private val _valueLoader: () -&gt; T?</ID>
    <ID>ConstructorParameterNaming:CordaClock.kt$MutableClock$private var _delegateClock: Clock</ID>
    <ID>ConstructorParameterNaming:ScheduledActivityObserver.kt$ScheduledActivityObserver$private val FlowLogicRefFactory: FlowLogicRefFactory</ID>
    <ID>ConstructorParameterNaming:VaultSchema.kt$VaultSchemaV1.VaultFungibleStates$_issuerParty: AbstractParty</ID>
    <ID>ConstructorParameterNaming:VaultSchema.kt$VaultSchemaV1.VaultFungibleStates$_issuerRef: OpaqueBytes</ID>
    <ID>ConstructorParameterNaming:VaultSchema.kt$VaultSchemaV1.VaultFungibleStates$_owner: AbstractParty</ID>
    <ID>ConstructorParameterNaming:VaultSchema.kt$VaultSchemaV1.VaultFungibleStates$_quantity: Long</ID>
    <ID>EmptyCatchBlock:PersistentUniquenessProvider.kt$PersistentUniquenessProvider${ }</ID>
    <ID>EmptyFunctionBlock:AbstractNode.kt$FlowStarterImpl.&lt;no name provided&gt;${}</ID>
    <ID>EmptyFunctionBlock:BFTSmartNotaryService.kt$BFTSmartNotaryService${ }</ID>
    <ID>EmptyFunctionBlock:CordaMigration.kt$CordaMigration${ }</ID>
    <ID>EmptyFunctionBlock:InMemoryTransactionVerifierService.kt$InMemoryTransactionVerifierService${}</ID>
    <ID>EmptyFunctionBlock:PersistentIdentityMigration.kt$PersistentIdentityMigration${ }</ID>
    <ID>EmptyFunctionBlock:PersistentIdentityMigrationNewTable.kt$PersistentIdentityMigrationNewTable${ }</ID>
    <ID>EmptyFunctionBlock:SimpleNotaryService.kt$SimpleNotaryService${}</ID>
    <ID>EmptyFunctionBlock:TransitionExecutorImpl.kt$TransitionExecutorImpl${}</ID>
    <ID>EmptyKtFile:ValidatingNotaryService.kt$.ValidatingNotaryService.kt</ID>
    <ID>ForbiddenComment:AbstractNode.kt$AbstractNode$// TODO: Use configuration to indicate composite key should be used instead of public key for the identity.</ID>
    <ID>ForbiddenComment:AbstractNode.kt$AbstractNode$// TODO: We need a good way of handling "nice to have" shutdown events, especially those that deal with the</ID>
    <ID>ForbiddenComment:AbstractNode.kt$AbstractNode.&lt;no name provided&gt;$// TODO: Exponential backoff? It should reach max interval of eventHorizon/2.</ID>
    <ID>ForbiddenComment:AffinityExecutor.kt$AffinityExecutor$// TODO: Rename this to executeWithResult</ID>
    <ID>ForbiddenComment:ArtemisMessagingServer.kt$// TODO: Implement a discovery engine that can trigger builds of new connections when another node registers? (later)</ID>
    <ID>ForbiddenComment:ArtemisMessagingServer.kt$// TODO: Verify that nobody can connect to us and fiddle with our config over the socket due to the secman.</ID>
    <ID>ForbiddenComment:ArtemisMessagingServer.kt$ArtemisMessagingServer$// TODO: Maybe wrap [IOException] on a key store load error so that it's clearly splitting key store loading from</ID>
    <ID>ForbiddenComment:BFTSmart.kt$BFTSmart$// TODO: Define and document the configuration of the bft-smart cluster.</ID>
    <ID>ForbiddenComment:BFTSmart.kt$BFTSmart$// TODO: Potentially update the bft-smart API for our use case or rebuild client and server from lower level building</ID>
    <ID>ForbiddenComment:BFTSmart.kt$BFTSmart$// TODO: Support cluster membership changes. This requires reading about reconfiguration of bft-smart clusters and</ID>
    <ID>ForbiddenComment:BFTSmart.kt$BFTSmart.Client$// TODO: Hopefully we only need to wait for the client's initial connection to the cluster, and this method can be moved to some startup code.</ID>
    <ID>ForbiddenComment:BFTSmart.kt$BFTSmart.Client$// TODO: Investigate ConcurrentModificationException in this method.</ID>
    <ID>ForbiddenComment:BFTSmart.kt$BFTSmart.Client$// TODO: for now we treat all errors as equal, compare by error type as well</ID>
    <ID>ForbiddenComment:BFTSmart.kt$BFTSmart.Client$// TODO: is it safe use the last message for sender/session/sequence info</ID>
    <ID>ForbiddenComment:BFTSmart.kt$BFTSmart.Client$// TODO: only return an aggregate if the majority of signatures are replies</ID>
    <ID>ForbiddenComment:BFTSmart.kt$BFTSmart.Client$// TODO: return an error reported by the majority and not just the first one</ID>
    <ID>ForbiddenComment:BFTSmart.kt$BFTSmart.CordaServiceReplica$// TODO: At the cluster level, join all Sender/Receiver threads.</ID>
    <ID>ForbiddenComment:BFTSmart.kt$BFTSmart.Replica$// TODO:</ID>
    <ID>ForbiddenComment:BFTSmartNotaryService.kt$BFTSmartNotaryService.ServiceFlow$// TODO: here we assume that all error will be the same, but there might be invalid onces from mailicious nodes</ID>
    <ID>ForbiddenComment:BasicHSMKeyManagementService.kt$BasicHSMKeyManagementService$// TODO: A full KeyManagementService implementation needs to record activity to the Audit Service and to limit</ID>
    <ID>ForbiddenComment:CordaClassResolver.kt$CordaClassResolver$// TODO: Later we can support annotations on attachment classes and spin up a proxy via bytecode that we know is harmless.</ID>
    <ID>ForbiddenComment:CordaClassResolver.kt$CordaClassResolver$// TODO: come up with a more efficient way. e.g. segregate the name space by class loader.</ID>
    <ID>ForbiddenComment:CordappProviderImpl.kt$CordappProviderImpl$// TODO: Use better supported APIs in Java 9</ID>
    <ID>ForbiddenComment:CoreFlowHandlers.kt$NotaryChangeHandler$// TODO: Right now all nodes will automatically approve the notary change. We need to figure out if stricter controls are necessary.</ID>
    <ID>ForbiddenComment:DbTransactionsResolver.kt$DbTransactionsResolver$// TODO: This approach has two problems. Analyze and resolve them:</ID>
    <ID>ForbiddenComment:DefaultKryoCustomizer.kt$DefaultKryoCustomizer$// TODO: re-organise registrations into logical groups before v1.0</ID>
    <ID>ForbiddenComment:E2ETestKeyManagementService.kt$E2ETestKeyManagementService$// TODO: A full KeyManagementService implementation needs to record activity to the Audit Service and to limit</ID>
    <ID>ForbiddenComment:FiberUtils.kt$// TODO: This method uses a built-in Quasar function to make a map of all ThreadLocals. This is probably inefficient, but the only API readily available.</ID>
    <ID>ForbiddenComment:FlowLogicRefFactoryImpl.kt$FlowLogicRefFactoryImpl$// TODO: Replace with a per app classloader/cordapp provider/cordapp loader - this will do for now</ID>
    <ID>ForbiddenComment:FlowLogicRefFactoryImpl.kt$FlowLogicRefFactoryImpl$// TODO: This is used via RPC but it's probably better if we pass in argument names and values explicitly</ID>
    <ID>ForbiddenComment:GenerateRpcSslCertsCli.kt$GenerateRpcSslCerts$// TODO: consider adding a password strength policy.</ID>
    <ID>ForbiddenComment:InitialRegistrationCli.kt$InitialRegistration$// TODO: Move node identity generation logic from node to registration helper.</ID>
    <ID>ForbiddenComment:Kryo.kt$PublicKeySerializer$// TODO: Instead of encoding to the default X509 format, we could have a custom per key type (space-efficient) serialiser.</ID>
    <ID>ForbiddenComment:Node.kt$Node.Companion$// TODO: make this configurable.</ID>
    <ID>ForbiddenComment:NodeAttachmentService.kt$NodeAttachmentService$// TODO: PLT-147: The attachment should be randomised to prevent brute force guessing and thus privacy leaks.</ID>
    <ID>ForbiddenComment:NodeAttachmentService.kt$NodeAttachmentService$// TODO: Switch to a two-phase insert so we can handle attachments larger than RAM.</ID>
    <ID>ForbiddenComment:NodeAttachmentService.kt$NodeAttachmentService$// TODO: this is racey. ENT-2870</ID>
    <ID>ForbiddenComment:NodeConfigurationImpl.kt$NodeConfigurationImpl$// TODO: There are two implications here:</ID>
    <ID>ForbiddenComment:NodeInfoWatcher.kt$NodeInfoWatcher$// TODO: Use NIO watch service instead?</ID>
    <ID>ForbiddenComment:NodeVaultService.kt$NodeVaultService$// TODO: Optimise this.</ID>
    <ID>ForbiddenComment:NodeVaultService.kt$NodeVaultService$// TODO: Perhaps these can be stored in a batch?</ID>
    <ID>ForbiddenComment:NodeVaultService.kt$NodeVaultService$// TODO: This is a catch-all solution. But why is the default pageNumber set to be -1 in the first place?</ID>
    <ID>ForbiddenComment:NodeVaultService.kt$NodeVaultService$// TODO: This is expensive - is there another way?</ID>
    <ID>ForbiddenComment:NodeVaultService.kt$NodeVaultService$// TODO: improve typing of returned other results</ID>
    <ID>ForbiddenComment:NodeVaultService.kt$NodeVaultService$// TODO: revisit (use single instance of parser for all queries)</ID>
    <ID>ForbiddenComment:PersistentStateService.kt$PersistentStateService$// TODO: Manage version evolution of the schemas via additional tooling.</ID>
    <ID>ForbiddenComment:RaftTransactionCommitLog.kt$RaftTransactionCommitLog$// TODO: read &amp; put entries in batches</ID>
    <ID>ForbiddenComment:RaftTransactionCommitLog.kt$RaftTransactionCommitLog.Commands.CommitTransaction$// TODO: Cluster membership changes need testing.</ID>
    <ID>ForbiddenComment:RaftTransactionCommitLog.kt$RaftTransactionCommitLog.Commands.CommitTransaction$// TODO: I'm wondering if we should support resizing notary clusters, or if we could require users to</ID>
    <ID>ForbiddenComment:RaftUniquenessProvider.kt$RaftUniquenessProvider$// TODO: use local transport for client-server communications</ID>
    <ID>ForbiddenComment:ScheduledActivityObserver.kt$ScheduledActivityObserver.Companion$// TODO: Beware we are calling dynamically loaded contract code inside here.</ID>
    <ID>ForbiddenComment:ServiceHubInternal.kt$WritableTransactionStorage$// TODO: Throw an exception if trying to add a transaction with fewer signatures than an existing entry.</ID>
    <ID>ForbiddenComment:ServicesForResolutionImpl.kt$ServicesForResolutionImpl$// TODO: check only one (or until one is resolved successfully), max recursive invocations check?</ID>
    <ID>ForbiddenComment:StateMachineManagerUtils.kt$//TODO: instead of replacing the progress tracker after constructing the flow logic, we should inject it during fiber deserialization</ID>
    <ID>ForbiddenComment:VaultSchema.kt$VaultSchemaV1.VaultStates$// TODO: create a distinct table to hold serialized state data (once DBTransactionStore is encrypted)</ID>
    <ID>FunctionNaming:NodeVaultService.kt$NodeVaultService$@Throws(VaultQueryException::class) private fun &lt;T : ContractState&gt; _queryBy(criteria: QueryCriteria, paging_: PageSpecification, sorting: Sort, contractStateType: Class&lt;out T&gt;, skipPagingChecks: Boolean): Vault.Page&lt;T&gt;</ID>
    <ID>FunctionParameterNaming:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase.Transactional.InFlight$_value: T</ID>
    <ID>FunctionParameterNaming:NodeVaultService.kt$NodeVaultService$paging_: PageSpecification</ID>
    <ID>LargeClass:AbstractNode.kt$AbstractNode&lt;S&gt; : SingletonSerializeAsToken</ID>
    <ID>LargeClass:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager : StateMachineManagerStateMachineManagerInternal</ID>
    <ID>LongMethod:AbstractNode.kt$AbstractNode$open fun start(): S</ID>
    <ID>LongMethod:DefaultKryoCustomizer.kt$DefaultKryoCustomizer$fun customize(kryo: Kryo, publicKeySerializer: Serializer&lt;PublicKey&gt; = PublicKeySerializer): Kryo</ID>
    <ID>LongMethod:GenerateRpcSslCertsCli.kt$GenerateRpcSslCerts$private fun generateRpcSslCertificates(conf: NodeConfiguration)</ID>
    <ID>LongMethod:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$override fun parseCriteria(criteria: CommonQueryCriteria): Collection&lt;Predicate&gt;</ID>
    <ID>LongMethod:NodeStartup.kt$NodeStartup$open fun drawBanner(versionInfo: VersionInfo)</ID>
    <ID>LongMethod:NodeVaultService.kt$NodeVaultService$@Throws(VaultQueryException::class) private fun &lt;T : ContractState&gt; _queryBy(criteria: QueryCriteria, paging_: PageSpecification, sorting: Sort, contractStateType: Class&lt;out T&gt;, skipPagingChecks: Boolean): Vault.Page&lt;T&gt;</ID>
    <ID>LongMethod:V1NodeConfigurationSpec.kt$V1NodeConfigurationSpec$override fun parseValid(configuration: Config): Validated&lt;NodeConfiguration, Configuration.Validation.Error&gt;</ID>
    <ID>LongParameterList:AbstractNode.kt$(databaseConfig: DatabaseConfig, wellKnownPartyFromX500Name: (CordaX500Name) -&gt; Party?, wellKnownPartyFromAnonymous: (AbstractParty) -&gt; Party?, schemaService: SchemaService, hikariProperties: Properties, cacheFactory: NamedCacheFactory, customClassLoader: ClassLoader?)</ID>
    <ID>LongParameterList:AbstractNode.kt$(hikariProperties: Properties, databaseConfig: DatabaseConfig, schemas: Set&lt;MappedSchema&gt;, metricRegistry: MetricRegistry? = null, cordappLoader: CordappLoader? = null, currentDir: Path? = null, ourName: CordaX500Name)</ID>
    <ID>LongParameterList:ArtemisMessagingServer.kt$ArtemisMessagingServer$(name: String, send: Boolean = false, consume: Boolean = false, createDurableQueue: Boolean = false, deleteDurableQueue: Boolean = false, createNonDurableQueue: Boolean = false, deleteNonDurableQueue: Boolean = false, manage: Boolean = false, browse: Boolean = false)</ID>
    <ID>LongParameterList:ArtemisRpcBroker.kt$ArtemisRpcBroker.Companion$(configuration: MutualSslConfiguration, address: NetworkHostAndPort, adminAddress: NetworkHostAndPort, securityManager: RPCSecurityManager, maxMessageSize: Int, jmxEnabled: Boolean, baseDirectory: Path, shouldStartLocalShell: Boolean)</ID>
    <ID>LongParameterList:ArtemisRpcBroker.kt$ArtemisRpcBroker.Companion$(configuration: MutualSslConfiguration, address: NetworkHostAndPort, adminAddress: NetworkHostAndPort, sslOptions: BrokerRpcSslOptions, securityManager: RPCSecurityManager, maxMessageSize: Int, jmxEnabled: Boolean, baseDirectory: Path, shouldStartLocalShell: Boolean)</ID>
    <ID>LongParameterList:BFTSmart.kt$BFTSmart.Replica$( states: List&lt;StateRef&gt;, txId: SecureHash, callerName: CordaX500Name, requestSignature: NotarisationRequestSignature, timeWindow: TimeWindow?, references: List&lt;StateRef&gt; = emptyList() )</ID>
    <ID>LongParameterList:NetworkMapUpdater.kt$NetworkMapUpdater$(trustRoot: X509Certificate, currentParametersHash: SecureHash, ourNodeInfo: SignedNodeInfo, networkParameters: NetworkParameters, keyManagementService: KeyManagementService, networkParameterAcceptanceSettings: NetworkParameterAcceptanceSettings)</ID>
    <ID>LongParameterList:PersistentUniquenessProvider.kt$PersistentUniquenessProvider$( states: List&lt;StateRef&gt;, txId: SecureHash, callerIdentity: Party, requestSignature: NotarisationRequestSignature, timeWindow: TimeWindow?, references: List&lt;StateRef&gt; )</ID>
    <ID>LongParameterList:RpcBrokerConfiguration.kt$RpcBrokerConfiguration$(name: String, send: Boolean = false, consume: Boolean = false, createDurableQueue: Boolean = false, deleteDurableQueue: Boolean = false, createNonDurableQueue: Boolean = false, deleteNonDurableQueue: Boolean = false, manage: Boolean = false, browse: Boolean = false)</ID>
    <ID>LongParameterList:ServiceHubInternal.kt$ServiceHubInternal.Companion$(statesToRecord: StatesToRecord, txs: Collection&lt;SignedTransaction&gt;, validatedTransactions: WritableTransactionStorage, stateMachineRecordedTransactionMapping: StateMachineRecordedTransactionMappingStorage, vaultService: VaultServiceInternal, database: CordaPersistence)</ID>
    <ID>LongParameterList:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$( flowLogic: FlowLogic&lt;A&gt;, initiatingMessageDeduplicationHandler: DeduplicationHandler, peerSession: FlowSessionImpl, initiatedSessionId: SessionId, initiatingMessage: InitialSessionMessage, senderCoreFlowVersion: Int?, initiatedFlowInfo: FlowInfo )</ID>
    <ID>LongParameterList:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$( invocationContext: InvocationContext, flowLogic: FlowLogic&lt;A&gt;, flowStart: FlowStart, ourIdentity: Party, deduplicationHandler: DeduplicationHandler?, isStartIdempotent: Boolean )</ID>
    <ID>LongParameterList:StateMachineState.kt$Checkpoint.Companion$( invocationContext: InvocationContext, flowStart: FlowStart, flowLogicClass: Class&lt;FlowLogic&lt;*&gt;&gt;, frozenFlowLogic: SerializedBytes&lt;FlowLogic&lt;*&gt;&gt;, ourIdentity: Party, subFlowVersion: SubFlowVersion, isEnabledTimedFlow: Boolean )</ID>
    <ID>MagicNumber:AMQPServerSerializationScheme.kt$AMQPServerSerializationScheme$128</ID>
    <ID>MagicNumber:AbstractNode.kt$AbstractNode$50</ID>
    <ID>MagicNumber:ArtemisMessagingServer.kt$ArtemisMessagingServer$10L</ID>
    <ID>MagicNumber:ArtemisMessagingServer.kt$ArtemisMessagingServer$2000</ID>
    <ID>MagicNumber:BFTSmart.kt$BFTSmart.Client$100</ID>
    <ID>MagicNumber:BFTSmart.kt$BFTSmart.Replica.&lt;no name provided&gt;$20000</ID>
    <ID>MagicNumber:BFTSmartConfigInternal.kt$3</ID>
    <ID>MagicNumber:BFTSmartConfigInternal.kt$BFTSmartConfigInternal$200</ID>
    <ID>MagicNumber:DefaultKryoCustomizer.kt$DefaultKryoCustomizer.ContractAttachmentSerializer$32</ID>
    <ID>MagicNumber:FlowMonitor.kt$FlowMonitor$1000</ID>
    <ID>MagicNumber:HTTPNetworkRegistrationService.kt$HTTPNetworkRegistrationService$10</ID>
    <ID>MagicNumber:InternalRPCMessagingClient.kt$InternalRPCMessagingClient$30000</ID>
    <ID>MagicNumber:InternalRPCMessagingClient.kt$InternalRPCMessagingClient$60000</ID>
    <ID>MagicNumber:JarScanningCordappLoader.kt$CordappLoaderTemplate$36</ID>
    <ID>MagicNumber:JarScanningCordappLoader.kt$CordappLoaderTemplate$64</ID>
    <ID>MagicNumber:JarScanningCordappLoader.kt$JarScanningCordappLoader$1000</ID>
    <ID>MagicNumber:KMSUtils.kt$3650</ID>
    <ID>MagicNumber:Kryo.kt$InputStreamSerializer$4096</ID>
    <ID>MagicNumber:KryoStreams.kt$1024</ID>
    <ID>MagicNumber:KryoStreams.kt$64</ID>
    <ID>MagicNumber:MigrationNamedCacheFactory.kt$MigrationNamedCacheFactory$1024L</ID>
    <ID>MagicNumber:NetworkMapUpdater.kt$NetworkMapUpdater$24</ID>
    <ID>MagicNumber:NetworkMapUpdater.kt$NetworkMapUpdater$4</ID>
    <ID>MagicNumber:NetworkMapUpdater.kt$NetworkMapUpdater$50</ID>
    <ID>MagicNumber:NetworkRegistrationHelper.kt$NetworkRegistrationHelper$10</ID>
    <ID>MagicNumber:NetworkRegistrationHelper.kt$NodeRegistrationHelper$10</ID>
    <ID>MagicNumber:Node.kt$Node$128</ID>
    <ID>MagicNumber:Node.kt$Node$256</ID>
    <ID>MagicNumber:Node.kt$Node$4</ID>
    <ID>MagicNumber:Node.kt$Node.Companion$171</ID>
    <ID>MagicNumber:Node.kt$Node.Companion$40</ID>
    <ID>MagicNumber:NodeCmdLineOptions.kt$NodeCmdLineOptions$2222</ID>
    <ID>MagicNumber:NodeConfiguration.kt$1024L</ID>
    <ID>MagicNumber:NodeConfiguration.kt$NodeConfiguration$5</ID>
    <ID>MagicNumber:NodeConfiguration.kt$NodeConfiguration.Companion$20</ID>
    <ID>MagicNumber:NodeConfiguration.kt$NodeConfiguration.Companion$300</ID>
    <ID>MagicNumber:NodeConfigurationImpl.kt$NodeConfigurationImpl.Defaults$5</ID>
    <ID>MagicNumber:NodeInfoWatcher.kt$NodeInfoWatcher$5</ID>
    <ID>MagicNumber:NodeNamedCache.kt$DefaultNamedCacheFactory$1024L</ID>
    <ID>MagicNumber:NodeSchedulerService.kt$NodeSchedulerService$60</ID>
    <ID>MagicNumber:NodeStartup.kt$NodeStartup$10</ID>
    <ID>MagicNumber:NodeStartup.kt$NodeStartup$100.0</ID>
    <ID>MagicNumber:NodeStartup.kt$NodeStartup$1000</ID>
    <ID>MagicNumber:NodeStartup.kt$NodeStartup$20</ID>
    <ID>MagicNumber:NodeStartup.kt$NodeStartup$7</ID>
    <ID>MagicNumber:NonValidatingNotaryFlow.kt$NonValidatingNotaryFlow$4</ID>
    <ID>MagicNumber:ObjectDiffer.kt$ObjectDiffer$3</ID>
    <ID>MagicNumber:ObjectDiffer.kt$ObjectDiffer$4</ID>
    <ID>MagicNumber:P2PMessagingClient.kt$P2PMessagingClient$30000</ID>
    <ID>MagicNumber:P2PMessagingClient.kt$P2PMessagingClient$60000</ID>
    <ID>MagicNumber:P2PMessagingClient.kt$P2PMessagingConsumer$10</ID>
    <ID>MagicNumber:Password.kt$Password$5</ID>
    <ID>MagicNumber:PersistentIdentityMigrationNewTable.kt$PersistentIdentityMigrationNewTable$70</ID>
    <ID>MagicNumber:PersistentUniquenessProvider.kt$PersistentUniquenessProvider$100</ID>
    <ID>MagicNumber:RPCServer.kt$RPCServer$5</ID>
    <ID>MagicNumber:RpcBrokerConfiguration.kt$RpcBrokerConfiguration$2000</ID>
    <ID>MagicNumber:RpcBrokerConfiguration.kt$RpcBrokerConfiguration$5L</ID>
    <ID>MagicNumber:RpcBrokerConfiguration.kt$RpcBrokerConfiguration$8</ID>
    <ID>MagicNumber:SecureArtemisConfiguration.kt$SecureArtemisConfiguration$128</ID>
    <ID>MagicNumber:SecureArtemisConfiguration.kt$SecureArtemisConfiguration$16</ID>
    <ID>MagicNumber:StaffedFlowHospital.kt$StaffedFlowHospital$1.5</ID>
    <ID>MagicNumber:StaffedFlowHospital.kt$StaffedFlowHospital$10</ID>
    <ID>MagicNumber:StaffedFlowHospital.kt$StaffedFlowHospital.DuplicateInsertSpecialist$3</ID>
    <ID>MagicNumber:VaultStateMigration.kt$VaultStateIterator$1000</ID>
    <ID>MagicNumber:VaultStateMigration.kt$VaultStateIterator.VaultPageTask$10</ID>
    <ID>MagicNumber:errorAndTerminate.kt$10</ID>
    <ID>MatchingDeclarationName:ConfigUtilities.kt$net.corda.node.services.config.ConfigUtilities.kt</ID>
    <ID>MatchingDeclarationName:RpcServerCordaFutureSerialiser.kt$net.corda.node.serialization.amqp.RpcServerCordaFutureSerialiser.kt</ID>
    <ID>MatchingDeclarationName:VirtualCordapps.kt$net.corda.node.internal.cordapp.VirtualCordapps.kt</ID>
    <ID>MaxLineLength:AMQPServerSerializationScheme.kt$AMQPServerSerializationScheme$( cordappCustomSerializers: Set&lt;SerializationCustomSerializer&lt;*, *&gt;&gt;, cordappSerializationWhitelists: Set&lt;SerializationWhitelist&gt;, serializerFactoriesForContexts: MutableMap&lt;SerializationFactoryCacheKey, SerializerFactory&gt; )</ID>
    <ID>MaxLineLength:AMQPServerSerializationScheme.kt$AMQPServerSerializationScheme$constructor() : this(emptySet(), emptySet(), AccessOrderLinkedHashMap&lt;SerializationFactoryCacheKey, SerializerFactory&gt;(128).toSynchronised() )</ID>
    <ID>MaxLineLength:AMQPServerSerializationScheme.kt$AMQPServerSerializationScheme$constructor(cordapps: List&lt;Cordapp&gt;) : this(cordapps.customSerializers, cordapps.serializationWhitelists, AccessOrderLinkedHashMap&lt;SerializationFactoryCacheKey, SerializerFactory&gt;(128).toSynchronised())</ID>
    <ID>MaxLineLength:AMQPServerSerializationScheme.kt$AMQPServerSerializationScheme$constructor(cordapps: List&lt;Cordapp&gt;, serializerFactoriesForContexts: MutableMap&lt;SerializationFactoryCacheKey, SerializerFactory&gt;) : this(cordapps.customSerializers, cordapps.serializationWhitelists, serializerFactoriesForContexts)</ID>
    <ID>MaxLineLength:AMQPServerSerializationScheme.kt$AMQPServerSerializationScheme$return SerializerFactoryBuilder.build(context.whitelist, context.deserializationClassLoader, context.lenientCarpenterEnabled).apply { register(RpcServerObservableSerializer()) register(RpcServerCordaFutureSerializer(this)) register(RxNotificationSerializer(this)) }</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$" for it exists in the database. This suggests the identity for this node has been lost. Shutting down to prevent network map issues."</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$"Private key for the node legal identity not found (alias $legalIdentityPrivateKeyAlias) but the corresponding public key"</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$"match what's in the key store: $subject. You might need to adjust the configuration of `notary.serviceLegalName`."</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$"or if you don't have one yet, fill out the config file and run corda.jar initial-registration. "</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$( CertificateType.LEGAL_IDENTITY, nodeCaCert.subjectX500Principal, nodeCaCert.publicKey, cryptoService.getSigner(X509Utilities.CORDA_CLIENT_CA), nodeCaCert.subjectX500Principal, legalIdentityPublicKey, // TODO this might be smaller than DEFAULT_VALIDITY_WINDOW, shall we strictly apply DEFAULT_VALIDITY_WINDOW? X509Utilities.getCertificateValidityWindow( DEFAULT_VALIDITY_WINDOW.first, DEFAULT_VALIDITY_WINDOW.second, nodeCaCert) )</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$/** * Should be [rx.schedulers.Schedulers.io] for production, * or [rx.internal.schedulers.CachedThreadScheduler] (with shutdown registered with [runOnStop]) for shared-JVM testing. */ protected abstract val rxIoScheduler: Scheduler</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$// Ideally we should be disabling the FinalityHandler if it's not needed, to prevent any party from submitting transactions to us without // us checking. Previously this was gated on app target version and if there were no apps with target version &lt;= 3 then the handler would // be disabled. However this prevents seemless rolling-upgrades and so it was removed until a better solution comes along. private fun installFinalityHandler()</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$// TODO Cancelling parameters updates - if we do that, how we ensure that no one uses cancelled parameters in the transactions? val networkMapUpdater = NetworkMapUpdater( networkMapCache, NodeInfoWatcher( configuration.baseDirectory, @Suppress("LeakingThis") rxIoScheduler, Duration.ofMillis(configuration.additionalNodeInfoPollingFrequencyMsec) ), networkMapClient, configuration.baseDirectory, configuration.extraNetworkMapKeys, networkParametersStorage ).closeOnStop()</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$// There is already a party in the identity store for this node, but the key has been lost. If this node starts up, it will // publish it's new key to the network map, which Corda cannot currently handle. To prevent this, stop the node from starting. "Private key for the node legal identity not found (alias $legalIdentityPrivateKeyAlias) but the corresponding public key" + " for it exists in the database. This suggests the identity for this node has been lost. Shutting down to prevent network map issues."</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$AllCertificateStores</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$CheckpointVerifier.verifyCheckpointsCompatible(checkpointStorage, cordappProvider.cordapps, versionInfo.platformVersion, services, tokenizableServices)</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$ServiceInstantiationException : CordaException</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$cordapp.initiatedFlows.groupBy { it.requireAnnotation&lt;InitiatedBy&gt;().value.java }</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$database.startHikariPool(props, configuration.database, schemaService.internalSchemas(), metricRegistry, this.cordappLoader, configuration.baseDirectory, configuration.myLegalName)</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$flowManager.registerInitiatedCoreFlowFactory(ContractUpgradeFlow.Initiate::class, NotaryChangeHandler::class, ::ContractUpgradeHandler)</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$flowManager.registerInitiatedCoreFlowFactory(NotaryChangeFlow::class, NotaryChangeHandler::class, ::NotaryChangeHandler)</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$flowManager.registerInitiatedCoreFlowFactory(SwapIdentitiesFlow::class, SwapIdentitiesHandler::class, ::SwapIdentitiesHandler)</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$if (!cryptoService.containsKey(legalIdentityPrivateKeyAlias) &amp;&amp; !signingCertificateStore.contains(legalIdentityPrivateKeyAlias)) { // Directly use the X500 name to public key map, as the identity service requires the node identity to start correctly. database.transaction { val x500Map = PersistentIdentityService.createX500ToKeyMap(cacheFactory) require(configuration.myLegalName !in x500Map) { // There is already a party in the identity store for this node, but the key has been lost. If this node starts up, it will // publish it's new key to the network map, which Corda cannot currently handle. To prevent this, stop the node from starting. "Private key for the node legal identity not found (alias $legalIdentityPrivateKeyAlias) but the corresponding public key" + " for it exists in the database. This suggests the identity for this node has been lost. Shutting down to prevent network map issues." } } log.info("$legalIdentityPrivateKeyAlias not found in key store, generating fresh key!") createAndStoreLegalIdentity(legalIdentityPrivateKeyAlias) signingCertificateStore = configuration.signingCertificateStore.get() // We need to resync after [createAndStoreLegalIdentity]. } else { checkAliasMismatch(legalIdentityPrivateKeyAlias, signingCertificateStore) }</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$log</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$log.error("Corda service ${it.name} failed to instantiate. Reason was: ${e.cause?.rootMessage}", e.cause)</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$log.error("Error while adding key fingerprint $it to cordappSignerKeyFingerprintBlacklist due to ${e.message}", e)</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$log.warn("Found more than one node registration with our legal name, this is only expected if our keypair has been regenerated")</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$networkParametersStorage.setCurrentParameters(signedNetParams, trustRoot) identityService.loadIdentities(nodeInfo.legalIdentitiesAndCerts) attachments.start() cordappProvider.start() nodeProperties.start() // Place the long term identity key in the KMS. Eventually, this is likely going to be separated again because // the KMS is meant for derived temporary keys used in transactions, and we're not supposed to sign things with // the identity key. But the infrastructure to make that easy isn't here yet. keyManagementService.start(keyPairs) val notaryService = maybeStartNotaryService(myNotaryIdentity) installCordaServices() contractUpgradeService.start() vaultService.start() ScheduledActivityObserver.install(vaultService, schedulerService, flowLogicRefFactory) val frozenTokenizableServices = tokenizableServices!! tokenizableServices = null verifyCheckpointsCompatible(frozenTokenizableServices) checkpointDumper.start(frozenTokenizableServices) smm.start(frozenTokenizableServices) // Shut down the SMM so no Fibers are scheduled. runOnStop += { smm.stop(acceptableLiveFiberCountOnStop()) } (smm as? StateMachineManagerInternal)?.let { val flowMonitor = FlowMonitor({ smm.snapshot().filter { flow -&gt; flow !in smm.flowHospital }.toSet() }, configuration.flowMonitorPeriodMillis, configuration.flowMonitorSuspensionLoggingThresholdMillis) runOnStop += flowMonitor::stop flowMonitor.start() } schedulerService.start() createStartedNode(nodeInfo, rpcOps, notaryService).also { _started = it }</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$private</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$protected open</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$protected open fun generateKeyPair(alias: String)</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$protected val cacheFactory = cacheFactoryPrototype.bindWithConfig(configuration).bindWithMetrics(metricRegistry).tokenize()</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$return NodeVaultService(platformClock, keyManagementService, services, database, schemaService, cordappLoader.appClassLoader)</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$signingCertificateStore = configuration.signingCertificateStore.get()</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$throw ConfigurationException("The name '$legalName' for $NODE_IDENTITY_ALIAS_PREFIX doesn't match what's in the key store: $subject")</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$throw ConfigurationException("The name of the notary service '$serviceLegalName' for $DISTRIBUTED_NOTARY_ALIAS_PREFIX doesn't " + "match what's in the key store: $subject. You might need to adjust the configuration of `notary.serviceLegalName`.")</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$throw IllegalArgumentException("At least one of the keystores or truststore passwords does not match configuration.")</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$throw IllegalStateException("CryptoService and signingCertificateStore are not aligned, the entry for key-alias: $alias is only found in $keyExistsIn")</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$val (netParams, signedNetParams) = NetworkParametersReader(trustRoot, networkMapClient, configuration.baseDirectory).read()</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$val certificates = if (cryptoService.containsKey(compositeKeyAlias) &amp;&amp; signingCertificateStore.contains(compositeKeyAlias)) { val certificate = signingCertificateStore[compositeKeyAlias] // We have to create the certificate chain for the composite key manually, this is because we don't have a keystore // provider that understand compositeKey-privateKey combo. The cert chain is created using the composite key certificate + // the tail of the private key certificates, as they are both signed by the same certificate chain. listOf(certificate) + privateKeyAliasCertChain.drop(1) } else { checkAliasMismatch(compositeKeyAlias, signingCertificateStore) // If [compositeKeyAlias] does not exist, we assume the notary is CFT, and each cluster member shares the same notary key pair. privateKeyAliasCertChain }</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$val certificates: List&lt;X509Certificate&gt; = signingCertificateStore.query { getCertificateChain(legalIdentityPrivateKeyAlias) }</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$val checkpointDumper = CheckpointDumper(checkpointStorage, database, services, services.configuration.baseDirectory)</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$val cordappProvider = CordappProviderImpl(cordappLoader, CordappConfigFileProvider(configuration.cordappDirectories), attachments).tokenize()</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$val extendedServiceConstructor = serviceClass.getDeclaredConstructor(AppServiceHub::class.java).apply { isAccessible = true }</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$val keyExistsIn: String = if (cryptoService.containsKey(alias)) "CryptoService" else "signingCertificateStore"</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$val networkMapClient: NetworkMapClient? = configuration.networkServices?.let { NetworkMapClient(it.networkMapURL, versionInfo) }</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode$val servicesForResolution = ServicesForResolutionImpl(identityService, attachments, cordappProvider, networkParametersStorage, transactionStorage).also { attachments.servicesForResolution = it }</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode${ // Directly use the X500 name to public key map, as the identity service requires the node identity to start correctly. database.transaction { val x500Map = PersistentIdentityService.createX500ToKeyMap(cacheFactory) require(configuration.myLegalName !in x500Map) { // There is already a party in the identity store for this node, but the key has been lost. If this node starts up, it will // publish it's new key to the network map, which Corda cannot currently handle. To prevent this, stop the node from starting. "Private key for the node legal identity not found (alias $legalIdentityPrivateKeyAlias) but the corresponding public key" + " for it exists in the database. This suggests the identity for this node has been lost. Shutting down to prevent network map issues." } } log.info("$legalIdentityPrivateKeyAlias not found in key store, generating fresh key!") createAndStoreLegalIdentity(legalIdentityPrivateKeyAlias) signingCertificateStore = configuration.signingCertificateStore.get() // We need to resync after [createAndStoreLegalIdentity]. }</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode${ // The following will throw IOException if key file not found or KeyStoreException if keystore password is incorrect. val sslKeyStore = configuration.p2pSslOptions.keyStore.get() val signingCertificateStore = configuration.signingCertificateStore.get() val trustStore = configuration.p2pSslOptions.trustStore.get() AllCertificateStores(trustStore, sslKeyStore, signingCertificateStore) }</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode${ checkAliasMismatch(compositeKeyAlias, signingCertificateStore) // If [compositeKeyAlias] does not exist, we assume the notary is CFT, and each cluster member shares the same notary key pair. privateKeyAliasCertChain }</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode${ val certificate = signingCertificateStore[compositeKeyAlias] // We have to create the certificate chain for the composite key manually, this is because we don't have a keystore // provider that understand compositeKey-privateKey combo. The cert chain is created using the composite key certificate + // the tail of the private key certificates, as they are both signed by the same certificate chain. listOf(certificate) + privateKeyAliasCertChain.drop(1) }</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode${ val loadedServices = cordappLoader.cordapps.flatMap { it.services } // This sets the Cordapp classloader on the contextClassLoader of the current thread, prior to initializing services // Needed because of bug CORDA-2653 - some Corda services can utilise third-party libraries that require access to // the Thread context class loader val oldContextClassLoader: ClassLoader? = Thread.currentThread().contextClassLoader try { Thread.currentThread().contextClassLoader = cordappLoader.appClassLoader loadedServices.forEach { try { installCordaService(it) } catch (e: NoSuchMethodException) { log.error("${it.name}, as a Corda service, must have a constructor with a single parameter of type " + ServiceHub::class.java.name) } catch (e: ServiceInstantiationException) { if (e.cause != null) { log.error("Corda service ${it.name} failed to instantiate. Reason was: ${e.cause?.rootMessage}", e.cause) } else { log.error("Corda service ${it.name} failed to instantiate", e) } } catch (e: Exception) { log.error("Unable to install Corda service ${it.name}", e) } } } finally { Thread.currentThread().contextClassLoader = oldContextClassLoader } }</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode.AppServiceHubImpl$private</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode.AppServiceHubImpl$require(logicType.isAnnotationPresent(StartableByService::class.java)) { "${logicType.name} was not designed for starting by a CordaService" }</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode.ServiceHubInternalImpl$inner</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode.ServiceHubInternalImpl$override val networkParametersService: NetworkParametersStorage get() = this@AbstractNode.networkParametersStorage</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode.ServiceHubInternalImpl$override val transactionVerifierService: TransactionVerifierService get() = this@AbstractNode.transactionVerifierService</ID>
    <ID>MaxLineLength:AbstractNode.kt$AbstractNode&lt;S&gt; : SingletonSerializeAsToken</ID>
    <ID>MaxLineLength:AbstractNode.kt$FlowStarterImpl : FlowStarter</ID>
    <ID>MaxLineLength:AbstractNode.kt$JavaTypeDescriptorRegistry.INSTANCE.addDescriptor(AbstractPartyDescriptor(wellKnownPartyFromX500Name, wellKnownPartyFromAnonymous))</ID>
    <ID>MaxLineLength:AbstractNode.kt$ex is HikariPool.PoolInitializationException -&gt; throw CouldNotCreateDataSourceException("Could not connect to the database. Please check your JDBC connection URL, or the connectivity to the database.", ex)</ID>
    <ID>MaxLineLength:AbstractNode.kt$ex.cause is ClassNotFoundException -&gt; throw CouldNotCreateDataSourceException("Could not find the database driver class. Please add it to the 'drivers' folder. See: https://docs.corda.net/corda-configuration-file.html")</ID>
    <ID>MaxLineLength:AbstractNode.kt$fun CordaPersistence.startHikariPool(hikariProperties: Properties, databaseConfig: DatabaseConfig, schemas: Set&lt;MappedSchema&gt;, metricRegistry: MetricRegistry? = null, cordappLoader: CordappLoader? = null, currentDir: Path? = null, ourName: CordaX500Name)</ID>
    <ID>MaxLineLength:AbstractNode.kt$return ClientRpcSslOptions(trustStorePath = nodeRpcOptions.sslConfig!!.keyStorePath, trustStorePassword = nodeRpcOptions.sslConfig!!.keyStorePassword)</ID>
    <ID>MaxLineLength:AbstractNode.kt$return CordaPersistence(databaseConfig, schemaService.schemaOptions.keys, jdbcUrl, cacheFactory, attributeConverters, customClassLoader)</ID>
    <ID>MaxLineLength:AbstractNode.kt$val attributeConverters = listOf(PublicKeyToTextConverter(), AbstractPartyToX500NameAsStringConverter(wellKnownPartyFromX500Name, wellKnownPartyFromAnonymous))</ID>
    <ID>MaxLineLength:AbstractPartyDescriptor.kt$AbstractPartyDescriptor$private val wellKnownPartyFromAnonymous: (AbstractParty) -&gt; Party?</ID>
    <ID>MaxLineLength:AbstractPartyToX500NameAsStringConverter.kt$AbstractPartyToX500NameAsStringConverter$private val wellKnownPartyFromAnonymous: (AbstractParty) -&gt; Party?</ID>
    <ID>MaxLineLength:Action.kt$Action$RetryFlowFromSafePoint : Action</ID>
    <ID>MaxLineLength:Action.kt$Action$ScheduleFlowTimeout : Action</ID>
    <ID>MaxLineLength:Action.kt$Action.PersistCheckpoint$data</ID>
    <ID>MaxLineLength:Action.kt$FlowRemovalReason${ data class OrderlyFinish(val flowReturnValue: Any?) : FlowRemovalReason() data class ErrorFinish(val flowErrors: List&lt;FlowError&gt;) : FlowRemovalReason() object SoftShutdown : FlowRemovalReason() { override fun toString() = "SoftShutdown" } // TODO Should we remove errored flows? How will the flow hospital work? Perhaps keep them in memory for a while, flush // them after a timeout, reload them on flow hospital request. In any case if we ever want to remove them // (e.g. temporarily) then add a case for that here. }</ID>
    <ID>MaxLineLength:ActionExecutorImpl.kt$ActionExecutorImpl$flowMessaging.sendSessionMessage(sessionState.peerParty, existingMessage, SenderDeduplicationId(deduplicationId, action.senderUUID))</ID>
    <ID>MaxLineLength:ActionExecutorImpl.kt$ActionExecutorImpl$private val checkpointBandwidth = metrics.register("Flows.CheckpointVolumeBytesPerSecondCurrent", LatchedGauge(checkpointSizesThisSecond))</ID>
    <ID>MaxLineLength:ActionExecutorImpl.kt$ActionExecutorImpl$private val checkpointBandwidthHist = metrics.register("Flows.CheckpointVolumeBytesPerSecondHist", Histogram(SlidingTimeWindowArrayReservoir(1, TimeUnit.DAYS)))</ID>
    <ID>MaxLineLength:AffinityExecutor.kt$AffinityExecutor$ fun executeASAP(runnable: () -&gt; Unit)</ID>
    <ID>MaxLineLength:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase$ fun addOrUpdate(key: K, value: V, updateFn: (K, V) -&gt; Boolean): Boolean</ID>
    <ID>MaxLineLength:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase$ fun addWithDuplicatesAllowed(key: K, value: V, logWarning: Boolean = true): Boolean</ID>
    <ID>MaxLineLength:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase$ operator fun set(key: K, value: V)</ID>
    <ID>MaxLineLength:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase$Transactional.InFlight(this, key, _readerValueLoader = { loadValue(key) }).apply { alsoWrite(value) }</ID>
    <ID>MaxLineLength:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase$log.warn("Double insert in ${this.javaClass.name} for entity class $persistentEntityClass key $key, not inserting the second time")</ID>
    <ID>MaxLineLength:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase$oldValueInCache</ID>
    <ID>MaxLineLength:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase${ // IMPORTANT: The flush is needed because detach() makes the queue of unflushed entries invalid w.r.t. Hibernate internal state if the found entity is unflushed. // We want the detach() so that we rely on our cache memory management and don't retain strong references in the Hibernate session. session.flush() }</ID>
    <ID>MaxLineLength:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase${ // If someone is writing (but not us) // For those not writing, they need to re-load the value from the database (which their database transaction MIGHT see). // For those writing, they need to re-load the value from the database (which their database transaction CAN see). Transactional.InFlight(this, key, { loadValue(key) }, { loadValue(key)!! }) }</ID>
    <ID>MaxLineLength:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase${ // If we found a value already in the database, and we were not already writing, then it's already committed but got evicted. Transactional.Committed(oldValue) }</ID>
    <ID>MaxLineLength:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase${ // Some database transactions, including us, writing, with readers seeing whatever is in the database and writers seeing the (in memory) value. Transactional.InFlight(this, key, _readerValueLoader = { loadValue(key) }).apply { alsoWrite(value) } }</ID>
    <ID>MaxLineLength:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase${ // Someone else is writing, so store away! val retainedValueFromDB = store(key, value) wasWritten = (retainedValueFromDB == null) // If the store function claims the value is new in the DB, then either the value is brand new or updated. In this case, // update the old value in the cache with the new value. Otherwise, leave it as it was before. if (wasWritten) { oldValueInCache.apply { alsoWrite(value) } } else { oldValueInCache } }</ID>
    <ID>MaxLineLength:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase${ val retainedValueFromDB = store(key, value) wasWritten = (retainedValueFromDB == null) // If the value has been updated, then isUnique will be true. In this case, the Committed value needs to be replaced // with InFlight to indicate that this transaction has changed the value associated with this key. Note that this allows // for cases where the value passed to set differs from that in the cache, but an update function has decided that this // differing value should not be written to the database. if (wasWritten) { Transactional.InFlight(this, key, _readerValueLoader = { loadValue(key) }).apply { alsoWrite(value) } } else { oldValueInCache } }</ID>
    <ID>MaxLineLength:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase.Transactional$InFlight&lt;K, T&gt; : Transactional</ID>
    <ID>MaxLineLength:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase.Transactional.InFlight$// The value from the perspective of the eviction algorithm of the cache. i.e. we want to reveal memory footprint to it etc. override val peekableValue: T? get() = if (writerValueLoader.get() != _writerValueLoader) writerValueLoader.get()() else if (readerValueLoader.get() != _readerValueLoader) readerValueLoader.get()() else null</ID>
    <ID>MaxLineLength:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase.Transactional.InFlight$get() = if (isPresentAsWriter) loadAsWriter() else if (isPresentAsReader) loadAsReader()!! else throw NoSuchElementException("Not present")</ID>
    <ID>MaxLineLength:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase.Transactional.InFlight$get() = if (writerValueLoader.get() != _writerValueLoader) writerValueLoader.get()() else if (readerValueLoader.get() != _readerValueLoader) readerValueLoader.get()() else null</ID>
    <ID>MaxLineLength:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase.Transactional.InFlight$private val _writerValueLoader: () -&gt; T = { throw IllegalAccessException("No value loader provided") }</ID>
    <ID>MaxLineLength:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase.Transactional.InFlight${ // Make the lazy loader the writers see actually just return the value that has been set. writerValueLoader.set { _value } // We make all these vals so that the lambdas do not need a reference to this, and so the onCommit only has a weak ref to the value. // We want this so that the cache could evict the value (due to memory constraints etc) without the onCommit callback // retaining what could be a large memory footprint object. val tx = contextTransaction val strongKey = key val strongMap = map if (map.addPendingKey(key, tx)) { // If the transaction commits, update cache to make globally visible if we're first for this key, // and then stop saying the transaction is writing the key. tx.onCommit { strongMap.cache.asMap().computeIfPresent(strongKey) { _, transactional: Transactional&lt;T&gt; -&gt; if (transactional is Transactional.InFlight&lt;*, T&gt;) { transactional.committed.set(true) val value = transactional.peekableValue if (value != null) { Transactional.Committed(value) } else { transactional } } else { transactional } } strongMap.removePendingKey(strongKey, tx) } // If the transaction rolls back, stop saying this transaction is writing the key. tx.onRollback { strongMap.removePendingKey(strongKey, tx) } } }</ID>
    <ID>MaxLineLength:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase.Transactional.Unknown$val readValue = _valueLoader() // We re-write the value into the cache so that any weigher can re-assess the weight based on the loaded value. map.cache.asMap().compute(key) { _, oldValue -&gt; if (oldValue === this@Unknown) { if (readValue == null) Missing() else Committed(readValue) } else oldValue } readValue</ID>
    <ID>MaxLineLength:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase&lt;K, V, E, out EK&gt;</ID>
    <ID>MaxLineLength:ArtemisBroker.kt$fun java.io.IOException.isBindingError()</ID>
    <ID>MaxLineLength:ArtemisMessagingServer.kt$ArtemisMessagingServer$ private fun ConfigurationImpl.configureAddressSecurity(): Configuration</ID>
    <ID>MaxLineLength:ArtemisMessagingServer.kt$ArtemisMessagingServer$acceptorConfigurations = mutableSetOf(p2pAcceptorTcpTransport(NetworkHostAndPort(messagingServerAddress.host, messagingServerAddress.port), config.p2pSslOptions))</ID>
    <ID>MaxLineLength:ArtemisMessagingServer.kt$ArtemisMessagingServer$deleteNonDurableQueue</ID>
    <ID>MaxLineLength:ArtemisMessagingServer.kt$ArtemisMessagingServer$deleteNonDurableQueue: Boolean = false</ID>
    <ID>MaxLineLength:ArtemisMessagingServer.kt$ArtemisMessagingServer$journalBufferSize_AIO = maxMessageSize + JOURNAL_HEADER_SIZE</ID>
    <ID>MaxLineLength:ArtemisMessagingServer.kt$ArtemisMessagingServer$journalBufferSize_NIO = maxMessageSize + JOURNAL_HEADER_SIZE</ID>
    <ID>MaxLineLength:ArtemisMessagingServer.kt$ArtemisMessagingServer$journalFileSize = maxMessageSize + JOURNAL_HEADER_SIZE</ID>
    <ID>MaxLineLength:ArtemisMessagingServer.kt$ArtemisMessagingServer$private</ID>
    <ID>MaxLineLength:ArtemisMessagingServer.kt$ArtemisMessagingServer$securityRoles["$INTERNAL_PREFIX#"] = setOf(nodeInternalRole)</ID>
    <ID>MaxLineLength:ArtemisRpcBroker.kt$ArtemisRpcBroker$throw AddressBindingException(adminAddressOptional?.let { setOf(it, addresses.primary) } ?: setOf(addresses.primary))</ID>
    <ID>MaxLineLength:ArtemisRpcBroker.kt$ArtemisRpcBroker$val serverConfiguration = RpcBrokerConfiguration(baseDirectory, maxMessageSize, jmxEnabled, addresses.primary, adminAddressOptional, sslOptions, useSsl, nodeConfiguration, shouldStartLocalShell)</ID>
    <ID>MaxLineLength:ArtemisRpcBroker.kt$ArtemisRpcBroker.&lt;no name provided&gt;$return arrayOf(AppConfigurationEntry(name, AppConfigurationEntry.LoginModuleControlFlag.REQUIRED, options))</ID>
    <ID>MaxLineLength:ArtemisRpcBroker.kt$ArtemisRpcBroker.Companion$fun withSsl(configuration: MutualSslConfiguration, address: NetworkHostAndPort, adminAddress: NetworkHostAndPort, sslOptions: BrokerRpcSslOptions, securityManager: RPCSecurityManager, maxMessageSize: Int, jmxEnabled: Boolean, baseDirectory: Path, shouldStartLocalShell: Boolean): ArtemisBroker</ID>
    <ID>MaxLineLength:ArtemisRpcBroker.kt$ArtemisRpcBroker.Companion$fun withoutSsl(configuration: MutualSslConfiguration, address: NetworkHostAndPort, adminAddress: NetworkHostAndPort, securityManager: RPCSecurityManager, maxMessageSize: Int, jmxEnabled: Boolean, baseDirectory: Path, shouldStartLocalShell: Boolean): ArtemisBroker</ID>
    <ID>MaxLineLength:ArtemisRpcBroker.kt$ArtemisRpcBroker.Companion$return ArtemisRpcBroker(address, adminAddress, null, false, securityManager, maxMessageSize, jmxEnabled, baseDirectory, configuration, shouldStartLocalShell)</ID>
    <ID>MaxLineLength:ArtemisRpcBroker.kt$ArtemisRpcBroker.Companion$return ArtemisRpcBroker(address, adminAddress, sslOptions, true, securityManager, maxMessageSize, jmxEnabled, baseDirectory, configuration, shouldStartLocalShell)</ID>
    <ID>MaxLineLength:AsyncLoggerContextSelectorNoThreadLocal.kt$AsyncLoggerContextSelectorNoThreadLocal.Companion$return AsyncLoggerContextSelectorNoThreadLocal::class.java.name == PropertiesUtil.getProperties().getStringProperty(Constants.LOG4J_CONTEXT_SELECTOR)</ID>
    <ID>MaxLineLength:AttachmentStorageInternal.kt$AttachmentStorageInternal$ fun privilegedImportAttachment(jar: InputStream, uploader: String, filename: String?): AttachmentId</ID>
    <ID>MaxLineLength:AuditService.kt$AuditEvent</ID>
    <ID>MaxLineLength:AuditService.kt$FlowPermissionAuditEvent : AuditEventFlowAuditInfo</ID>
    <ID>MaxLineLength:AuthenticatedRpcOpsProxy.kt$AuthenticatedRpcOpsProxy$/** * Returns the RPC protocol version, which is the same the node's Platform Version. Exists since version 1 so guaranteed * to be present. * * TODO: Why is this logic duplicated vs the actual implementation? */ override val protocolVersion: Int get() = delegate.nodeInfo().platformVersion</ID>
    <ID>MaxLineLength:AuthenticatedRpcOpsProxy.kt$AuthenticatedRpcOpsProxy$internal</ID>
    <ID>MaxLineLength:AuthenticatedRpcOpsProxy.kt$AuthenticatedRpcOpsProxy$override</ID>
    <ID>MaxLineLength:AuthenticatedRpcOpsProxy.kt$AuthenticatedRpcOpsProxy.Companion$return Proxy.newProxyInstance(delegate::class.java.classLoader, arrayOf(InternalCordaRPCOps::class.java), handler) as InternalCordaRPCOps</ID>
    <ID>MaxLineLength:AuthenticatedRpcOpsProxy.kt$AuthenticatedRpcOpsProxy.PermissionsEnforcingInvocationHandler$override fun invoke(proxy: Any, method: Method, arguments: Array&lt;out Any?&gt;?)</ID>
    <ID>MaxLineLength:AuthenticatedRpcOpsProxy.kt$AuthenticatedRpcOpsProxy.PermissionsEnforcingInvocationHandler$private</ID>
    <ID>MaxLineLength:AuthenticatedRpcOpsProxy.kt$private</ID>
    <ID>MaxLineLength:AuthenticatedRpcOpsProxy.kt$private fun &lt;RESULT&gt; guard(methodName: String, context: () -&gt; RpcAuthContext, action: () -&gt; RESULT)</ID>
    <ID>MaxLineLength:BFTSmart.kt$BFTSmart</ID>
    <ID>MaxLineLength:BFTSmart.kt$BFTSmart$Client : SingletonSerializeAsToken</ID>
    <ID>MaxLineLength:BFTSmart.kt$BFTSmart$ClusterResponse</ID>
    <ID>MaxLineLength:BFTSmart.kt$BFTSmart.Client$ private fun buildExtractor(): Extractor</ID>
    <ID>MaxLineLength:BFTSmart.kt$BFTSmart.Client$log.debug { "BFT Client $clientId: number of replicas accepted the commit: ${accepted.size}, rejected: ${rejected.size}" }</ID>
    <ID>MaxLineLength:BFTSmart.kt$BFTSmart.Client$private val sessionTable = (proxy.communicationSystem as NettyClientServerCommunicationSystemClientSide).declaredField&lt;Map&lt;Int, NettyClientServerSession&gt;&gt;("sessionTable").value</ID>
    <ID>MaxLineLength:BFTSmart.kt$BFTSmart.Client${ // TODO: Hopefully we only need to wait for the client's initial connection to the cluster, and this method can be moved to some startup code. // TODO: Investigate ConcurrentModificationException in this method. while (true) { val inactive = sessionTable.entries.mapNotNull { if (it.value.channel.isActive) null else it.key } if (inactive.isEmpty()) break log.info("Client-replica channels not yet active: $clientId to $inactive") Thread.sleep((inactive.size * 100).toLong()) } }</ID>
    <ID>MaxLineLength:BFTSmart.kt$BFTSmart.CordaServiceReplica$private</ID>
    <ID>MaxLineLength:BFTSmart.kt$BFTSmart.Replica$checkConflict(conflictingStates, references, StateConsumptionDetails.ConsumedStateType.REFERENCE_INPUT_STATE)</ID>
    <ID>MaxLineLength:BFTSmart.kt$BFTSmart.Replica$private</ID>
    <ID>MaxLineLength:BFTSmart.kt$BFTSmart.Replica$val (committedStates, requests) = bytes.deserialize&lt;Pair&lt;LinkedHashMap&lt;StateRef, SecureHash&gt;, List&lt;PersistentUniquenessProvider.Request&gt;&gt;&gt;()</ID>
    <ID>MaxLineLength:BFTSmart.kt$BFTSmart.Replica$val criteriaQuery = session.criteriaBuilder.createQuery(PersistentUniquenessProvider.Request::class.java)</ID>
    <ID>MaxLineLength:BFTSmart.kt$BFTSmart.Replica$val deleteQuery = session.criteriaBuilder.createCriteriaDelete(PersistentUniquenessProvider.Request::class.java)</ID>
    <ID>MaxLineLength:BFTSmart.kt$BFTSmart.Replica$val signableData = SignableData(txId, SignatureMetadata(services.myInfo.platformVersion, Crypto.findSignatureScheme(notaryIdentityKey).schemeNumberID))</ID>
    <ID>MaxLineLength:BFTSmart.kt$BFTSmart.Replica.&lt;no name provided&gt;$if (exposeStartupRace) Thread.sleep(20000)</ID>
    <ID>MaxLineLength:BFTSmartConfigInternal.kt$BFTSmartConfigInternal : PathManager</ID>
    <ID>MaxLineLength:BFTSmartConfigInternal.kt$BFTSmartConfigInternal$val systemConfig = String.format(javaClass.getResource("system.config.printf").readText(), n, maxFaultyReplicas(n), if (debug) 1 else 0, (0 until n).joinToString(","))</ID>
    <ID>MaxLineLength:BFTSmartNotaryService.kt$BFTSmartNotaryService$?:</ID>
    <ID>MaxLineLength:BFTSmartNotaryService.kt$BFTSmartNotaryService$CommittedState : BaseComittedState</ID>
    <ID>MaxLineLength:BFTSmartNotaryService.kt$BFTSmartNotaryService$client</ID>
    <ID>MaxLineLength:BFTSmartNotaryService.kt$BFTSmartNotaryService$override fun createServiceFlow(otherPartySession: FlowSession): FlowLogic&lt;Void?&gt;</ID>
    <ID>MaxLineLength:BFTSmartNotaryService.kt$BFTSmartNotaryService.&lt;no name provided&gt;$log.warn("A BFT replica may still be initializing, in which case the upcoming consensus change may cause it to spin.")</ID>
    <ID>MaxLineLength:BFTSmartNotaryService.kt$BFTSmartNotaryService.Replica$createMap: () -&gt; AppendOnlyPersistentMap&lt;StateRef, SecureHash, CommittedState, PersistentStateRef&gt;</ID>
    <ID>MaxLineLength:BFTSmartNotaryService.kt$BFTSmartNotaryService.Replica$notaryIdentityKey: PublicKey</ID>
    <ID>MaxLineLength:BFTSmartNotaryService.kt$BFTSmartNotaryService.Replica$private</ID>
    <ID>MaxLineLength:BFTSmartNotaryService.kt$BFTSmartNotaryService.Replica$val response = verifyAndCommitTx(commitRequest.payload.coreTransaction, commitRequest.callerIdentity, commitRequest.payload.requestSignature)</ID>
    <ID>MaxLineLength:BFTSmartNotaryService.kt$BFTSmartNotaryService.ServiceFlow$private</ID>
    <ID>MaxLineLength:BFTSmartNotaryService.kt$BFTSmartNotaryService.ServiceFlow${ // TODO: here we assume that all error will be the same, but there might be invalid onces from mailicious nodes val responseError = response.errors.first().verified() throw NotaryException(responseError, payload.coreTransaction.id) }</ID>
    <ID>MaxLineLength:BasicHSMKeyManagementService.kt$BasicHSMKeyManagementService$"Metadata schemeCodeName: ${sigMetaData.schemeCodeName} is not aligned with the key type: ${sigKey.schemeCodeName}."</ID>
    <ID>MaxLineLength:BasicHSMKeyManagementService.kt$BasicHSMKeyManagementService$// Get [KeyPair] for the input [publicKey]. This is used for fresh keys, in which we have access to the private key material. private fun getSigningKeyPair(publicKey: PublicKey): KeyPair</ID>
    <ID>MaxLineLength:BasicHSMKeyManagementService.kt$BasicHSMKeyManagementService$private val pkToIdCache: WritablePublicKeyToOwningIdentityCache</ID>
    <ID>MaxLineLength:BasicHSMKeyManagementService.kt$BasicHSMKeyManagementService$require(it.private is AliasPrivateKey) { "${this.javaClass.name} supports AliasPrivateKeys only, but ${it.private.algorithm} key was found" }</ID>
    <ID>MaxLineLength:BasicHSMKeyManagementService.kt$BasicHSMKeyManagementService.Companion$fun createKeyMap(cacheFactory: NamedCacheFactory): AppendOnlyPersistentMap&lt;PublicKey, PrivateKey, PersistentKey, String&gt;</ID>
    <ID>MaxLineLength:BrokerJaasLoginModule.kt$BaseBrokerJaasLoginModule$override</ID>
    <ID>MaxLineLength:BrokerJaasLoginModule.kt$BrokerJaasLoginModule : BaseBrokerJaasLoginModule</ID>
    <ID>MaxLineLength:BrokerJaasLoginModule.kt$BrokerJaasLoginModule$CertificateChainCheckPolicy.LeafMustMatch.createCheck(nodeJaasConfig.keyStore, nodeJaasConfig.trustStore).checkCertificateChain(certificates!!)</ID>
    <ID>MaxLineLength:BrokerJaasLoginModule.kt$BrokerJaasLoginModule$CertificateChainCheckPolicy.RootMustMatch.createCheck(p2pJaasConfig!!.keyStore, p2pJaasConfig!!.trustStore).checkCertificateChain(certificates!!)</ID>
    <ID>MaxLineLength:BrokerJaasLoginModule.kt$BrokerJaasLoginModule$Pair(username, listOf(RolePrincipal(RPC_ROLE), RolePrincipal("${RPCApi.RPC_CLIENT_QUEUE_NAME_PREFIX}.$username")))</ID>
    <ID>MaxLineLength:BrokerJaasLoginModule.kt$BrokerJaasLoginModule$fun requireTls(certificates: Array&lt;X509Certificate&gt;?)</ID>
    <ID>MaxLineLength:BrokerJaasLoginModule.kt$BrokerJaasLoginModule$if (e is IllegalArgumentException &amp;&amp; e.stackTrace.any { it.className == "org.apache.activemq.artemis.protocol.amqp.sasl.PlainSASL" }) { log.trace("SASL Login failed.") } else { log.warn("Login failed: ${e.message}") }</ID>
    <ID>MaxLineLength:BrokerJaasLoginModule.kt$BrokerJaasLoginModule$override</ID>
    <ID>MaxLineLength:BrokerJaasLoginModule.kt$BrokerJaasLoginModule$private</ID>
    <ID>MaxLineLength:BrokerJaasLoginModule.kt$BrokerJaasLoginModule${ // This is a known problem, so we swallow this exception. A peer will attempt to connect without presenting client certificates during SASL if (e is IllegalArgumentException &amp;&amp; e.stackTrace.any { it.className == "org.apache.activemq.artemis.protocol.amqp.sasl.PlainSASL" }) { log.trace("SASL Login failed.") } else { log.warn("Login failed: ${e.message}") } if (e is LoginException) { throw e } else { throw FailedLoginException(e.message) } }</ID>
    <ID>MaxLineLength:BrokerJaasLoginModule.kt$RPCJaasConfig$val loginListener: LoginListener</ID>
    <ID>MaxLineLength:CertificateChainCheckPolicy.kt$CertificateChainCheckPolicy.UsernameMustMatchCommonNameCheck$if (!theirChain.any { certificate -&gt; CordaX500Name.parse(certificate.subjectDN.name).commonName == username }) { throw CertificateException("Client certificate does not match login username.") }</ID>
    <ID>MaxLineLength:CertificatesUtils.kt$fun saveToKeyStore(keyStorePath: Path, rpcKeyPair: KeyPair, selfSignCert: X509Certificate, password: String = "password", alias: String = "Key"): Path</ID>
    <ID>MaxLineLength:CertificatesUtils.kt$fun saveToTrustStore(trustStorePath: Path, selfSignCert: X509Certificate, password: String = "password", alias: String = "Key"): Path</ID>
    <ID>MaxLineLength:CertificatesUtils.kt$validityWindow: Pair&lt;Duration, Duration&gt; = X509Utilities.DEFAULT_VALIDITY_WINDOW</ID>
    <ID>MaxLineLength:CheckpointDumper.kt$CheckpointDumper</ID>
    <ID>MaxLineLength:CheckpointDumper.kt$CheckpointDumper$is WaitForStateConsumption -&gt; SuspendedOn(waitForStateConsumption = (operation as WaitForStateConsumption).stateRefs)</ID>
    <ID>MaxLineLength:CheckpointDumper.kt$CheckpointDumper$it.secondsSpentWaiting = TimeUnit.MILLISECONDS.toSeconds(Duration.between(suspendedTimestamp, now).toMillis())</ID>
    <ID>MaxLineLength:CheckpointDumper.kt$CheckpointDumper$serialisedCheckpoint.checkpointDeserialize(context = checkpointSerializationContext)</ID>
    <ID>MaxLineLength:CheckpointDumper.kt$CheckpointDumper$val file = baseDirectory / NodeStartup.LOGS_DIRECTORY_NAME / "checkpoints_dump-${TIME_FORMATTER.format(now)}.zip"</ID>
    <ID>MaxLineLength:CheckpointDumper.kt$CheckpointDumper${ // Poke into Quasar's stack and find the object references to the sub-flows so that we can correctly get the current progress // step for each sub-call. val stackObjects = fiber.getQuasarStack() subFlowStack.map { it.toJson(stackObjects) } }</ID>
    <ID>MaxLineLength:CheckpointDumper.kt$CheckpointDumper.AttachmentSerializer$override fun serialize(value: Attachment, gen: JsonGenerator, serializers: SerializerProvider)</ID>
    <ID>MaxLineLength:CheckpointDumper.kt$CheckpointDumper.CheckpointDumperBeanModifier$beanProperties: MutableList&lt;BeanPropertyWriter&gt;</ID>
    <ID>MaxLineLength:CheckpointDumper.kt$CheckpointDumper.CheckpointDumperBeanModifier$it.type.isTypeOrSubTypeOf(ProgressTracker::class.java) || it.name == "_stateMachine" || it.name == "deprecatedPartySessionMap"</ID>
    <ID>MaxLineLength:CheckpointDumper.kt$CheckpointDumper.CheckpointDumperBeanModifier${ // Do not serialise node singletons // TODO This will cause the singleton to appear as an empty object. Ideally we don't want it to appear at all but this will // have to do for now. beanProperties.clear() }</ID>
    <ID>MaxLineLength:CheckpointDumper.kt$CheckpointDumper.FlowLogicMixin$@JsonAutoDetect(getterVisibility = Visibility.NONE, isGetterVisibility = Visibility.NONE, fieldVisibility = Visibility.ANY)</ID>
    <ID>MaxLineLength:CheckpointVerifier.kt$CheckpointIncompatibleException$FlowVersionIncompatibleException : CheckpointIncompatibleException</ID>
    <ID>MaxLineLength:CheckpointVerifier.kt$CheckpointIncompatibleException$SubFlowCoreVersionIncompatibleException : CheckpointIncompatibleException</ID>
    <ID>MaxLineLength:CheckpointVerifier.kt$CheckpointIncompatibleException.CannotBeDeserialisedException$"Found checkpoint that cannot be deserialised using the current Corda version. Please revert to the previous version of Corda, "</ID>
    <ID>MaxLineLength:CheckpointVerifier.kt$CheckpointIncompatibleException.CannotBeDeserialisedException$"drain your node (see https://docs.corda.net/upgrading-cordapps.html#flow-drains), and try again. Cause: ${e.message}"</ID>
    <ID>MaxLineLength:CheckpointVerifier.kt$CheckpointIncompatibleException.CordappNotInstalledException$"Found checkpoint for CorDapp that is no longer installed. Specifically, could not find class $classNotFound. Please install the "</ID>
    <ID>MaxLineLength:CheckpointVerifier.kt$CheckpointIncompatibleException.CordappNotInstalledException$"missing CorDapp, drain your node (see https://docs.corda.net/upgrading-cordapps.html#flow-drains), and try again."</ID>
    <ID>MaxLineLength:CheckpointVerifier.kt$CheckpointIncompatibleException.FlowVersionIncompatibleException$"Found checkpoint for flow: $flowClass that is incompatible with the current installed version of ${cordapp.name}. "</ID>
    <ID>MaxLineLength:CheckpointVerifier.kt$CheckpointIncompatibleException.SubFlowCoreVersionIncompatibleException$"Found checkpoint for flow: $flowClass that is incompatible with the current Corda platform. Please revert to the previous "</ID>
    <ID>MaxLineLength:CheckpointVerifier.kt$CheckpointIncompatibleException.SubFlowCoreVersionIncompatibleException$"version of Corda (version $oldVersion), drain your node (see https://docs.corda.net/upgrading-cordapps.html#flow-drains), and try again."</ID>
    <ID>MaxLineLength:CheckpointVerifier.kt$CheckpointVerifier$private</ID>
    <ID>MaxLineLength:CheckpointVerifier.kt$CheckpointVerifier$throw CheckpointIncompatibleException.FlowVersionIncompatibleException(subFlow.flowClass, matchingCordapp, subFlowVersion.corDappHash)</ID>
    <ID>MaxLineLength:CheckpointVerifier.kt$CheckpointVerifier$throw CheckpointIncompatibleException.SubFlowCoreVersionIncompatibleException(subFlow.flowClass, subFlowVersion.platformVersion)</ID>
    <ID>MaxLineLength:CheckpointVerifier.kt$CheckpointVerifier${ // If we don't then see if the flow exists in any of the CorDapps so that we can give the user a more useful error message val matchingCordapp = currentCordappsByHash.values.find { subFlow.flowClass in it.allFlows } if (matchingCordapp != null) { throw CheckpointIncompatibleException.FlowVersionIncompatibleException(subFlow.flowClass, matchingCordapp, subFlowVersion.corDappHash) } else { throw CheckpointIncompatibleException.CordappNotInstalledException(subFlow.flowClass.name) } }</ID>
    <ID>MaxLineLength:ClearNetworkCacheCli.kt$ClearNetworkCacheCli : NodeCliCommand</ID>
    <ID>MaxLineLength:ConfigSections.kt$BFTSmartConfigSpec$return valid(BFTSmartConfig(configuration[replicaId], configuration[clusterAddresses], configuration[debug], configuration[exposeRaces]))</ID>
    <ID>MaxLineLength:ConfigSections.kt$CertChainPolicyConfigSpec$@Suppress("DEPRECATION") internal</ID>
    <ID>MaxLineLength:ConfigSections.kt$CertChainPolicyConfigSpec$return valid(CertChainPolicyConfig(configuration[role], configuration[policy], configuration[trustedAliases].toSet()))</ID>
    <ID>MaxLineLength:ConfigSections.kt$DatabaseConfigSpec$private val exportHibernateJMXStatistics by boolean().optional().withDefaultValue(DatabaseConfig.Defaults.exportHibernateJMXStatistics)</ID>
    <ID>MaxLineLength:ConfigSections.kt$DatabaseConfigSpec$private val initialiseAppSchema by enum(SchemaInitializationType::class).optional().withDefaultValue(DatabaseConfig.Defaults.initialiseAppSchema)</ID>
    <ID>MaxLineLength:ConfigSections.kt$DatabaseConfigSpec$private val mappedSchemaCacheSize by long().optional().withDefaultValue(DatabaseConfig.Defaults.mappedSchemaCacheSize)</ID>
    <ID>MaxLineLength:ConfigSections.kt$DatabaseConfigSpec$private val transactionIsolationLevel by enum(TransactionIsolationLevel::class).optional().withDefaultValue(DatabaseConfig.Defaults.transactionIsolationLevel)</ID>
    <ID>MaxLineLength:ConfigSections.kt$DatabaseConfigSpec$return valid(DatabaseConfig(configuration[initialiseSchema], configuration[initialiseAppSchema], configuration[transactionIsolationLevel], configuration[exportHibernateJMXStatistics], configuration[mappedSchemaCacheSize]))</ID>
    <ID>MaxLineLength:ConfigSections.kt$DevModeOptionsSpec$private val allowCompatibilityZone by boolean().optional().withDefaultValue(DevModeOptions.Defaults.allowCompatibilityZone)</ID>
    <ID>MaxLineLength:ConfigSections.kt$DevModeOptionsSpec$private val disableCheckpointChecker by boolean().optional().withDefaultValue(DevModeOptions.Defaults.disableCheckpointChecker)</ID>
    <ID>MaxLineLength:ConfigSections.kt$FlowTimeoutConfigurationSpec$internal</ID>
    <ID>MaxLineLength:ConfigSections.kt$FlowTimeoutConfigurationSpec$return valid(FlowTimeoutConfiguration(configuration[timeout], configuration[maxRestartCount], configuration[backoffBase]))</ID>
    <ID>MaxLineLength:ConfigSections.kt$NetworkServicesConfigSpec$internal</ID>
    <ID>MaxLineLength:ConfigSections.kt$NetworkServicesConfigSpec$return valid(NetworkServicesConfig(configuration[doormanURL], configuration[networkMapURL], configuration[pnm], configuration[inferred]))</ID>
    <ID>MaxLineLength:ConfigSections.kt$NodeRpcSettingsSpec$return valid(NodeRpcSettings(configuration[address], configuration[adminAddress], configuration[standAloneBroker], configuration[useSsl], configuration[ssl]))</ID>
    <ID>MaxLineLength:ConfigSections.kt$NotaryConfigSpec$private val etaMessageThresholdSeconds by int().optional().withDefaultValue(NotaryServiceFlow.defaultEstimatedWaitTime.seconds.toInt())</ID>
    <ID>MaxLineLength:ConfigSections.kt$NotaryConfigSpec$return valid(NotaryConfig(configuration[validating], configuration[serviceLegalName], configuration[className], configuration[etaMessageThresholdSeconds], configuration[extraConfig], configuration[raft], configuration[bftSMaRt]))</ID>
    <ID>MaxLineLength:ConfigSections.kt$SSHDConfigurationSpec$override fun parseValid(configuration: Config): Valid&lt;SSHDConfiguration&gt;</ID>
    <ID>MaxLineLength:ConfigSections.kt$SecurityConfigurationSpec$internal</ID>
    <ID>MaxLineLength:ConfigSections.kt$SecurityConfigurationSpec.AuthServiceSpec$dataSource.type == AuthDataSourceType.INMEMORY &amp;&amp; options?.cache != null -&gt; badValue("no cache supported for \"INMEMORY\" data provider")</ID>
    <ID>MaxLineLength:ConfigSections.kt$SecurityConfigurationSpec.AuthServiceSpec.DataSourceSpec$else -&gt; valid(SecurityConfiguration.AuthService.DataSource(type, passwordEncryption, connection, users))</ID>
    <ID>MaxLineLength:ConfigSections.kt$SecurityConfigurationSpec.AuthServiceSpec.DataSourceSpec$private</ID>
    <ID>MaxLineLength:ConfigSections.kt$SecurityConfigurationSpec.AuthServiceSpec.DataSourceSpec$private val passwordEncryption by enum(PasswordEncryption::class).optional().withDefaultValue(SecurityConfiguration.AuthService.DataSource.Defaults.passwordEncryption)</ID>
    <ID>MaxLineLength:ConfigSections.kt$SecurityConfigurationSpec.AuthServiceSpec.DataSourceSpec$type == AuthDataSourceType.DB &amp;&amp; (users != null || connection == null) -&gt; badValue("\"DB\" data source type requires \"connection\" and cannot specify \"users\"")</ID>
    <ID>MaxLineLength:ConfigSections.kt$SecurityConfigurationSpec.AuthServiceSpec.DataSourceSpec$type == AuthDataSourceType.INMEMORY &amp;&amp; (users == null || connection != null) -&gt; badValue("\"INMEMORY\" data source type requires \"users\" and cannot specify \"connection\"")</ID>
    <ID>MaxLineLength:ConfigSections.kt$SecurityConfigurationSpec.AuthServiceSpec.OptionsSpec.CacheSpec$private</ID>
    <ID>MaxLineLength:ConfigSections.kt$SecurityConfigurationSpec.AuthServiceSpec.OptionsSpec.CacheSpec$private val expireAfterSecs by long().mapValid { value -&gt; if (value &gt;= 0) validValue(value) else badValue("cannot be less than 0'") }</ID>
    <ID>MaxLineLength:ConfigSections.kt$SecurityConfigurationSpec.AuthServiceSpec.OptionsSpec.CacheSpec$private val maxEntries by long().mapValid { value -&gt; if (value &gt;= 0) validValue(value) else badValue("cannot be less than 0'") }</ID>
    <ID>MaxLineLength:ConfigSections.kt$SecurityConfigurationSpec.AuthServiceSpec.OptionsSpec.CacheSpec$return valid(SecurityConfiguration.AuthService.Options.Cache(configuration[expireAfterSecs], configuration[maxEntries]))</ID>
    <ID>MaxLineLength:ConfigUtilities.kt$ // TODO Move this to KeyStoreConfigHelpers. fun NodeConfiguration.configureWithDevSSLCertificate(cryptoService: CryptoService? = null)</ID>
    <ID>MaxLineLength:ConfigUtilities.kt$// TODO Move this to KeyStoreConfigHelpers. fun MutualSslConfiguration.configureDevKeyAndTrustStores(myLegalName: CordaX500Name, signingCertificateStore: FileBasedCertificateStoreSupplier, certificatesDirectory: Path, cryptoService: CryptoService? = null)</ID>
    <ID>MaxLineLength:ConfigUtilities.kt$ConfigHelper$configOf( // Add substitution values here "baseDirectory" to baseDirectory.toString()) .withFallback(configOverrides) .withFallback(systemOverrides) .withFallback(environmentOverrides) .withFallback(appConfig) .withFallback(devModeConfig)</ID>
    <ID>MaxLineLength:ConfigUtilities.kt$ConfigHelper$return ConfigFactory.parseMap(toProperties().filterKeys { (it as String).startsWith(CORDA_PROPERTY_PREFIX) }.mapKeys { (it.key as String).removePrefix(CORDA_PROPERTY_PREFIX) })</ID>
    <ID>MaxLineLength:ConfigUtilities.kt$ConfigHelper$val smartDevMode = CordaSystemUtils.isOsMac() || (CordaSystemUtils.isOsWindows() &amp;&amp; !CordaSystemUtils.getOsName().toLowerCase().contains("server"))</ID>
    <ID>MaxLineLength:ConfigUtilities.kt$ConfigHelper${ val parseOptions = ConfigParseOptions.defaults() val defaultConfig = ConfigFactory.parseResources("reference.conf", parseOptions.setAllowMissing(false)) val appConfig = ConfigFactory.parseFile(configFile.toFile(), parseOptions.setAllowMissing(allowMissingConfig)) // Detect the underlying OS. If mac or windows non-server then we assume we're running in devMode. Unless specified otherwise. val smartDevMode = CordaSystemUtils.isOsMac() || (CordaSystemUtils.isOsWindows() &amp;&amp; !CordaSystemUtils.getOsName().toLowerCase().contains("server")) val devModeConfig = ConfigFactory.parseMap(mapOf("devMode" to smartDevMode)) val systemOverrides = ConfigFactory.systemProperties().cordaEntriesOnly() val environmentOverrides = ConfigFactory.systemEnvironment().cordaEntriesOnly() val finalConfig = configOf( // Add substitution values here "baseDirectory" to baseDirectory.toString()) .withFallback(configOverrides) .withFallback(systemOverrides) .withFallback(environmentOverrides) .withFallback(appConfig) .withFallback(devModeConfig) // this needs to be after the appConfig, so it doesn't override the configured devMode .withFallback(defaultConfig) .resolve() val entrySet = finalConfig.entrySet().filter { entry -&gt; entry.key.contains("\"") } for ((key) in entrySet) { log.error("Config files should not contain \" in property names. Please fix: $key") } return finalConfig }</ID>
    <ID>MaxLineLength:ConfigUtilities.kt$setPrivateKey(it, serviceKeystore.getPrivateKey(it, DEV_CA_KEY_STORE_PASS), serviceKeystore.getCertificateChain(it), signingKeyStore.entryPassword)</ID>
    <ID>MaxLineLength:ConfigUtilities.kt$val signingKeyStore = FileBasedCertificateStoreSupplier(signingCertificateStore.path, signingCertificateStore.storePassword, signingCertificateStore.entryPassword).get(true) .also { it.installDevNodeCaCertPath(myLegalName) }</ID>
    <ID>MaxLineLength:ConfigUtilities.kt${ val signingKeyStore = FileBasedCertificateStoreSupplier(signingCertificateStore.path, signingCertificateStore.storePassword, signingCertificateStore.entryPassword).get(true) .also { it.installDevNodeCaCertPath(myLegalName) } // Move distributed service composite key (generated by IdentityGenerator.generateToDisk) to keystore if exists. val distributedServiceKeystore = certificatesDirectory / "distributedService.jks" if (distributedServiceKeystore.exists()) { val serviceKeystore = X509KeyStore.fromFile(distributedServiceKeystore, DEV_CA_KEY_STORE_PASS) signingKeyStore.update { serviceKeystore.aliases().forEach { if (serviceKeystore.internal.isKeyEntry(it)) { setPrivateKey(it, serviceKeystore.getPrivateKey(it, DEV_CA_KEY_STORE_PASS), serviceKeystore.getCertificateChain(it), signingKeyStore.entryPassword) } else { setCertificate(it, serviceKeystore.getCertificate(it)) } } } } }</ID>
    <ID>MaxLineLength:ContractUpgradeServiceImpl.kt$ContractUpgradeServiceImpl : ContractUpgradeServiceSingletonSerializeAsToken</ID>
    <ID>MaxLineLength:ContractUpgradeServiceImpl.kt$ContractUpgradeServiceImpl$override</ID>
    <ID>MaxLineLength:ContractUpgradeServiceImpl.kt$ContractUpgradeServiceImpl.Companion$fun createContractUpgradesMap(cacheFactory: NamedCacheFactory): PersistentMap&lt;String, String, DBContractUpgrade, String&gt;</ID>
    <ID>MaxLineLength:CordaClassResolver.kt$CordaClassResolver$// We don't allow the annotation for classes in attachments for now. The class will be on the main classpath if we have the CorDapp installed. // We also do not allow extension of KryoSerializable for annotated classes, or combination with @DefaultSerializer for custom serialisation. // TODO: Later we can support annotations on attachment classes and spin up a proxy via bytecode that we know is harmless. private fun checkForAnnotation(type: Class&lt;*&gt;): Boolean</ID>
    <ID>MaxLineLength:CordaClassResolver.kt$CordaClassResolver$if (type.isPrimitive || type == Any::class.java || type == String::class.java || (!type.isEnum &amp;&amp; isAbstract(type.modifiers))) return null</ID>
    <ID>MaxLineLength:CordaClassResolver.kt$CordaClassResolver$kotlin.jvm.internal.Lambda::class.java.isAssignableFrom(targetType)</ID>
    <ID>MaxLineLength:CordaClassResolver.kt$CordaClassResolver$throw KryoException("Class ${Util.className(type)} is not annotated or on the whitelist, so cannot be used in serialization")</ID>
    <ID>MaxLineLength:CordaClassResolver.kt$CordaClassResolver${ // If call path has disabled whitelisting (see [CordaKryo.register]), just return without checking. if (!whitelistEnabled) return null // If array, recurse on element type if (type.isArray) return checkClass(type.componentType) // Specialised enum entry, so just resolve the parent Enum type since cannot annotate the specialised entry. if (!type.isEnum &amp;&amp; Enum::class.java.isAssignableFrom(type)) return checkClass(type.superclass) // Allow primitives, abstracts and interfaces. Note that we can also create abstract Enum types, // but we don't want to whitelist those here. if (type.isPrimitive || type == Any::class.java || type == String::class.java || (!type.isEnum &amp;&amp; isAbstract(type.modifiers))) return null // It's safe to have the Class already, since Kryo loads it with initialisation off. // If we use a whitelist with blacklisting capabilities, whitelist.hasListed(type) may throw an IllegalStateException if input class is blacklisted. // Thus, blacklisting precedes annotation checking. if (!whitelist.hasListed(type) &amp;&amp; !checkForAnnotation(type)) { throw KryoException("Class ${Util.className(type)} is not annotated or on the whitelist, so cannot be used in serialization") } return null }</ID>
    <ID>MaxLineLength:CordaClassResolver.kt$CordaClassResolver${ val targetType = typeForSerializationOf(type) val objectInstance = targetType.kotlinObjectInstance // We have to set reference to true, since the flag influences how String fields are treated and we want it to be consistent. val references = kryo.references try { kryo.references = true val serializer = when { objectInstance != null -&gt; KotlinObjectSerializer(objectInstance) kotlin.jvm.internal.Lambda::class.java.isAssignableFrom(targetType) -&gt; // Kotlin lambdas extend this class and any captured variables are stored in synthetic fields FieldSerializer&lt;Any&gt;(kryo, targetType).apply { setIgnoreSyntheticFields(false) } Throwable::class.java.isAssignableFrom(targetType) -&gt; ThrowableSerializer(kryo, targetType) else -&gt; kryo.getDefaultSerializer(targetType) } return register(Registration(targetType, serializer, NAME.toInt())) } finally { kryo.references = references } }</ID>
    <ID>MaxLineLength:CordaClock.kt$CordaClock$@Deprecated("Do not use this. Instead seek to use ZonedDateTime methods.", level = DeprecationLevel.ERROR) override</ID>
    <ID>MaxLineLength:CordaClock.kt$MutableClock$ protected fun notifyMutationObservers()</ID>
    <ID>MaxLineLength:CordaClosureSerializer.kt$CordaClosureSerializer$const val ERROR_MESSAGE = "Unable to serialize Java Lambda expression, unless explicitly declared e.g., Runnable r = (Runnable &amp; Serializable) () -&gt; System.out.println(\"Hello world!\");"</ID>
    <ID>MaxLineLength:CordaMigration.kt$CordaMigration : CustomTaskChange</ID>
    <ID>MaxLineLength:CordaMigration.kt$CordaMigration$_servicesForResolution = MigrationServicesForResolution(identityService, attachmentsService, dbTransactions, cordaDB, cacheFactory)</ID>
    <ID>MaxLineLength:CordaMigration.kt$CordaMigration$return CordaPersistence(configDefaults, schema, jdbcUrl, cacheFactory, attributeConverters, closeConnection = false)</ID>
    <ID>MaxLineLength:CordaMigration.kt$CordaMigration${ val configDefaults = DatabaseConfig() val attributeConverters = listOf( PublicKeyToTextConverter(), AbstractPartyToX500NameAsStringConverter( identityService::wellKnownPartyFromX500Name, identityService::wellKnownPartyFromAnonymous) ) // Liquibase handles closing the database connection when migrations are finished. If the connection is closed here, then further // migrations may fail. return CordaPersistence(configDefaults, schema, jdbcUrl, cacheFactory, attributeConverters, closeConnection = false) }</ID>
    <ID>MaxLineLength:CordaRPCOpsImpl.kt$CordaRPCOpsImpl$/** * Returns the RPC protocol version, which is the same the node's platform Version. Exists since version 1 so guaranteed * to be present. */ override val protocolVersion: Int get() = nodeInfo().platformVersion</ID>
    <ID>MaxLineLength:CordaRPCOpsImpl.kt$CordaRPCOpsImpl$?:</ID>
    <ID>MaxLineLength:CordaRPCOpsImpl.kt$CordaRPCOpsImpl$contractStateType: Class&lt;out T&gt;</ID>
    <ID>MaxLineLength:CordaRPCOpsImpl.kt$CordaRPCOpsImpl$hash.serialize().sign { services.keyManagementService.sign(it.bytes, services.myInfo.legalIdentities[0].owningKey) }</ID>
    <ID>MaxLineLength:CordaRPCOpsImpl.kt$CordaRPCOpsImpl$is ConnectException -&gt; throw CordaRuntimeException("There is connection problem to network map. The possible causes are incorrect configuration or network map service being down")</ID>
    <ID>MaxLineLength:CordaRPCOpsImpl.kt$CordaRPCOpsImpl$is InvocationOrigin.Scheduled -&gt; FlowInitiator.Scheduled((origin as InvocationOrigin.Scheduled).scheduledState)</ID>
    <ID>MaxLineLength:CordaRPCOpsImpl.kt$CordaRPCOpsImpl$override</ID>
    <ID>MaxLineLength:CordaRPCOpsImpl.kt$CordaRPCOpsImpl$override fun internalFindVerifiedTransaction(txnId: SecureHash): SignedTransaction?</ID>
    <ID>MaxLineLength:CordaRPCOpsImpl.kt$CordaRPCOpsImpl$override fun killFlow(id: StateMachineRunId): Boolean</ID>
    <ID>MaxLineLength:CordaRPCOpsImpl.kt$CordaRPCOpsImpl$override fun registeredFlows(): List&lt;String&gt;</ID>
    <ID>MaxLineLength:CordaRPCOpsImpl.kt$CordaRPCOpsImpl$override fun setFlowsDrainingModeEnabled(enabled: Boolean)</ID>
    <ID>MaxLineLength:CordaRPCOpsImpl.kt$CordaRPCOpsImpl$pendingFlowsCount() .updates .doOnNext { (completed, total) -&gt; logger.info("Pending flows progress before shutdown: $completed / $total.") }</ID>
    <ID>MaxLineLength:CordaRPCOpsImpl.kt$CordaRPCOpsImpl$progress = stateMachine.logic.track()?.updates?.filter { !it.startsWith(STRUCTURAL_STEP_PREFIX) } ?: Observable.empty()</ID>
    <ID>MaxLineLength:CordaRPCOpsImpl.kt$CordaRPCOpsImpl$return StateMachineInfo(flowLogic.runId, flowLogic.javaClass.name, flowLogic.stateMachine.context.toFlowInitiator(), flowLogic.track(), flowLogic.stateMachine.context)</ID>
    <ID>MaxLineLength:CordaRPCOpsImpl.kt$CordaRPCOpsImpl$return vaultQueryBy(QueryCriteria.VaultQueryCriteria(), PageSpecification(), Sort(emptySet()), contractStateType)</ID>
    <ID>MaxLineLength:CordaRPCOpsImpl.kt$CordaRPCOpsImpl$return vaultTrackBy(QueryCriteria.VaultQueryCriteria(), PageSpecification(), Sort(emptySet()), contractStateType)</ID>
    <ID>MaxLineLength:CordaRPCOpsImpl.kt$CordaRPCOpsImpl$val wellKnownParty = services.identityService.wellKnownPartyFromX500Name((origin as InvocationOrigin.Peer).party)</ID>
    <ID>MaxLineLength:CordaRPCOpsImpl.kt$CordaRPCOpsImpl${ error -&gt; logger.error("Error while waiting for pending flows to drain in preparation for shutdown. Cause was: ${error.message}", error) }</ID>
    <ID>MaxLineLength:CordappProviderImpl.kt$CordappProviderImpl$private val attachmentStorage: AttachmentStorage</ID>
    <ID>MaxLineLength:CoreFlowHandlers.kt$ContractUpgradeHandler : Acceptor</ID>
    <ID>MaxLineLength:CoreFlowHandlers.kt$ContractUpgradeHandler$"The instigator is one of the participants" using (initiatingSession.counterparty in oldStateAndRef.state.data.participants)</ID>
    <ID>MaxLineLength:CoreFlowHandlers.kt$ContractUpgradeHandler$"The proposed upgrade ${proposal.modification.javaClass} is a trusted upgrade path" using (proposal.modification.name == authorisedUpgrade)</ID>
    <ID>MaxLineLength:CoreFlowHandlers.kt$ContractUpgradeHandler$@Suspendable override</ID>
    <ID>MaxLineLength:CoreFlowHandlers.kt$ContractUpgradeHandler$val authorisedUpgrade = checkNotNull(serviceHub.contractUpgradeService.getAuthorisedContractUpgrade(oldStateAndRef.ref)) { "Contract state upgrade is unauthorised. State hash : ${oldStateAndRef.ref}" }</ID>
    <ID>MaxLineLength:CoreFlowHandlers.kt$ContractUpgradeHandler$val expectedTx = ContractUpgradeUtils.assembleUpgradeTx(oldStateAndRef, proposal.modification, proposedTx.privacySalt, serviceHub)</ID>
    <ID>MaxLineLength:CoreFlowHandlers.kt$ContractUpgradeHandler${ // Retrieve signed transaction from our side, we will apply the upgrade logic to the transaction on our side, and // verify outputs matches the proposed upgrade. val ourSTX = requireNotNull(serviceHub.validatedTransactions.getTransaction(proposal.stateRef.txhash)) { "We don't have a copy of the referenced state" } val oldStateAndRef = ourSTX.resolveBaseTransaction(serviceHub).outRef&lt;ContractState&gt;(proposal.stateRef.index) val authorisedUpgrade = checkNotNull(serviceHub.contractUpgradeService.getAuthorisedContractUpgrade(oldStateAndRef.ref)) { "Contract state upgrade is unauthorised. State hash : ${oldStateAndRef.ref}" } val proposedTx = stx.coreTransaction as ContractUpgradeWireTransaction val expectedTx = ContractUpgradeUtils.assembleUpgradeTx(oldStateAndRef, proposal.modification, proposedTx.privacySalt, serviceHub) requireThat { "The instigator is one of the participants" using (initiatingSession.counterparty in oldStateAndRef.state.data.participants) "The proposed upgrade ${proposal.modification.javaClass} is a trusted upgrade path" using (proposal.modification.name == authorisedUpgrade) "The proposed tx matches the expected tx for this upgrade" using (proposedTx == expectedTx) } proposedTx.resolve(serviceHub, stx.sigs) }</ID>
    <ID>MaxLineLength:CoreFlowHandlers.kt$FinalityHandler$logger.warnOnce("Insecure API to record finalised transaction was used by ${sender.counterparty} (${sender.getCounterpartyFlowInfo()})")</ID>
    <ID>MaxLineLength:CoreFlowHandlers.kt$NotaryChangeHandler : Acceptor</ID>
    <ID>MaxLineLength:CoreFlowHandlers.kt$NotaryChangeHandler${ val state = proposal.stateRef val proposedTx = stx.resolveNotaryChangeTransaction(serviceHub) // TODO: Right now all nodes will automatically approve the notary change. We need to figure out if stricter controls are necessary. if (state !in proposedTx.inputs.map { it.ref }) { throw StateReplacementException("The proposed state $state is not in the proposed transaction inputs") } val newNotary = proposal.modification val isNotary = serviceHub.networkMapCache.isNotary(newNotary) if (!isNotary) { throw StateReplacementException("The proposed node $newNotary does not run a Notary service") } }</ID>
    <ID>MaxLineLength:DBNetworkParametersStorage.kt$DBNetworkParametersStorage$log.warn("Tried to download historical network parameters with hash $parametersHash, but network map url isn't configured")</ID>
    <ID>MaxLineLength:DBNetworkParametersStorage.kt$DBNetworkParametersStorage$override</ID>
    <ID>MaxLineLength:DBNetworkParametersStorage.kt$DBNetworkParametersStorage.Companion$PersistentNetworkParameters</ID>
    <ID>MaxLineLength:DBNetworkParametersStorage.kt$DBNetworkParametersStorage.Companion$fun createParametersMap(cacheFactory: NamedCacheFactory): AppendOnlyPersistentMap&lt;SecureHash, SignedDataWithCert&lt;NetworkParameters&gt;, PersistentNetworkParameters, String&gt;</ID>
    <ID>MaxLineLength:DBNetworkParametersStorage.kt$DBNetworkParametersStorage.PersistentNetworkParameters$( @Id @Column(name = "hash", length = MAX_HASH_HEX_SIZE, nullable = false) val hash: String = "", @Column(name = "epoch", nullable = false) val epoch: Int = 0, // Stored as serialized bytes because network parameters structure evolves over time. @Lob @Column(name = "parameters_bytes", nullable = false) val networkParametersBytes: ByteArray = ArrayUtils.EMPTY_BYTE_ARRAY, @Lob @Column(name = "signature_bytes", nullable = false) private val signature: ByteArray = ArrayUtils.EMPTY_BYTE_ARRAY, // First certificate in the certificate chain. @Lob @Column(name = "cert", nullable = false) private val certificate: ByteArray = ArrayUtils.EMPTY_BYTE_ARRAY, // Parent certificate path (the first one is stored separately), so node is agnostic to certificate hierarchy. @Lob @Column(name = "parent_cert_path", nullable = false) private val certPath: ByteArray = ArrayUtils.EMPTY_BYTE_ARRAY )</ID>
    <ID>MaxLineLength:DBNetworkParametersStorage.kt$DBNetworkParametersStorage.PersistentNetworkParameters$val signWithCert = DigitalSignatureWithCert(X509CertificateFactory().generateCertificate(certificate.inputStream()), certChain, signature)</ID>
    <ID>MaxLineLength:DBTransactionMappingStorage.kt$DBTransactionMappingStorage : StateMachineRecordedTransactionMappingStorage</ID>
    <ID>MaxLineLength:DBTransactionMappingStorage.kt$DBTransactionMappingStorage$cq.multiselect(from.get&lt;String&gt;(DBTransactionStorage.DBTransaction::stateMachineRunId.name), from.get&lt;String&gt;(DBTransactionStorage.DBTransaction::txId.name))</ID>
    <ID>MaxLineLength:DBTransactionMappingStorage.kt$DBTransactionMappingStorage$override</ID>
    <ID>MaxLineLength:DBTransactionMappingStorage.kt$DBTransactionMappingStorage$val flowIds = session.createQuery(cq).resultList.map { StateMachineTransactionMapping(StateMachineRunId(UUID.fromString(it[0] as String)), SecureHash.parse(it[1] as String)) }</ID>
    <ID>MaxLineLength:DBTransactionStorage.kt$DBTransactionStorage : WritableTransactionStorageSingletonSerializeAsToken</ID>
    <ID>MaxLineLength:DBTransactionStorage.kt$DBTransactionStorage$criteriaBuilder.equal(updateRoot.get&lt;TransactionStatus&gt;(DBTransaction::status.name), TransactionStatus.UNVERIFIED)</ID>
    <ID>MaxLineLength:DBTransactionStorage.kt$DBTransactionStorage$logger.debug { "Transaction ${transaction.id} is already recorded as verified, so no need to re-record" }</ID>
    <ID>MaxLineLength:DBTransactionStorage.kt$DBTransactionStorage.Companion$return if (effectiveSerializationEnv.serializationFactory.currentContext?.useCase == SerializationContext.UseCase.Storage) { effectiveSerializationEnv.serializationFactory.currentContext!! } else { SerializationDefaults.STORAGE_CONTEXT }</ID>
    <ID>MaxLineLength:DBTransactionStorage.kt$DBTransactionStorage.Companion$transaction = value.toSignedTx().serialize(context = contextToUse().withEncoding(SNAPPY)).bytes</ID>
    <ID>MaxLineLength:DBTransactionStorage.kt$DBTransactionStorage.TransactionStatus$UnexpectedStatusValueException : Exception</ID>
    <ID>MaxLineLength:DataSourceFactory.kt$DataSourceFactory$fun createDataSource(hikariProperties: Properties, pool: Boolean = true, metricRegistry: MetricRegistry? = null): DataSource</ID>
    <ID>MaxLineLength:DbExceptionHandler.kt$DbExceptionHandler : UncaughtExceptionHandler</ID>
    <ID>MaxLineLength:DbExceptionHandler.kt$DbExceptionHandler$errorAndTerminate("Thread ${t!!.name} failed due to database connection error. This is unrecoverable, terminating node.", e)</ID>
    <ID>MaxLineLength:DbTransactionsResolver.kt$DbTransactionsResolver$TopologicalSort</ID>
    <ID>MaxLineLength:DbTransactionsResolver.kt$DbTransactionsResolver$logger.debug { "Downloaded ${sortedDependencies?.size} dependencies from remote peer for transactions ${flow.txHashes}" }</ID>
    <ID>MaxLineLength:DbTransactionsResolver.kt$DbTransactionsResolver$val (existingTxIds, downloadedTxs) = fetchRequiredTransactions(Collections.singleton(nextRequests.first())) // Fetch first item only</ID>
    <ID>MaxLineLength:DbTransactionsResolver.kt$DbTransactionsResolver$val nextRequests = LinkedHashSet&lt;SecureHash&gt;(flow.txHashes) // Keep things unique but ordered, for unit test stability.</ID>
    <ID>MaxLineLength:DbTransactionsResolver.kt$DbTransactionsResolver${ // Don't re-download the same tx when we haven't verified it yet but it's referenced multiple times in the // graph we're traversing. nextRequests.removeAll(topologicalSort.transactionIds) if (nextRequests.isEmpty()) { // Done early. break } // Request the standalone transaction data (which may refer to things we don't yet have). val (existingTxIds, downloadedTxs) = fetchRequiredTransactions(Collections.singleton(nextRequests.first())) // Fetch first item only for (tx in downloadedTxs) { val dependencies = tx.dependencies topologicalSort.add(tx.id, dependencies) } var suspended = true for (downloaded in downloadedTxs) { suspended = false val dependencies = downloaded.dependencies // Do not keep in memory as this bloats the checkpoint. Write each item to the database. transactionStorage.addUnverifiedTransaction(downloaded) // The write locks are only released over a suspend, so need to keep track of whether the flow has been suspended to ensure // that locks are not held beyond each while loop iteration (as doing this would result in a deadlock due to claiming locks // in the wrong order) val suspendedViaAttachments = flow.fetchMissingAttachments(downloaded) val suspendedViaParams = flow.fetchMissingNetworkParameters(downloaded) suspended = suspended || suspendedViaAttachments || suspendedViaParams // Add all input states and reference input states to the work queue. nextRequests.addAll(dependencies) } // If the flow did not suspend on the last iteration of the downloaded loop above, perform a suspend here to ensure no write // locks are held going into the next while loop iteration. if (!suspended) { FlowLogic.sleep(0.seconds) } // It's possible that the node has a transaction in storage already. Dependencies should also be present for this transaction, // so just remove these IDs from the set of next requests. nextRequests.removeAll(existingTxIds) }</ID>
    <ID>MaxLineLength:DbTransactionsResolver.kt$DbTransactionsResolver${ suspended = false val dependencies = downloaded.dependencies // Do not keep in memory as this bloats the checkpoint. Write each item to the database. transactionStorage.addUnverifiedTransaction(downloaded) // The write locks are only released over a suspend, so need to keep track of whether the flow has been suspended to ensure // that locks are not held beyond each while loop iteration (as doing this would result in a deadlock due to claiming locks // in the wrong order) val suspendedViaAttachments = flow.fetchMissingAttachments(downloaded) val suspendedViaParams = flow.fetchMissingNetworkParameters(downloaded) suspended = suspended || suspendedViaAttachments || suspendedViaParams // Add all input states and reference input states to the work queue. nextRequests.addAll(dependencies) }</ID>
    <ID>MaxLineLength:DbTransactionsResolver.kt$DbTransactionsResolver.TopologicalSort$// Note that we use a LinkedHashSet here to make the traversal deterministic (as long as the input list is). val deDupeIt = dedupe(it) forwardGraph.computeIfAbsent(deDupeIt) { LinkedHashSet() }.add(txId)</ID>
    <ID>MaxLineLength:DeduplicationId.kt$SenderDeduplicationId</ID>
    <ID>MaxLineLength:DefaultKryoCustomizer.kt$DefaultKryoCustomizer$// Store a little schema of field names in the stream the first time a class is used which increases tolerance // for change to a class. setDefaultSerializer(CompatibleFieldSerializer::class.java) // Take the safest route here and allow subclasses to have fields named the same as super classes. fieldSerializerConfig.cachedFieldNameStrategy = FieldSerializer.CachedFieldNameStrategy.EXTENDED instantiatorStrategy = CustomInstantiatorStrategy() // Required for HashCheckingStream (de)serialization. // Note that return type should be specifically set to InputStream, otherwise it may not work, i.e. val aStream : InputStream = HashCheckingStream(...). addDefaultSerializer(InputStream::class.java, InputStreamSerializer) addDefaultSerializer(SerializeAsToken::class.java, SerializeAsTokenSerializer&lt;SerializeAsToken&gt;()) addDefaultSerializer(Logger::class.java, LoggerSerializer) addDefaultSerializer(X509Certificate::class.java, X509CertificateSerializer) // WARNING: reordering the registrations here will cause a change in the serialized form, since classes // with custom serializers get written as registration ids. This will break backwards-compatibility. // Please add any new registrations to the end. // TODO: re-organise registrations into logical groups before v1.0 register(Arrays.asList("").javaClass, ArraysAsListSerializer()) register(LazyMappedList::class.java, LazyMappedListSerializer) register(SignedTransaction::class.java, SignedTransactionSerializer) register(WireTransaction::class.java, WireTransactionSerializer) register(SerializedBytes::class.java, SerializedBytesSerializer) UnmodifiableCollectionsSerializer.registerSerializers(this) ImmutableListSerializer.registerSerializers(this) ImmutableSetSerializer.registerSerializers(this) ImmutableSortedSetSerializer.registerSerializers(this) ImmutableMapSerializer.registerSerializers(this) ImmutableMultimapSerializer.registerSerializers(this) // InputStream subclasses whitelisting, required for attachments. register(BufferedInputStream::class.java, InputStreamSerializer) register(Class.forName("sun.net.www.protocol.jar.JarURLConnection\$JarURLInputStream"), InputStreamSerializer) noReferencesWithin&lt;WireTransaction&gt;() register(ECPublicKeyImpl::class.java, publicKeySerializer) register(EdDSAPublicKey::class.java, publicKeySerializer) register(EdDSAPrivateKey::class.java, PrivateKeySerializer) register(CompositeKey::class.java, publicKeySerializer) // Using a custom serializer for compactness // Exceptions. We don't bother sending the stack traces as the client will fill in its own anyway. register(Array&lt;StackTraceElement&gt;::class, read = { _, _ -&gt; emptyArray() }, write = { _, _, _ -&gt; }) // This ensures a NonEmptySetSerializer is constructed with an initial value. register(NonEmptySet::class.java, NonEmptySetSerializer) register(BitSet::class.java, BitSetSerializer()) register(Class::class.java, ClassSerializer) register(FileInputStream::class.java, InputStreamSerializer) register(CertPath::class.java, CertPathSerializer) register(X509CertPath::class.java, CertPathSerializer) register(BCECPrivateKey::class.java, PrivateKeySerializer) register(BCECPublicKey::class.java, publicKeySerializer) register(BCRSAPrivateCrtKey::class.java, PrivateKeySerializer) register(BCRSAPublicKey::class.java, publicKeySerializer) register(BCSphincs256PrivateKey::class.java, PrivateKeySerializer) register(BCSphincs256PublicKey::class.java, publicKeySerializer) register(NotaryChangeWireTransaction::class.java, NotaryChangeWireTransactionSerializer) register(PartyAndCertificate::class.java, PartyAndCertificateSerializer) // Don't deserialize PrivacySalt via its default constructor. register(PrivacySalt::class.java, PrivacySaltSerializer) // Used by the remote verifier, and will possibly be removed in future. register(ContractAttachment::class.java, ContractAttachmentSerializer) register(java.lang.invoke.SerializedLambda::class.java) register(ClosureSerializer.Closure::class.java, CordaClosureBlacklistSerializer) register(ContractUpgradeWireTransaction::class.java, ContractUpgradeWireTransactionSerializer) register(ContractUpgradeFilteredTransaction::class.java, ContractUpgradeFilteredTransactionSerializer) for (whitelistProvider in serializationWhitelists) { val types = whitelistProvider.whitelist require(types.toSet().size == types.size) { val duplicates = types.toMutableList() types.toSet().forEach { duplicates -= it } "Cannot add duplicate classes to the whitelist ($duplicates)." } for (type in types) { ((kryo.classResolver as? CordaClassResolver)?.whitelist as? MutableClassWhitelist)?.add(type) } }</ID>
    <ID>MaxLineLength:DefaultKryoCustomizer.kt$DefaultKryoCustomizer$register(Class.forName("sun.net.www.protocol.jar.JarURLConnection\$JarURLInputStream"), InputStreamSerializer)</ID>
    <ID>MaxLineLength:DefaultKryoCustomizer.kt$DefaultKryoCustomizer.ContractAttachmentSerializer$return ContractAttachment.create(lazyAttachment, contract, additionalContracts, uploader, signers, version)</ID>
    <ID>MaxLineLength:DefaultKryoCustomizer.kt$DefaultKryoCustomizer.CustomInstantiatorStrategy$val strat = if (type.name.startsWith("java.") &amp;&amp; !isPublic(type.modifiers)) fallbackStrategy else defaultStrategy</ID>
    <ID>MaxLineLength:DeliverSessionMessageTransition.kt$DeliverSessionMessageTransition$Action.SendExisting(initiatedSession.peerParty, existingMessage, SenderDeduplicationId(deduplicationId, startingState.senderUUID))</ID>
    <ID>MaxLineLength:DeliverSessionMessageTransition.kt$DeliverSessionMessageTransition$is FlowException -&gt; DeclaredField&lt;Party?&gt;(FlowException::class.java, "peer", exception).value = sessionState.peerParty</ID>
    <ID>MaxLineLength:DeliverSessionMessageTransition.kt$DeliverSessionMessageTransition$pendingDeduplicationHandlers = currentState.pendingDeduplicationHandlers + event.deduplicationHandler</ID>
    <ID>MaxLineLength:DeliverSessionMessageTransition.kt$DeliverSessionMessageTransition$sessions = checkpoint.sessions + (sessionId to sessionState.copy(rejectionError = flowError))</ID>
    <ID>MaxLineLength:DeliverSessionMessageTransition.kt$DeliverSessionMessageTransition$sessions = currentState.checkpoint.sessions + (event.sessionMessage.recipientSessionId to initiatedSession)</ID>
    <ID>MaxLineLength:DeliverSessionMessageTransition.kt$DeliverSessionMessageTransition$sessions = startingState.checkpoint.sessions + (event.sessionMessage.recipientSessionId to newSessionState)</ID>
    <ID>MaxLineLength:DumpHistoryOnErrorInterceptor.kt$DumpHistoryOnErrorInterceptor$val (continuation, nextState) = delegate.executeTransition(fiber, previousState, event, transition, actionExecutor)</ID>
    <ID>MaxLineLength:DumpHistoryOnErrorInterceptor.kt$DumpHistoryOnErrorInterceptor$val transitionRecord = TransitionDiagnosticRecord(Instant.now(), fiber.id, previousState, nextState, event, transition, continuation)</ID>
    <ID>MaxLineLength:DumpHistoryOnErrorInterceptor.kt$DumpHistoryOnErrorInterceptor${ val (continuation, nextState) = delegate.executeTransition(fiber, previousState, event, transition, actionExecutor) val transitionRecord = TransitionDiagnosticRecord(Instant.now(), fiber.id, previousState, nextState, event, transition, continuation) val record = records.compute(fiber.id) { _, record -&gt; (record ?: ArrayList()).apply { add(transitionRecord) } } // Just if we decide to propagate, and not if just on the way to the hospital. Only log at debug level here - the flow transition // information is often unhelpful in the logs, and the actual cause of the problem will be logged elsewhere. if (nextState.checkpoint.errorState is ErrorState.Errored &amp;&amp; nextState.checkpoint.errorState.propagating) { log.warn("Flow ${fiber.id} errored, dumping all transitions:\n${record!!.joinToString("\n")}") for (error in nextState.checkpoint.errorState.errors) { log.warn("Flow ${fiber.id} error", error.exception) } } if (nextState.isRemoved) { records.remove(fiber.id) } return Pair(continuation, nextState) }</ID>
    <ID>MaxLineLength:E2ETestKeyManagementService.kt$E2ETestKeyManagementService : SingletonSerializeAsTokenKeyManagementServiceInternal</ID>
    <ID>MaxLineLength:E2ETestKeyManagementService.kt$E2ETestKeyManagementService$getPrivateKey((privateKey as AliasPrivateKey).alias, cryptoService.certificateStore.entryPassword)</ID>
    <ID>MaxLineLength:E2ETestKeyManagementService.kt$E2ETestKeyManagementService$throw UnsupportedOperationException("This operation is only supported by persistent key management service variants.")</ID>
    <ID>MaxLineLength:ErrorFlowTransition.kt$ErrorFlowTransition$val (initiatedSessions, newSessions) = bufferErrorMessagesInInitiatingSessions(startingState.checkpoint.sessions, errorMessages)</ID>
    <ID>MaxLineLength:Event.kt$Event$GeneratedByExternalEvent</ID>
    <ID>MaxLineLength:Event.kt$Event$RetryFlowFromSafePoint : Event</ID>
    <ID>MaxLineLength:Event.kt$Event.EnterSubFlow$data</ID>
    <ID>MaxLineLength:ExceptionMaskingRpcOpsProxy.kt$ExceptionMaskingRpcOpsProxy$internal</ID>
    <ID>MaxLineLength:ExceptionMaskingRpcOpsProxy.kt$ExceptionMaskingRpcOpsProxy.Companion$return newProxyInstance(delegate::class.java.classLoader, arrayOf(InternalCordaRPCOps::class.java), handler) as InternalCordaRPCOps</ID>
    <ID>MaxLineLength:ExceptionMaskingRpcOpsProxy.kt$ExceptionMaskingRpcOpsProxy.ErrorObfuscatingInvocationHandler$private</ID>
    <ID>MaxLineLength:ExceptionMaskingRpcOpsProxy.kt$ExceptionMaskingRpcOpsProxy.ErrorObfuscatingInvocationHandler$val exposed = if (error.isWhitelisted()) error else InternalNodeException((error as? IdentifiableException)?.errorId)</ID>
    <ID>MaxLineLength:ExceptionSerialisingRpcOpsProxy.kt$ExceptionSerialisingRpcOpsProxy$internal</ID>
    <ID>MaxLineLength:ExceptionSerialisingRpcOpsProxy.kt$ExceptionSerialisingRpcOpsProxy.Companion$return newProxyInstance(delegate::class.java.classLoader, arrayOf(InternalCordaRPCOps::class.java), handler) as InternalCordaRPCOps</ID>
    <ID>MaxLineLength:ExceptionSerialisingRpcOpsProxy.kt$ExceptionSerialisingRpcOpsProxy.ErrorSerialisingInvocationHandler$private</ID>
    <ID>MaxLineLength:ExceptionSerialisingRpcOpsProxy.kt$ExceptionSerialisingRpcOpsProxy.ErrorSerialisingInvocationHandler$val serialisable = (superclasses(error::class.java) + error::class.java).any { it.isAnnotationPresent(CordaSerializable::class.java) || it.interfaces.any { it.isAnnotationPresent(CordaSerializable::class.java) } }</ID>
    <ID>MaxLineLength:FiberDeserializationCheckingInterceptor.kt$FiberDeserializationCheckingInterceptor$val (continuation, nextState) = delegate.executeTransition(fiber, previousState, event, transition, actionExecutor)</ID>
    <ID>MaxLineLength:FiberUtils.kt$// TODO: This method uses a built-in Quasar function to make a map of all ThreadLocals. This is probably inefficient, but the only API readily available. fun &lt;V, T&gt; Fiber&lt;V&gt;.swappedOutThreadLocalValue(threadLocal: ThreadLocal&lt;T&gt;): T?</ID>
    <ID>MaxLineLength:FiberUtils.kt$private val fiberThreadLocalsField: Field = Fiber::class.java.getDeclaredField("fiberLocals").apply { this.isAccessible = true }</ID>
    <ID>MaxLineLength:FlowLogicRefFactoryImpl.kt$FlowLogicRefFactoryImpl : SingletonSerializeAsTokenFlowLogicRefFactory</ID>
    <ID>MaxLineLength:FlowLogicRefFactoryImpl.kt$FlowLogicRefFactoryImpl$if (ref !is FlowLogicRefImpl) throw IllegalFlowLogicException(ref.javaClass, "FlowLogicRef was not created via correct FlowLogicRefFactory interface")</ID>
    <ID>MaxLineLength:FlowLogicRefFactoryImpl.kt$FlowLogicRefFactoryImpl$open</ID>
    <ID>MaxLineLength:FlowLogicRefFactoryImpl.kt$FlowLogicRefFactoryImpl$private</ID>
    <ID>MaxLineLength:FlowLogicRefFactoryImpl.kt$FlowLogicRefFactoryImpl$protected open</ID>
    <ID>MaxLineLength:FlowLogicRefFactoryImpl.kt$FlowLogicRefFactoryImpl$return (value is Any &amp;&amp; parameterAssignableFrom(parameter.type.javaType, value)) || parameter.type.isMarkedNullable</ID>
    <ID>MaxLineLength:FlowLogicRefFactoryImpl.kt$FlowLogicRefImpl$@CordaSerializable data</ID>
    <ID>MaxLineLength:FlowManager.kt$FlowManager</ID>
    <ID>MaxLineLength:FlowManager.kt$FlowManager$fun registerInitiatedCoreFlowFactory(initiatingFlowClass: KClass&lt;out FlowLogic&lt;*&gt;&gt;, flowFactory: (FlowSession) -&gt; FlowLogic&lt;*&gt;)</ID>
    <ID>MaxLineLength:FlowManager.kt$FlowManager$fun registerInitiatedCoreFlowFactory(initiatingFlowClass: KClass&lt;out FlowLogic&lt;*&gt;&gt;, initiatedFlowClass: KClass&lt;out FlowLogic&lt;*&gt;&gt;?, flowFactory: (FlowSession) -&gt; FlowLogic&lt;*&gt;)</ID>
    <ID>MaxLineLength:FlowManager.kt$FlowManager$fun registerInitiatedCoreFlowFactory(initiatingFlowClass: KClass&lt;out FlowLogic&lt;*&gt;&gt;, initiatedFlowClass: KClass&lt;out FlowLogic&lt;*&gt;&gt;?, flowFactory: InitiatedFlowFactory.Core&lt;FlowLogic&lt;*&gt;&gt;)</ID>
    <ID>MaxLineLength:FlowManager.kt$NodeFlowManager$"${InitiatingFlow::class.java.name}.version not applicable for core flows; their version is the node's platform version"</ID>
    <ID>MaxLineLength:FlowManager.kt$NodeFlowManager$// To verify the integrity of the current state, it is important that the tip of the responders is a unique weight // if there are multiple flows with the same weight as the tip, it means that it is impossible to reliably pick one as the responder private fun validateInvariants(toValidate: List&lt;RegisteredFlowContainer&gt;)</ID>
    <ID>MaxLineLength:FlowManager.kt$NodeFlowManager$@Synchronized override</ID>
    <ID>MaxLineLength:FlowManager.kt$NodeFlowManager$FlowWeightComparator : Comparator</ID>
    <ID>MaxLineLength:FlowManager.kt$NodeFlowManager$log</ID>
    <ID>MaxLineLength:FlowManager.kt$NodeFlowManager$log.warn("Multiple flows are registered for InitiatingFlow: $initiatingFlowClass, currently using: ${listOfFlowsForInitiator.first().initiatedFlowClass}")</ID>
    <ID>MaxLineLength:FlowManager.kt$NodeFlowManager$registerInitiatedCoreFlowFactory(initiatingFlowClass, initiatedFlowClass, InitiatedFlowFactory.Core(flowFactory))</ID>
    <ID>MaxLineLength:FlowManager.kt$NodeFlowManager$throw IllegalArgumentException("$responder must have a constructor accepting a ${FlowSession::class.java.name}")</ID>
    <ID>MaxLineLength:FlowManager.kt$NodeFlowManager$val equalWeightAsCurrentTip = toValidate.map { flowWeightComparator.compare(currentTip, it) to it }.filter { it.first == 0 }.map { it.second }</ID>
    <ID>MaxLineLength:FlowManager.kt$NodeFlowManager$val flowToAdd = RegisteredFlowContainer(initiatingFlowClass, initiatedFlowClass, flowFactory, FlowType.CORDAPP)</ID>
    <ID>MaxLineLength:FlowManager.kt$NodeFlowManager$val message = "Unable to determine which flow to use when responding to: ${currentTip.initiatingFlowClass.canonicalName}. ${equalWeightAsCurrentTip.map { it.initiatedFlowClass!!.canonicalName }} are all registered with equal weight."</ID>
    <ID>MaxLineLength:FlowManager.kt$NodeFlowManager.FlowWeightComparator$override</ID>
    <ID>MaxLineLength:FlowManager.kt$NodeFlowManager.FlowWeightComparator$private open</ID>
    <ID>MaxLineLength:FlowMessaging.kt$FlowMessagingImpl$@Suspendable override</ID>
    <ID>MaxLineLength:FlowMessaging.kt$FlowMessagingImpl$val mightDeadlockDrainingTarget = FlowStateMachineImpl.currentStateMachine()?.context?.origin.let { it is InvocationOrigin.Peer &amp;&amp; it.party == target.name }</ID>
    <ID>MaxLineLength:FlowMessaging.kt$FlowMessagingImpl$val networkMessage = serviceHub.networkService.createMessage(sessionTopic, serializeSessionMessage(message).bytes, deduplicationId, message.additionalHeaders(party))</ID>
    <ID>MaxLineLength:FlowMessaging.kt$FlowMessagingImpl$val wellKnown = requireNotNull(serviceHub.identityService.wellKnownPartyFromAnonymous(destination as AnonymousParty)) { "We do not know who $destination belongs to" }</ID>
    <ID>MaxLineLength:FlowMessaging.kt$FlowMessagingImpl${ // Handling Kryo and AMQP serialization problems. Unfortunately the two exception types do not share much of a common exception interface. if ((exception is KryoException || exception is NotSerializableException) &amp;&amp; message is ExistingSessionMessage &amp;&amp; message.payload is ErrorSessionMessage) { val error = message.payload.flowException val rewrappedError = FlowException(error?.message) message.copy(payload = message.payload.copy(flowException = rewrappedError)).serialize() } else { throw exception } }</ID>
    <ID>MaxLineLength:FlowMessaging.kt$FlowMessagingImpl${ // This prevents a "deadlock" in case an initiated flow tries to start a session against a draining node that is also the initiator. // It does not help in case more than 2 nodes are involved in a circle, so the kill switch via RPC should be used in that case. val mightDeadlockDrainingTarget = FlowStateMachineImpl.currentStateMachine()?.context?.origin.let { it is InvocationOrigin.Peer &amp;&amp; it.party == target.name } return when { this !is InitialSessionMessage || mightDeadlockDrainingTarget -&gt; emptyMap() else -&gt; mapOf(P2PMessagingHeaders.Type.KEY to P2PMessagingHeaders.Type.SESSION_INIT_VALUE) } }</ID>
    <ID>MaxLineLength:FlowMonitor.kt$FlowMonitor$flow.ioRequest()?.let { request -&gt; warningMessageForFlowWaitingOnIo(request, flow, now) }?.let(logger::info)</ID>
    <ID>MaxLineLength:FlowMonitor.kt$FlowMonitor$is FlowIORequest.ExecuteAsyncOperation -&gt; "for asynchronous operation of type ${request.operation::javaClass} to complete"</ID>
    <ID>MaxLineLength:FlowMonitor.kt$FlowMonitor$is FlowIORequest.GetFlowInfo -&gt; "to get flow information from parties ${request.sessions.partiesInvolved()}"</ID>
    <ID>MaxLineLength:FlowMonitor.kt$FlowMonitor$is FlowIORequest.Send -&gt; "to send a message to parties ${request.sessionToMessage.keys.partiesInvolved()}"</ID>
    <ID>MaxLineLength:FlowMonitor.kt$FlowMonitor$is FlowIORequest.SendAndReceive -&gt; "to send and receive messages from parties ${request.sessionToMessage.keys.partiesInvolved()}"</ID>
    <ID>MaxLineLength:FlowMonitor.kt$FlowMonitor$is FlowIORequest.Sleep -&gt; "to wake up from sleep ending at ${LocalDateTime.ofInstant(request.wakeUpAfter, ZoneId.systemDefault())}"</ID>
    <ID>MaxLineLength:FlowMonitor.kt$FlowMonitor$is FlowIORequest.WaitForLedgerCommit -&gt; "for the ledger to commit transaction with hash ${request.hash}"</ID>
    <ID>MaxLineLength:FlowMonitor.kt$FlowMonitor$private</ID>
    <ID>MaxLineLength:FlowMonitor.kt$FlowMonitor$private fun FlowStateMachineImpl&lt;*&gt;.ioRequest()</ID>
    <ID>MaxLineLength:FlowMonitor.kt$FlowMonitor$scheduler!!.scheduleAtFixedRate({ logFlowsWaitingForParty(suspensionLoggingThreshold) }, 0, monitoringPeriod.toMillis(), TimeUnit.MILLISECONDS)</ID>
    <ID>MaxLineLength:FlowMonitor.kt$FlowMonitor$val message = StringBuilder("Flow with id ${flow.id.uuid} has been waiting for ${flow.ongoingDuration(now).toMillis() / 1000} seconds ")</ID>
    <ID>MaxLineLength:FlowSessionImpl.kt$FlowSessionImpl$@Suspendable override</ID>
    <ID>MaxLineLength:FlowSessionImpl.kt$FlowSessionImpl$override fun equals(other: Any?): Boolean</ID>
    <ID>MaxLineLength:FlowSessionImpl.kt$FlowSessionImpl$val responseValues: Map&lt;FlowSession, SerializedBytes&lt;Any&gt;&gt; = flowStateMachine.suspend(request, maySkipCheckpoint)</ID>
    <ID>MaxLineLength:FlowStateMachineImpl.kt$"${InitiatingFlow::class.java.name}. See https://docs.corda.net/api-flows.html#flowlogic-annotations."</ID>
    <ID>MaxLineLength:FlowStateMachineImpl.kt$?:</ID>
    <ID>MaxLineLength:FlowStateMachineImpl.kt$FlowStateMachineImpl$"Transaction context is missing. This might happen if a suspendable method is not annotated with @Suspendable annotation."</ID>
    <ID>MaxLineLength:FlowStateMachineImpl.kt$FlowStateMachineImpl$/** * Return the logger for this state machine. The logger name incorporates [id] and so including it in the log message * is not necessary. */ override val logger = log</ID>
    <ID>MaxLineLength:FlowStateMachineImpl.kt$FlowStateMachineImpl$@Suspendable private</ID>
    <ID>MaxLineLength:FlowStateMachineImpl.kt$FlowStateMachineImpl$Thread.currentThread().contextClassLoader = (serviceHub.cordappProvider as CordappProviderImpl).cordappLoader.appClassLoader</ID>
    <ID>MaxLineLength:FlowStateMachineImpl.kt$FlowStateMachineImpl$errorAndTerminate("Caught unrecoverable error from flow. Forcibly terminating the JVM, this might leave resources open, and most likely will.", t)</ID>
    <ID>MaxLineLength:FlowStateMachineImpl.kt$FlowStateMachineImpl$require(continuation == FlowContinuation.ProcessEvents) { "Expected a continuation of type ${FlowContinuation.ProcessEvents}, found $continuation " }</ID>
    <ID>MaxLineLength:FlowStateMachineImpl.kt$FlowStateMachineImpl$require(destination is Party || destination is AnonymousParty) { "Unsupported destination type ${destination.javaClass.name}" }</ID>
    <ID>MaxLineLength:FlowStateMachineImpl.kt$FlowStateMachineImpl$throw FlowPermissionException("User ${context.principal()} not permissioned for $permissionName on flow $id")</ID>
    <ID>MaxLineLength:FlowStateMachineImpl.kt$FlowStateMachineImpl$val (continuation, newState) = transitionExecutor.executeTransition(this, oldState, event, transition, actionExecutor)</ID>
    <ID>MaxLineLength:FlowStateMachineImpl.kt$FlowStateMachineImpl$val permissionGranted = true // TODO define permission control service on ServiceHubInternal and actually check authorization.</ID>
    <ID>MaxLineLength:FlowStateMachineImpl.kt$FlowStateMachineImpl$val serializationContext = TransientReference(getTransientField(TransientValues::checkpointSerializationContext))</ID>
    <ID>MaxLineLength:FlowStateMachineImpl.kt$FlowStateMachineImpl${ // This sets the Cordapp classloader on the contextClassLoader of the current thread. // Needed because in previous versions of the finance app we used Thread.contextClassLoader to resolve services defined in cordapps. Thread.currentThread().contextClassLoader = (serviceHub.cordappProvider as CordappProviderImpl).cordappLoader.appClassLoader val result = logic.call() suspend(FlowIORequest.WaitForSessionConfirmations, maySkipCheckpoint = true) Try.Success(result) }</ID>
    <ID>MaxLineLength:FlowStateMachineImpl.kt$FlowStateMachineImpl.Companion$private val SERIALIZER_BLOCKER = Fiber::class.java.getDeclaredField("SERIALIZER_BLOCKER").apply { isAccessible = true }.get(null)</ID>
    <ID>MaxLineLength:FlowStateMachineImpl.kt$if (found != null) throw IllegalArgumentException("${InitiatingFlow::class.java.name} can only be annotated once")</ID>
    <ID>MaxLineLength:GenerateNodeInfoCli.kt$GenerateNodeInfoCli : NodeCliCommand</ID>
    <ID>MaxLineLength:GenerateRpcSslCertsCli.kt$GenerateRpcSslCerts$println("You need to distribute this file along with the password in a secure way to all RPC clients.")</ID>
    <ID>MaxLineLength:GenerateRpcSslCertsCli.kt$GenerateRpcSslCertsCli : NodeCliCommand</ID>
    <ID>MaxLineLength:HTTPNetworkRegistrationService.kt$HTTPNetworkRegistrationService$HTTP_UNAUTHORIZED -&gt; throw CertificateRequestException("Certificate signing request has been rejected: ${conn.errorMessage}")</ID>
    <ID>MaxLineLength:HTTPNetworkRegistrationService.kt$HTTPNetworkRegistrationService$else -&gt; throw IOException("Error while connecting to the Doorman. Http response status code was ${conn.responseCode}.")</ID>
    <ID>MaxLineLength:HTTPNetworkRegistrationService.kt$HTTPNetworkRegistrationService$in TRANSIENT_ERROR_STATUS_CODES -&gt; throw ServiceUnavailableException("Could not connect with Doorman. Http response status code was ${conn.responseCode}.")</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$AbstractQueryCriteriaParser$LIKE_IGNORE_CASE -&gt; criteriaBuilder.like(criteriaBuilder.upper(column), columnPredicate.rightLiteral.toUpperCase())</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$AbstractQueryCriteriaParser$NOT_IN_IGNORE_CASE -&gt; criteriaBuilder.not(criteriaBuilder.upper(column).`in`(literal.map { it.toUpperCase() }))</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$AbstractQueryCriteriaParser$NOT_LIKE_IGNORE_CASE -&gt; criteriaBuilder.notLike(criteriaBuilder.upper(column), columnPredicate.rightLiteral.toUpperCase())</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$AbstractQueryCriteriaParser$abstract</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$AbstractQueryCriteriaParser$private</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateAttachmentQueryCriteriaParser$AbstractQueryCriteriaParser&lt;AttachmentQueryCriteria, AttachmentsQueryCriteriaParser, AttachmentSort&gt;(), AttachmentsQueryCriteriaParser</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateAttachmentQueryCriteriaParser$Sort.Direction.DESC -&gt; orderCriteria.add(criteriaBuilder.desc(root.get&lt;String&gt;(sortAttribute.columnName)))</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateAttachmentQueryCriteriaParser$private val criteriaQuery: CriteriaQuery&lt;NodeAttachmentService.DBAttachment&gt;</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateAttachmentQueryCriteriaParser$val joinDBAttachmentToContractClassNames = root.joinList&lt;NodeAttachmentService.DBAttachment, ContractClassName&gt;("contractClassNames")</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$Sort.Direction.ASC -&gt; criteriaBuilder.asc(criteriaBuilder.literal&lt;Int&gt;(orderByColumnPosition - shiftLeft))</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$Sort.Direction.DESC -&gt; criteriaBuilder.desc(criteriaBuilder.literal&lt;Int&gt;(orderByColumnPosition - shiftLeft))</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$Triple(VaultSchemaV1.VaultStates::class.java, sortAttribute.attributeParent, sortAttribute.attributeChild)</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$commonPredicates.replace(predicateID, criteriaBuilder.and(vaultStates.get&lt;String&gt;(VaultSchemaV1.VaultStates::contractStateClassName.name).`in`(contractStateTypes.plus(existingTypes))))</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$commonPredicates.replace(predicateID, criteriaBuilder.and(vaultStates.get&lt;Vault.ConstraintInfo.Type&gt;(VaultSchemaV1.VaultStates::constraintType.name).`in`(criteria.constraintTypes.plus(existingTypes))))</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$commonPredicates.replace(predicateID, criteriaBuilder.equal(vaultStates.get&lt;Vault.RelevancyStatus&gt;(VaultSchemaV1.VaultStates::relevancyStatus.name), criteria.relevancyStatus))</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$commonPredicates.replace(predicateID, criteriaBuilder.equal(vaultStates.get&lt;Vault.StateStatus&gt;(VaultSchemaV1.VaultStates::stateStatus.name), criteria.status))</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$commonPredicates[predicateID] = criteriaBuilder.and(vaultStates.get&lt;String&gt;(VaultSchemaV1.VaultStates::contractStateClassName.name).`in`(contractStateTypes))</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$commonPredicates[predicateID] = criteriaBuilder.and(vaultStates.get&lt;Vault.ConstraintInfo.Type&gt;(VaultSchemaV1.VaultStates::constraintType.name).`in`(criteria.constraintTypes))</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$commonPredicates[predicateID] = criteriaBuilder.equal(vaultStates.get&lt;Vault.RelevancyStatus&gt;(VaultSchemaV1.VaultStates::relevancyStatus.name), criteria.relevancyStatus)</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$commonPredicates[predicateID] = criteriaBuilder.equal(vaultStates.get&lt;Vault.StateStatus&gt;(VaultSchemaV1.VaultStates::stateStatus.name), criteria.status)</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$criteriaBuilder.equal(vaultStates.get&lt;PersistentStateRef&gt;("stateRef"), entityRoot.get&lt;IndirectStatePersistable&lt;*&gt;&gt;("compositeKey").get&lt;PersistentStateRef&gt;("stateRef"))</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$criteriaBuilder.equal(vaultStates.get&lt;PersistentStateRef&gt;("stateRef"), entityRoot.get&lt;PersistentStateRef&gt;("stateRef"))</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$elem</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$if (path is SingularAttributePath) //remove the same columns from different joins to match the single column in 'group by' only (from the last join) aggregateExpressions.removeAll { elem -&gt; if (elem is SingularAttributePath) elem.attribute.javaMember == path.attribute.javaMember else false }</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$is SortAttribute.Custom -&gt; Triple(sortAttribute.entityStateClass, sortAttribute.entityStateColumnName, null)</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$log.warn("Enriching previous attribute [${VaultSchemaV1.VaultStates::constraintType.name}] values [$existingTypes] with [${criteria.constraintTypes}]")</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$log.warn("Enriching previous attribute [${VaultSchemaV1.VaultStates::contractStateClassName.name}] values [$existingTypes] with [$contractStateTypes]")</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$log.warn("Overriding previous attribute [${VaultSchemaV1.VaultStates::relevancyStatus.name}] value $existingStatus with ${criteria.status}")</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$log.warn("Overriding previous attribute [${VaultSchemaV1.VaultStates::stateStatus.name}] value $existingStatus with ${criteria.status}")</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$orderCriteria.add(criteriaBuilder.asc(sortEntityRoot.get&lt;String&gt;(entityStateAttributeParent).get&lt;String&gt;(entityStateAttributeChild)))</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$orderCriteria.add(criteriaBuilder.desc(sortEntityRoot.get&lt;String&gt;(entityStateAttributeParent).get&lt;String&gt;(entityStateAttributeChild)))</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$override</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$predicateSet.add(criteriaBuilder.and(vaultStates.get&lt;String&gt;("lockId").`in`(softLocking.lockIds.map { it.toString() })))</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$private</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$private val commonPredicates = mutableMapOf&lt;Pair&lt;String, Operator&gt;, Predicate&gt;() // schema attribute Name, operator -&gt; predicate</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$shiftLeft += columnNumberBeforeRemoval - aggregateExpressions.size</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$sorting.copy(columns = sorting.columns + Sort.SortColumn(SortAttribute.Standard(Sort.CommonStateAttribute.STATE_REF), Sort.Direction.ASC))</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$val actualSorting = if (sorting.columns.none { it.sortAttribute == SortAttribute.Standard(Sort.CommonStateAttribute.STATE_REF) }) { sorting.copy(columns = sorting.columns + Sort.SortColumn(SortAttribute.Standard(Sort.CommonStateAttribute.STATE_REF), Sort.Direction.ASC)) } else { sorting }</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$val combinedPredicates = commonPredicates.values.plus(predicateSet).plus(constraintPredicates).plus(joinPredicates)</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$val existingStatus = ((commonPredicates[predicateID] as ComparisonPredicate).rightHandOperand as LiteralExpression).literal</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$val existingTypes = (commonPredicates[predicateID]!!.expressions[0] as InPredicate&lt;*&gt;).values.map { (it as LiteralExpression).literal }.toSet()</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$val externalIdJoin = criteriaBuilder.equal(vaultStates.get&lt;VaultSchemaV1.VaultStates&gt;("stateRef"), entityRoot.get&lt;VaultSchemaV1.StateToExternalId&gt;("compositeKey").get&lt;PersistentStateRef&gt;("stateRef"))</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$val externalIdPredicate = criteriaBuilder.and(entityRoot.get&lt;VaultSchemaV1.StateToExternalId&gt;("externalId").`in`(ids))</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$val joinPredicate = criteriaBuilder.equal(vaultStates.get&lt;PersistentStateRef&gt;("stateRef"), entityRoot.get&lt;PersistentStateRef&gt;("stateRef"))</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$val joinPredicate = criteriaBuilder.equal(vaultStates.get&lt;PersistentStateRef&gt;("stateRef"), vaultFungibleStates.get&lt;PersistentStateRef&gt;("stateRef"))</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$val joinPredicate = criteriaBuilder.equal(vaultStates.get&lt;PersistentStateRef&gt;("stateRef"), vaultLinearStates.get&lt;PersistentStateRef&gt;("stateRef"))</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$val participantsPredicate = criteriaBuilder.and(entityRoot.get&lt;VaultSchemaV1.PersistentParty&gt;("x500Name").`in`(participants))</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$val predicateConstraintData = criteriaBuilder.equal(vaultStates.get&lt;Vault.ConstraintInfo&gt;(VaultSchemaV1.VaultStates::constraintData.name), constraint.data())</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$val predicateConstraintType = criteriaBuilder.equal(vaultStates.get&lt;Vault.ConstraintInfo&gt;(VaultSchemaV1.VaultStates::constraintType.name), constraint.type())</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$val statePartyJoin = criteriaBuilder.equal(vaultStates.get&lt;VaultSchemaV1.VaultStates&gt;("stateRef"), entityRoot.get&lt;VaultSchemaV1.PersistentParty&gt;("compositeKey").get&lt;PersistentStateRef&gt;("stateRef"))</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$val vaultStates: Root&lt;VaultSchemaV1.VaultStates&gt;</ID>
    <ID>MaxLineLength:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser${ @Suppress("UNCHECKED_CAST") column as Path&lt;Long?&gt;? val aggregateExpression = when (columnPredicate.type) { AggregateFunctionType.SUM -&gt; criteriaBuilder.sum(column) AggregateFunctionType.AVG -&gt; criteriaBuilder.avg(column) AggregateFunctionType.COUNT -&gt; criteriaBuilder.count(column) AggregateFunctionType.MAX -&gt; criteriaBuilder.max(column) AggregateFunctionType.MIN -&gt; criteriaBuilder.min(column) } //TODO investigate possibility to avoid producing redundant joins in SQL for multiple aggregate functions against the same table aggregateExpressions.add(aggregateExpression) // Some databases may not support aggregate expression in 'group by' clause e.g. 'group by sum(col)', // Hibernate Criteria Builder can't produce alias 'group by col_alias', and the only solution is to use a positional parameter 'group by 1' val orderByColumnPosition = aggregateExpressions.size var shiftLeft = 0 // add optional group by clauses expression.groupByColumns?.let { columns -&gt; val groupByExpressions = columns.map { _column -&gt; val path = root.get&lt;Any?&gt;(getColumnName(_column)) val columnNumberBeforeRemoval = aggregateExpressions.size if (path is SingularAttributePath) //remove the same columns from different joins to match the single column in 'group by' only (from the last join) aggregateExpressions.removeAll { elem -&gt; if (elem is SingularAttributePath) elem.attribute.javaMember == path.attribute.javaMember else false } shiftLeft += columnNumberBeforeRemoval - aggregateExpressions.size //record how many times a duplicated column was removed (from the previous 'parseAggregateFunction' run) aggregateExpressions.add(path) path } criteriaQuery.groupBy(groupByExpressions) } // optionally order by this aggregate function expression.orderBy?.let { val orderCriteria = when (expression.orderBy!!) { // when adding column position of 'group by' shift in case columns were removed Sort.Direction.ASC -&gt; criteriaBuilder.asc(criteriaBuilder.literal&lt;Int&gt;(orderByColumnPosition - shiftLeft)) Sort.Direction.DESC -&gt; criteriaBuilder.desc(criteriaBuilder.literal&lt;Int&gt;(orderByColumnPosition - shiftLeft)) } criteriaQuery.orderBy(orderCriteria) } return aggregateExpression }</ID>
    <ID>MaxLineLength:HospitalisingInterceptor.kt$HospitalisingInterceptor : TransitionExecutor</ID>
    <ID>MaxLineLength:HospitalisingInterceptor.kt$HospitalisingInterceptor$val (continuation, nextState) = delegate.executeTransition(fiber, previousState, event, transition, actionExecutor)</ID>
    <ID>MaxLineLength:IdentityServiceInternal.kt$IdentityServiceInternal$ @Throws(CertificateExpiredException::class, CertificateNotYetValidException::class, InvalidAlgorithmParameterException::class) fun verifyAndRegisterIdentity(identity: PartyAndCertificate, isNewRandomIdentity: Boolean): PartyAndCertificate?</ID>
    <ID>MaxLineLength:IdentityServiceInternal.kt$IdentityServiceInternal$ @Throws(CertificateExpiredException::class, CertificateNotYetValidException::class, InvalidAlgorithmParameterException::class) fun verifyAndRegisterIdentity(trustAnchor: TrustAnchor, identity: PartyAndCertificate, isNewRandomIdentity: Boolean = false): PartyAndCertificate?</ID>
    <ID>MaxLineLength:IdentityServiceInternal.kt$IdentityServiceInternal$ fun justVerifyAndRegisterIdentity(identity: PartyAndCertificate, isNewRandomIdentity: Boolean = false)</ID>
    <ID>MaxLineLength:IdentityServiceInternal.kt$IdentityServiceInternal$@Throws(CertificateExpiredException::class, CertificateNotYetValidException::class, InvalidAlgorithmParameterException::class)</ID>
    <ID>MaxLineLength:IdentityServiceInternal.kt$IdentityServiceInternal$log.warn("Certificate validation failed for ${identity.name} against trusted root ${trustAnchor.trustedCert.subjectX500Principal}.")</ID>
    <ID>MaxLineLength:IdentityServiceInternal.kt$IdentityServiceInternal$val components = listOfNotNull(x500name.commonName, x500name.organisationUnit, x500name.organisation, x500name.locality, x500name.state, x500name.country)</ID>
    <ID>MaxLineLength:IdentityServiceInternal.kt$IdentityServiceInternal${ private companion object { val log = contextLogger() } /** This method exists so it can be mocked with doNothing, rather than having to make up a possibly invalid return value. */ fun justVerifyAndRegisterIdentity(identity: PartyAndCertificate, isNewRandomIdentity: Boolean = false) { verifyAndRegisterIdentity(identity, isNewRandomIdentity) } /** * Verify and then store an identity. * * @param identity a party and the certificate path linking them to the network trust root. * @param isNewRandomIdentity true if the identity will not have been registered before (e.g. because it is randomly generated by ourselves). * @return the issuing entity, if known. * @throws IllegalArgumentException if the certificate path is invalid. */ @Throws(CertificateExpiredException::class, CertificateNotYetValidException::class, InvalidAlgorithmParameterException::class) fun verifyAndRegisterIdentity(identity: PartyAndCertificate, isNewRandomIdentity: Boolean): PartyAndCertificate? // We can imagine this being a query over a lucene index in future. // // Kostas says: When exactMatch = false, we can easily use the Jaro-Winkler distance metric as it is best suited for short // strings such as entity/company names, and to detect small typos. We can also apply it for city // or any keyword related search in lists of records (not raw text - for raw text we need indexing) // and we can return results in hierarchical order (based on normalised String similarity 0.0-1.0). /** Check if [x500name] matches the [query]. */ fun x500Matches(query: String, exactMatch: Boolean, x500name: CordaX500Name): Boolean { val components = listOfNotNull(x500name.commonName, x500name.organisationUnit, x500name.organisation, x500name.locality, x500name.state, x500name.country) return components.any { (exactMatch &amp;&amp; it == query) || (!exactMatch &amp;&amp; it.contains(query, ignoreCase = true)) } } /** * Verifies that an identity is valid. * * @param trustAnchor The trust anchor that will verify the identity's validity * @param identity The identity to verify * @param isNewRandomIdentity true if the identity will not have been registered before (e.g. because it is randomly generated by ourselves). */ @Throws(CertificateExpiredException::class, CertificateNotYetValidException::class, InvalidAlgorithmParameterException::class) fun verifyAndRegisterIdentity(trustAnchor: TrustAnchor, identity: PartyAndCertificate, isNewRandomIdentity: Boolean = false): PartyAndCertificate? { // Validate the chain first, before we do anything clever with it val identityCertChain = identity.certPath.x509Certificates try { identity.verify(trustAnchor) } catch (e: CertPathValidatorException) { log.warn("Certificate validation failed for ${identity.name} against trusted root ${trustAnchor.trustedCert.subjectX500Principal}.") log.warn("Certificate path :") identityCertChain.reversed().forEachIndexed { index, certificate -&gt; val space = (0 until index).joinToString("") { " " } log.warn("$space${certificate.subjectX500Principal}") } throw e } // Ensure we record the first identity of the same name, first val wellKnownCert = identityCertChain.single { CertRole.extract(it)?.isWellKnown ?: false } if (wellKnownCert != identity.certificate &amp;&amp; !isNewRandomIdentity) { val idx = identityCertChain.lastIndexOf(wellKnownCert) val firstPath = X509Utilities.buildCertPath(identityCertChain.slice(idx until identityCertChain.size)) verifyAndRegisterIdentity(trustAnchor, PartyAndCertificate(firstPath)) } return registerIdentity(identity, isNewRandomIdentity) } fun registerIdentity(identity: PartyAndCertificate, isNewRandomIdentity: Boolean = false): PartyAndCertificate? }</ID>
    <ID>MaxLineLength:InMemoryIdentityService.kt$InMemoryIdentityService$@Throws(CertificateExpiredException::class, CertificateNotYetValidException::class, InvalidAlgorithmParameterException::class)</ID>
    <ID>MaxLineLength:InMemoryIdentityService.kt$InMemoryIdentityService$@Throws(CertificateExpiredException::class, CertificateNotYetValidException::class, InvalidAlgorithmParameterException::class) private</ID>
    <ID>MaxLineLength:InMemoryIdentityService.kt$InMemoryIdentityService$log.warn("Certificate validation failed for ${identity.name} against trusted root ${trustAnchor.trustedCert.subjectX500Principal}.")</ID>
    <ID>MaxLineLength:InMemoryIdentityService.kt$InMemoryIdentityService$override</ID>
    <ID>MaxLineLength:InMemoryIdentityService.kt$InMemoryIdentityService$results += keyToPartyAndCerts[key]?.party ?: throw IllegalArgumentException("Could not find an entry in the database for the public key $key.")</ID>
    <ID>MaxLineLength:InMemoryTransactionVerifierService.kt$InMemoryTransactionVerifierService : SingletonSerializeAsTokenTransactionVerifierServiceTransactionVerifierServiceInternalAutoCloseable</ID>
    <ID>MaxLineLength:InfrequentlyMutatedCache.kt$InfrequentlyMutatedCache$ fun get(key: K, valueGetter: (K) -&gt; V): V</ID>
    <ID>MaxLineLength:InfrequentlyMutatedCache.kt$InfrequentlyMutatedCache$// This protects against the cache purging something that is marked as invalid and thus we "forget" it shouldn't be cached. private val currentlyInvalid = ConcurrentHashMap&lt;K, Wrapper.Invalidated&lt;V&gt;&gt;()</ID>
    <ID>MaxLineLength:InfrequentlyMutatedCache.kt$InfrequentlyMutatedCache&lt;K : Any, V : Any&gt;</ID>
    <ID>MaxLineLength:InitialRegistrationCli.kt$InitialRegistration : RunAfterNodeInitialisationNodeStartupLogging</ID>
    <ID>MaxLineLength:InitialRegistrationCli.kt$InitialRegistration$e.logAsUnexpected( "Could not delete the marker file that was created for `initial-registration`.", print = logger::warn)</ID>
    <ID>MaxLineLength:InitialRegistrationCli.kt$InitialRegistration$println("Node was started before with `--initial-registration`, but the registration was not completed.\nResuming registration.")</ID>
    <ID>MaxLineLength:InitialRegistrationCli.kt$InitialRegistration$println("Successfully registered Corda node with compatibility zone, node identity keys and certificates are stored in '${conf.certificatesDirectory}', it is advised to backup the private keys and certificates.")</ID>
    <ID>MaxLineLength:InitialRegistrationCli.kt$InitialRegistration$require(networkRootTrustStorePath.exists()) { "Network root trust store path: '$networkRootTrustStorePath' doesn't exist" }</ID>
    <ID>MaxLineLength:InitialRegistrationCli.kt$InitialRegistration${ // Null checks for [compatibilityZoneURL], [rootTruststorePath] and [rootTruststorePassword] has been done in [CmdLineOptions.loadConfig] attempt { registerWithNetwork(config) }.doOnFailure(Consumer(this::handleRegistrationError)) as Try.Success // At this point the node registration was successful. We can delete the marker file. deleteNodeRegistrationMarker(baseDirectory) }</ID>
    <ID>MaxLineLength:InitialRegistrationCli.kt$InitialRegistrationCli : CliWrapperBase</ID>
    <ID>MaxLineLength:InitialRegistrationCli.kt$InitialRegistrationCli$@Option(names = ["-p", "--network-root-truststore-password"], description = ["Network root trust store password obtained from network operator."], required = true)</ID>
    <ID>MaxLineLength:InitialRegistrationCli.kt$InitialRegistrationCli$@Option(names = ["-t", "--network-root-truststore"], description = ["Network root trust store obtained from network operator."])</ID>
    <ID>MaxLineLength:InitialRegistrationCli.kt$InitialRegistrationCli$return startup.initialiseAndRun(cmdLineOptions, InitialRegistration(cmdLineOptions.baseDirectory, networkRootTrustStorePath, networkRootTrustStorePassword, startup))</ID>
    <ID>MaxLineLength:InitialRegistrationCli.kt$InitialRegistrationCli$val networkRootTrustStorePath: Path = networkRootTrustStorePathParameter ?: cmdLineOptions.baseDirectory / "certificates" / "network-root-truststore.jks"</ID>
    <ID>MaxLineLength:InternalRPCMessagingClient.kt$InternalRPCMessagingClient : SingletonSerializeAsTokenAutoCloseable</ID>
    <ID>MaxLineLength:InternalRPCMessagingClient.kt$InternalRPCMessagingClient$fun init(rpcOps: RPCOps, securityManager: RPCSecurityManager, cacheFactory: NamedCacheFactory)</ID>
    <ID>MaxLineLength:InternalRPCMessagingClient.kt$InternalRPCMessagingClient$rpcServer = RPCServer(rpcOps, NODE_RPC_USER, NODE_RPC_USER, locator!!, securityManager, nodeName, rpcServerConfiguration, cacheFactory)</ID>
    <ID>MaxLineLength:JarScanningCordappLoader.kt$CordappLoaderTemplate$"${entry.value.first().first.name}: [ ${entry.value.joinToString { it.second.jarPath.toString() }} ]."</ID>
    <ID>MaxLineLength:JarScanningCordappLoader.kt$CordappLoaderTemplate$throw MultipleCordappsForFlowException("There are multiple CorDapp JARs on the classpath for flow " + "${entry.value.first().first.name}: [ ${entry.value.joinToString { it.second.jarPath.toString() }} ].")</ID>
    <ID>MaxLineLength:JarScanningCordappLoader.kt$JarScanningCordappLoader$"platform version ${it.minimumPlatformVersion} (This node is running version ${versionInfo.platformVersion})."</ID>
    <ID>MaxLineLength:JarScanningCordappLoader.kt$JarScanningCordappLoader$?:</ID>
    <ID>MaxLineLength:JarScanningCordappLoader.kt$JarScanningCordappLoader$RestrictedURL</ID>
    <ID>MaxLineLength:JarScanningCordappLoader.kt$JarScanningCordappLoader$contractInfo != null &amp;&amp; workflowInfo != null -&gt; return Cordapp.Info.ContractAndWorkflow(contractInfo, workflowInfo)</ID>
    <ID>MaxLineLength:JarScanningCordappLoader.kt$JarScanningCordappLoader$it.javaClass.location == cordappJarPath.url &amp;&amp; it.javaClass.name.startsWith(cordappJarPath.qualifiedNamePrefix)</ID>
    <ID>MaxLineLength:JarScanningCordappLoader.kt$JarScanningCordappLoader$logger</ID>
    <ID>MaxLineLength:JarScanningCordappLoader.kt$JarScanningCordappLoader$override val appClassLoader: URLClassLoader = URLClassLoader(cordappJarPaths.stream().map { it.url }.toTypedArray(), javaClass.classLoader)</ID>
    <ID>MaxLineLength:JarScanningCordappLoader.kt$JarScanningCordappLoader$private val signerKeyFingerprintBlacklist: List&lt;SecureHash.SHA256&gt; = emptyList()</ID>
    <ID>MaxLineLength:JarScanningCordappLoader.kt$JarScanningCordappLoader$return Modifier.isPublic(modifiers) &amp;&amp; !isLocalClass &amp;&amp; !isAnonymousClass &amp;&amp; (!isMemberClass || Modifier.isStatic(modifiers))</ID>
    <ID>MaxLineLength:JarScanningCordappLoader.kt$JarScanningCordappLoader$return scanResult.getClassesWithAnnotation(FlowLogic::class, StartableByRPC::class).filter { it.isUserInvokable() }</ID>
    <ID>MaxLineLength:JarScanningCordappLoader.kt$JarScanningCordappLoader$throw CordappInvalidVersionException("Target versionId ($versionStr) for attribute $attributeName must not be smaller than 1.")</ID>
    <ID>MaxLineLength:JarScanningCordappLoader.kt$JarScanningCordappLoader$throw CordappInvalidVersionException("Target versionId attribute $attributeName not specified. Please specify a whole number starting from 1.")</ID>
    <ID>MaxLineLength:JarScanningCordappLoader.kt$JarScanningCordappLoader$val blockedCertificates = certificates.filter { it.publicKey.hash.sha256() in signerKeyFingerprintBlacklist }</ID>
    <ID>MaxLineLength:JarScanningCordappLoader.kt$JarScanningCordappLoader$val certificates = it.jarPath.openStream().let(::JarInputStream).use(JarSignatureCollector::collectCertificates)</ID>
    <ID>MaxLineLength:JarScanningCordappLoader.kt$JarScanningCordappLoader$val scanResult = ClassGraph().addClassLoader(appClassLoader).overrideClasspath(cordappJarPath.url).enableAllInfo().pooledScan()</ID>
    <ID>MaxLineLength:JarScanningCordappLoader.kt$JarScanningCordappLoader$val targetPlatformVersion = manifest?.get(CordappImpl.TARGET_PLATFORM_VERSION)?.toIntOrNull() ?: minPlatformVersion</ID>
    <ID>MaxLineLength:JarScanningCordappLoader.kt$JarScanningCordappLoader$versionId = parseVersion(manifest[CordappImpl.CORDAPP_CONTRACT_VERSION], CordappImpl.CORDAPP_CONTRACT_VERSION)</ID>
    <ID>MaxLineLength:JarScanningCordappLoader.kt$JarScanningCordappLoader$versionId = parseVersion(manifest[CordappImpl.CORDAPP_WORKFLOW_VERSION], CordappImpl.CORDAPP_WORKFLOW_VERSION)</ID>
    <ID>MaxLineLength:JarScanningCordappLoader.kt$JarScanningCordappLoader.Companion$ fun fromJarUrls(scanJars: List&lt;URL&gt;, versionInfo: VersionInfo = VersionInfo.UNKNOWN, extraCordapps: List&lt;CordappImpl&gt; = emptyList(), cordappsSignerKeyFingerprintBlacklist: List&lt;SecureHash.SHA256&gt; = emptyList()): JarScanningCordappLoader</ID>
    <ID>MaxLineLength:JarScanningCordappLoader.kt$JarScanningCordappLoader.Companion$cordappsSignerKeyFingerprintBlacklist: List&lt;SecureHash.SHA256&gt; = emptyList()</ID>
    <ID>MaxLineLength:JarScanningCordappLoader.kt$JarScanningCordappLoader.Companion$signerKeyFingerprintBlacklist: List&lt;SecureHash.SHA256&gt; = emptyList()</ID>
    <ID>MaxLineLength:JarScanningCordappLoader.kt$JarScanningCordappLoader.RestrictedScanResult$fun &lt;T : Any&gt; getClassesWithAnnotation(type: KClass&lt;T&gt;, annotation: KClass&lt;out Annotation&gt;): List&lt;Class&lt;out T&gt;&gt;</ID>
    <ID>MaxLineLength:JarScanningCordappLoader.kt$JarScanningCordappLoader.RestrictedScanResult$private inner</ID>
    <ID>MaxLineLength:KMSUtils.kt$require(issuerRole == CertRole.LEGAL_IDENTITY) { "Confidential identities can only be issued from well known identities, provided issuer ${issuer.name} has role $issuerRole" }</ID>
    <ID>MaxLineLength:KeyManagementServiceInternal.kt$KeyManagementServiceInternal$override</ID>
    <ID>MaxLineLength:Kryo.kt$ContractUpgradeFilteredTransactionSerializer$override</ID>
    <ID>MaxLineLength:Kryo.kt$ContractUpgradeFilteredTransactionSerializer$val visibleComponents: Map&lt;Int, ContractUpgradeFilteredTransaction.FilteredComponent&gt; = uncheckedCast(kryo.readClassAndObject(input))</ID>
    <ID>MaxLineLength:Kryo.kt$ContractUpgradeWireTransactionSerializer$override</ID>
    <ID>MaxLineLength:Kryo.kt$ImmutableClassSerializer$throw KryoException("Hashcode mismatch for parameter types for ${klass.qualifiedName}: unsupported type evolution has happened.")</ID>
    <ID>MaxLineLength:Kryo.kt$PublicKeySerializer${ // TODO: Instead of encoding to the default X509 format, we could have a custom per key type (space-efficient) serialiser. output.writeBytesWithLength(obj.encoded) }</ID>
    <ID>MaxLineLength:Kryo.kt$ThrowableSerializer$private val delegate: Serializer&lt;Throwable&gt; = uncheckedCast(ReflectionSerializerFactory.makeSerializer(kryo, FieldSerializer::class.java, type))</ID>
    <ID>MaxLineLength:Kryo.kt$X509CertificateSerializer$return CertificateFactory.getInstance("X.509").generateCertificate(input.readBytesWithLength().inputStream()) as X509Certificate</ID>
    <ID>MaxLineLength:Kryo.kt$fun Kryo.serializationContext(): SerializeAsTokenContext?</ID>
    <ID>MaxLineLength:Kryo.kt$if (elemCount &lt; minLen) throw KryoException("Cannot deserialize list, too little elements. Minimum required: $minLen, got: $elemCount")</ID>
    <ID>MaxLineLength:KryoCheckpointSerializer.kt$AutoCloseableSerialisationDetector$override fun read(kryo: Kryo, input: Input, type: Class&lt;AutoCloseable&gt;)</ID>
    <ID>MaxLineLength:KryoCheckpointSerializer.kt$AutoCloseableSerialisationDetector$val message = "${closeable.javaClass.name}, which is a closeable resource, has been detected during flow checkpointing. " + "Restoring such resources across node restarts is not supported. Make sure code accessing it is " + "confined to a private method or the reference is nulled out."</ID>
    <ID>MaxLineLength:KryoCheckpointSerializer.kt$KryoCheckpointSerializer$context.encodingWhitelist.acceptEncoding(encoding) || throw KryoException(encodingNotPermittedFormat.format(encoding))</ID>
    <ID>MaxLineLength:KryoCheckpointSerializer.kt$KryoCheckpointSerializer$override</ID>
    <ID>MaxLineLength:KryoCheckpointSerializer.kt$KryoCheckpointSerializer$val serializer = Fiber.getFiberSerializer(false) as KryoSerializer val classResolver = CordaClassResolver(context).apply { setKryo(serializer.kryo) } // TODO The ClassResolver can only be set in the Kryo constructor and Quasar doesn't provide us with a way of doing that val field = Kryo::class.java.getDeclaredField("classResolver").apply { isAccessible = true } serializer.kryo.apply { field.set(this, classResolver) // don't allow overriding the public key serializer for checkpointing DefaultKryoCustomizer.customize(this) addDefaultSerializer(AutoCloseable::class.java, AutoCloseableSerialisationDetector) register(ClosureSerializer.Closure::class.java, CordaClosureSerializer) classLoader = it.second }</ID>
    <ID>MaxLineLength:Messaging.kt$DeduplicationHandler</ID>
    <ID>MaxLineLength:Messaging.kt$MessagingService$ fun addMessageHandler(topic: String, callback: MessageHandler): MessageHandlerRegistration</ID>
    <ID>MaxLineLength:Messaging.kt$MessagingService$ fun createMessage(topic: String, data: ByteArray, deduplicationId: SenderDeduplicationId = SenderDeduplicationId(DeduplicationId.createRandom(newSecureRandom()), ourSenderUUID), additionalHeaders: Map&lt;String, String&gt; = emptyMap()): Message</ID>
    <ID>MaxLineLength:Messaging.kt$MessagingService$/** * A unique identifier for this sender that changes whenever a node restarts. This is used in conjunction with a sequence * number for message de-duplication at the recipient. */ val ourSenderUUID: String</ID>
    <ID>MaxLineLength:Messaging.kt$ReceivedMessage : Message</ID>
    <ID>MaxLineLength:Messaging.kt$fun MessagingService.send(topicSession: String, payload: Any, to: MessageRecipients, deduplicationId: SenderDeduplicationId = SenderDeduplicationId(DeduplicationId.createRandom(newSecureRandom()), ourSenderUUID), additionalHeaders: Map&lt;String, String&gt; = emptyMap())</ID>
    <ID>MaxLineLength:MessagingExecutor.kt$MessagingExecutor$putLongProperty(org.apache.activemq.artemis.api.core.Message.HDR_SCHEDULED_DELIVERY_TIME, System.currentTimeMillis() + amqDelayMillis)</ID>
    <ID>MaxLineLength:MessagingExecutor.kt$MessagingExecutor$putStringProperty(P2PMessagingHeaders.cordaVendorProperty, cordaVendor) putStringProperty(P2PMessagingHeaders.releaseVersionProperty, releaseVersion) putIntProperty(P2PMessagingHeaders.platformVersionProperty, versionInfo.platformVersion) putStringProperty(P2PMessagingHeaders.topicProperty, SimpleString(message.topic)) writeBodyBufferBytes(message.data.bytes) // Use the magic deduplication property built into Artemis as our message identity too putStringProperty(org.apache.activemq.artemis.api.core.Message.HDR_DUPLICATE_DETECTION_ID, SimpleString(message.uniqueMessageId.toString)) // If we are the sender (ie. we are not going through recovery of some sort), use sequence number short cut. if (ourSenderUUID == message.senderUUID) { putStringProperty(P2PMessagingHeaders.senderUUID, SimpleString(ourSenderUUID)) putLongProperty(P2PMessagingHeaders.senderSeqNo, ourSenderSeqNo.getAndIncrement()) } // For demo purposes - if set then add a delay to messages in order to demonstrate that the flows are doing as intended if (amqDelayMillis &gt; 0 &amp;&amp; message.topic == FlowMessagingImpl.sessionTopic) { putLongProperty(org.apache.activemq.artemis.api.core.Message.HDR_SCHEDULED_DELIVERY_TIME, System.currentTimeMillis() + amqDelayMillis) } message.additionalHeaders.forEach { key, value -&gt; putStringProperty(key, value) }</ID>
    <ID>MaxLineLength:MessagingExecutor.kt$MessagingExecutor$putStringProperty(org.apache.activemq.artemis.api.core.Message.HDR_DUPLICATE_DETECTION_ID, SimpleString(message.uniqueMessageId.toString))</ID>
    <ID>MaxLineLength:MetricInterceptor.kt$MetricInterceptor$@Suspendable override</ID>
    <ID>MaxLineLength:MigrationNamedCacheFactory.kt$MigrationNamedCacheFactory : BindableNamedCacheFactorySingletonSerializeAsToken</ID>
    <ID>MaxLineLength:MigrationNamedCacheFactory.kt$MigrationNamedCacheFactory$override</ID>
    <ID>MaxLineLength:MigrationNamedCacheFactory.kt$MigrationNamedCacheFactory$override fun bindWithConfig(nodeConfiguration: NodeConfiguration)</ID>
    <ID>MaxLineLength:MigrationNamedCacheFactory.kt$MigrationNamedCacheFactory$override fun bindWithMetrics(metricRegistry: MetricRegistry)</ID>
    <ID>MaxLineLength:MigrationNamedCacheFactory.kt$MigrationNamedCacheFactory$private val nodeConfiguration: NodeConfiguration?</ID>
    <ID>MaxLineLength:MigrationServicesForResolution.kt$MigrationServicesForResolution$deserialiseComponentGroup(tx.componentGroups, TransactionState::class, ComponentGroupEnum.OUTPUTS_GROUP, forceDeserialize = true)</ID>
    <ID>MaxLineLength:MigrationServicesForResolution.kt$MigrationServicesForResolution$else -&gt; throw MigrationException("Unknown transaction type ${baseTx::class.qualifiedName} found when loading a state")</ID>
    <ID>MaxLineLength:MigrationServicesForResolution.kt$MigrationServicesForResolution$is ContractUpgradeLedgerTransaction -&gt; it.value.map { stateRef -&gt; StateAndRef(baseTx.outputs[stateRef.index], stateRef) }</ID>
    <ID>MaxLineLength:MigrationServicesForResolution.kt$MigrationServicesForResolution$is NotaryChangeLedgerTransaction -&gt; it.value.map { stateRef -&gt; StateAndRef(baseTx.outputs[stateRef.index], stateRef) }</ID>
    <ID>MaxLineLength:MigrationServicesForResolution.kt$MigrationServicesForResolution$logger.info("Couldn't find network parameters file: ${e.message}. This is expected if the node is starting for the first time.")</ID>
    <ID>MaxLineLength:MigrationServicesForResolution.kt$MigrationServicesForResolution$override</ID>
    <ID>MaxLineLength:MigrationServicesForResolution.kt$MigrationServicesForResolution$private</ID>
    <ID>MaxLineLength:MigrationServicesForResolution.kt$MigrationServicesForResolution${ // If there is no attachment that allows the state class to be deserialised correctly, then carpent a state class anyway. It // might still be possible to access the participants depending on how the state class was serialised. logger.debug("Could not use attachments to deserialise transaction output states for transaction ${tx.id}") tx.outputs.filterIndexed { index, _ -&gt; stateIndices.contains(index)} }</ID>
    <ID>MaxLineLength:MigrationServicesForResolution.kt$MigrationServicesForResolution.&lt;no name provided&gt;${ // Note that the parameters in any file shouldn't be put into the database - this will be done by the node on startup. return if (hash == filedParams?.raw?.hash) { filedParams.raw.deserialize() } else { cordaDB.transaction { storage[hash]?.verified() } } }</ID>
    <ID>MaxLineLength:NetworkMapClient.kt$NetworkMapClient$logger.trace { "Fetched network parameters: '$networkParameterHash' successfully. Network Parameters: $networkParameter" }</ID>
    <ID>MaxLineLength:NetworkMapClient.kt$NetworkMapClient$logger.trace { "Sending network parameters with hash ${signedParametersHash.raw.deserialize()} approval to $ackURL." }</ID>
    <ID>MaxLineLength:NetworkMapUpdater.kt$@VisibleForTesting internal</ID>
    <ID>MaxLineLength:NetworkMapUpdater.kt$NetworkMapUpdater$"""Node is using network parameters with hash $currentParametersHash but the network map is advertising ${networkMap.networkParameterHash}. To resolve this mismatch, and move to the current parameters, delete the $NETWORK_PARAMS_FILE_NAME file from the node's directory and restart. The node will shutdown now."""</ID>
    <ID>MaxLineLength:NetworkMapUpdater.kt$NetworkMapUpdater$// Add new node info to the network map cache, these could be new node info or modification of node info for existing nodes. networkMapCache.addNodes(retrievedNodeInfos)</ID>
    <ID>MaxLineLength:NetworkMapUpdater.kt$NetworkMapUpdater$?:</ID>
    <ID>MaxLineLength:NetworkMapUpdater.kt$NetworkMapUpdater$ParametersUpdateInfo(it.first.newParametersHash, it.second.verified(), it.first.description, it.first.updateDeadline)</ID>
    <ID>MaxLineLength:NetworkMapUpdater.kt$NetworkMapUpdater$To resolve this mismatch, and move to the current parameters, delete the </ID>
    <ID>MaxLineLength:NetworkMapUpdater.kt$NetworkMapUpdater$hash.serialize().sign { keyManagementService.sign(it.bytes, ourNodeInfo.verified().legalIdentities[0].owningKey) }</ID>
    <ID>MaxLineLength:NetworkMapUpdater.kt$NetworkMapUpdater$if (autoAcceptNetworkParameters &amp;&amp; networkParameters.canAutoAccept(newNetParams, excludedAutoAcceptNetworkParameters)) { logger.info("Auto-accepting network parameter update ${update.newParametersHash}") acceptNewNetworkParameters(update.newParametersHash) { hash -&gt; hash.serialize().sign { keyManagementService.sign(it.bytes, ourNodeInfo.verified().legalIdentities[0].owningKey) } } } else { parametersUpdatesTrack.onNext(updateInfo) }</ID>
    <ID>MaxLineLength:NetworkMapUpdater.kt$NetworkMapUpdater$logger.info("Auto-accept enabled for network parameter changes which modify only: $autoAcceptNetworkParametersNames")</ID>
    <ID>MaxLineLength:NetworkMapUpdater.kt$NetworkMapUpdater$logger.info("Fetched: ${hashesToFetch.size} using $threadsToUseForNetworkMapDownload Threads in ${System.currentTimeMillis() - networkMapDownloadStartTime}ms")</ID>
    <ID>MaxLineLength:NetworkMapUpdater.kt$NetworkMapUpdater$logger.warn("Error encountered when downloading node info '$nodeInfo', skipping...", e)</ID>
    <ID>MaxLineLength:NetworkMapUpdater.kt$NetworkMapUpdater$private</ID>
    <ID>MaxLineLength:NetworkMapUpdater.kt$NetworkMapUpdater$this.excludedAutoAcceptNetworkParameters = networkParameterAcceptanceSettings.excludedAutoAcceptableParameters</ID>
    <ID>MaxLineLength:NetworkMapUpdater.kt$NetworkMapUpdater$throw CordaRuntimeException("Network map cache can be updated only if network map/compatibility zone URL is specified")</ID>
    <ID>MaxLineLength:NetworkMapUpdater.kt$NetworkMapUpdater$val (update, signedNewNetParams) = requireNotNull(newNetworkParameters) { "Couldn't find parameters update for the hash: $parametersHash" }</ID>
    <ID>MaxLineLength:NetworkMapUpdater.kt$NetworkMapUpdater$val acceptedHash = if (updatesFile.exists()) updatesFile.readObject&lt;SignedNetworkParameters&gt;().raw.hash else null</ID>
    <ID>MaxLineLength:NetworkMapUpdater.kt$NetworkMapUpdater$val executorToUseForDownloadingNodeInfos = Executors.newFixedThreadPool(threadsToUseForNetworkMapDownload, NamedThreadFactory("NetworkMapUpdaterNodeInfoDownloadThread"))</ID>
    <ID>MaxLineLength:NetworkMapUpdater.kt$NetworkMapUpdater$val executorToUseForInsertionIntoDB = Executors.newSingleThreadExecutor(NamedThreadFactory("NetworkMapUpdateDBInsertThread"))</ID>
    <ID>MaxLineLength:NetworkMapUpdater.kt$NetworkMapUpdater$val networkMapDownloadFutures = hashesToFetch.chunked(max(hashesToFetch.size / threadsToUseForNetworkMapDownload, 1)) .map { nodeInfosToGet -&gt; //for a set of chunked hashes, get the nodeInfo for each hash CompletableFuture.supplyAsync(Supplier&lt;List&lt;NodeInfo&gt;&gt; { nodeInfosToGet.mapNotNull { nodeInfo -&gt; try { networkMapClient.getNodeInfo(nodeInfo) } catch (e: Exception) { // Failure to retrieve one node info shouldn't stop the whole update, log and return null instead. logger.warn("Error encountered when downloading node info '$nodeInfo', skipping...", e) null } } }, executorToUseForDownloadingNodeInfos).thenAcceptAsync(Consumer { retrievedNodeInfos -&gt; // Add new node info to the network map cache, these could be new node info or modification of node info for existing nodes. networkMapCache.addNodes(retrievedNodeInfos) }, executorToUseForInsertionIntoDB) }.toTypedArray()</ID>
    <ID>MaxLineLength:NetworkMapUpdater.kt$NetworkMapUpdater${ // Failure to retrieve one node info shouldn't stop the whole update, log and return null instead. logger.warn("Error encountered when downloading node info '$nodeInfo', skipping...", e) null }</ID>
    <ID>MaxLineLength:NetworkMapUpdater.kt$NetworkMapUpdater${ if (networkMapClient == null) { throw CordaRuntimeException("Network map cache can be updated only if network map/compatibility zone URL is specified") } val (globalNetworkMap, cacheTimeout) = networkMapClient.getNetworkMap() globalNetworkMap.parametersUpdate?.let { handleUpdateNetworkParameters(networkMapClient, it) } val additionalHashes = extraNetworkMapKeys.flatMap { try { networkMapClient.getNetworkMap(it).payload.nodeInfoHashes } catch (e: Exception) { // Failure to retrieve one network map using UUID shouldn't stop the whole update. logger.warn("Error encountered when downloading network map with uuid '$it', skipping...", e) emptyList&lt;SecureHash&gt;() } } val allHashesFromNetworkMap = (globalNetworkMap.nodeInfoHashes + additionalHashes).toSet() if (currentParametersHash != globalNetworkMap.networkParameterHash) { exitOnParametersMismatch(globalNetworkMap) } val currentNodeHashes = networkMapCache.allNodeHashes // Remove node info from network map. (currentNodeHashes - allHashesFromNetworkMap - nodeInfoWatcher.processedNodeInfoHashes) .mapNotNull { if (it != ourNodeInfoHash) networkMapCache.getNodeByHash(it) else null } .forEach(networkMapCache::removeNode) //at the moment we use a blocking HTTP library - but under the covers, the OS will interleave threads waiting for IO //as HTTP GET is mostly IO bound, use more threads than CPU's //maximum threads to use = 24, as if we did not limit this on large machines it could result in 100's of concurrent requests val threadsToUseForNetworkMapDownload = min(Runtime.getRuntime().availableProcessors() * 4, 24) val executorToUseForDownloadingNodeInfos = Executors.newFixedThreadPool(threadsToUseForNetworkMapDownload, NamedThreadFactory("NetworkMapUpdaterNodeInfoDownloadThread")) //DB insert is single threaded - use a single threaded executor for it. val executorToUseForInsertionIntoDB = Executors.newSingleThreadExecutor(NamedThreadFactory("NetworkMapUpdateDBInsertThread")) val hashesToFetch = (allHashesFromNetworkMap - currentNodeHashes) val networkMapDownloadStartTime = System.currentTimeMillis() if (hashesToFetch.isNotEmpty()) { val networkMapDownloadFutures = hashesToFetch.chunked(max(hashesToFetch.size / threadsToUseForNetworkMapDownload, 1)) .map { nodeInfosToGet -&gt; //for a set of chunked hashes, get the nodeInfo for each hash CompletableFuture.supplyAsync(Supplier&lt;List&lt;NodeInfo&gt;&gt; { nodeInfosToGet.mapNotNull { nodeInfo -&gt; try { networkMapClient.getNodeInfo(nodeInfo) } catch (e: Exception) { // Failure to retrieve one node info shouldn't stop the whole update, log and return null instead. logger.warn("Error encountered when downloading node info '$nodeInfo', skipping...", e) null } } }, executorToUseForDownloadingNodeInfos).thenAcceptAsync(Consumer { retrievedNodeInfos -&gt; // Add new node info to the network map cache, these could be new node info or modification of node info for existing nodes. networkMapCache.addNodes(retrievedNodeInfos) }, executorToUseForInsertionIntoDB) }.toTypedArray() //wait for all the futures to complete val waitForAllHashes = CompletableFuture.allOf(*networkMapDownloadFutures) waitForAllHashes.thenRunAsync { logger.info("Fetched: ${hashesToFetch.size} using $threadsToUseForNetworkMapDownload Threads in ${System.currentTimeMillis() - networkMapDownloadStartTime}ms") executorToUseForDownloadingNodeInfos.shutdown() executorToUseForInsertionIntoDB.shutdown() }.getOrThrow() } // Mark the network map cache as ready on a successful poll of the HTTP network map, even on the odd chance that // it's empty networkMapCache.nodeReady.set(null) return cacheTimeout }</ID>
    <ID>MaxLineLength:NetworkMapUpdater.kt$NetworkMapUpdater${ networkMapClient ?: throw IllegalStateException("Network parameters updates are not supported without compatibility zone configured") // TODO This scenario will happen if node was restarted and didn't download parameters yet, but we accepted them. // Add persisting of newest parameters from update. val (update, signedNewNetParams) = requireNotNull(newNetworkParameters) { "Couldn't find parameters update for the hash: $parametersHash" } // We should check that we sign the right data structure hash. val newNetParams = signedNewNetParams.verifiedNetworkParametersCert(trustRoot) val newParametersHash = signedNewNetParams.raw.hash if (parametersHash == newParametersHash) { // The latest parameters have priority. signedNewNetParams.serialize() .open() .copyTo(baseDirectory / NETWORK_PARAMS_UPDATE_FILE_NAME, StandardCopyOption.REPLACE_EXISTING) networkMapClient.ackNetworkParametersUpdate(sign(parametersHash)) logger.info("Accepted network parameter update $update: $newNetParams") } else { throw OutdatedNetworkParameterHashException(parametersHash, newParametersHash) } }</ID>
    <ID>MaxLineLength:NetworkMapUpdater.kt$autoAcceptableNamesAndGetters.none { it.key in excludedParameterNames &amp;&amp; valueChanged(newNetworkParameters, it.value) }</ID>
    <ID>MaxLineLength:NetworkMapUpdater.kt$private fun KProperty1&lt;out NetworkParameters, Any?&gt;.isAutoAcceptable(): Boolean</ID>
    <ID>MaxLineLength:NetworkMapUpdater.kt$private val memberPropertyPartition = NetworkParameters::class.declaredMemberProperties.partition { it.isAutoAcceptable() }</ID>
    <ID>MaxLineLength:NetworkParametersReader.kt$NetworkParametersReader$logger.info("No network-parameters file found. Expecting network parameters to be available from the network map.")</ID>
    <ID>MaxLineLength:NetworkParametersReader.kt$NetworkParametersReader$private</ID>
    <ID>MaxLineLength:NetworkParametersReader.kt$NetworkParametersReader${ // Node joins for the first time. downloadParameters(advertisedParametersHash) }</ID>
    <ID>MaxLineLength:NetworkParametersReader.kt$NetworkParametersReader${ // TODO On one hand we have node starting without parameters and just accepting them by default, // on the other we have parameters update process - it needs to be unified. Say you start the node, you don't have matching parameters, // you get them from network map, but you have to run the approval step. if (signedParametersFromFile == null) { // Node joins for the first time. downloadParameters(advertisedParametersHash) } else if (signedParametersFromFile.raw.hash == advertisedParametersHash) { // Restarted with the same parameters. signedParametersFromFile } else { // Update case. readParametersUpdate(advertisedParametersHash, signedParametersFromFile.raw.hash) } }</ID>
    <ID>MaxLineLength:NetworkParametersReader.kt$NetworkParametersReader${ logger.info("Unable to download network map", e) // If NetworkMap is down while restarting the node, we should be still able to continue with parameters from file null }</ID>
    <ID>MaxLineLength:NetworkParametersReader.kt$NetworkParametersReader.Error$NetworkMapNotConfigured : Error</ID>
    <ID>MaxLineLength:NetworkParametersReader.kt$NetworkParametersReader.Error$ParamsNotConfigured : Error</ID>
    <ID>MaxLineLength:NetworkParametersReader.kt$NetworkParametersReader.Error.OldParamsAndUpdate$"parameters advertised by network map. Please update node to use correct network parameters file."</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NetworkRegistrationHelper$ fun generateKeysAndRegister()</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NetworkRegistrationHelper$ | Please make sure the config is correct or that the correct certificate for the CRL issuer is added to the node's trust store.</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NetworkRegistrationHelper$"$networkRootTrustStorePath does not exist. This file must contain the root CA cert of your compatibility zone. "</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NetworkRegistrationHelper$certStore.query { setPrivateKey(SELF_SIGNED_PRIVATE_KEY, AliasPrivateKey(SELF_SIGNED_PRIVATE_KEY), listOf(NOT_YET_REGISTERED_MARKER_KEYS_AND_CERTS.ECDSAR1_CERT), certificateStore.entryPassword) }</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NetworkRegistrationHelper$if (Crypto.toSupportedPublicKey(certificates.first().publicKey) != Crypto.toSupportedPublicKey(registeringPublicKey)) { throw CertificateRequestException("Received certificate contains incorrect public key, expected '$registeringPublicKey', got '${certificates.first().publicKey}'.") }</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NetworkRegistrationHelper$logError</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NetworkRegistrationHelper$logProgress("Certificate signing request with the following information will be submitted to the Corda certificate signing server.")</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NetworkRegistrationHelper$logProgress("Successfully submitted request to Corda certificate signing server, request ID: $requestId.")</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NetworkRegistrationHelper$onSuccess(nodeCaPublicKey, cryptoService.getSigner(nodeCaKeyAlias), nodeCaCertificates, tlsCrlIssuerCert?.subjectX500Principal?.toX500Name())</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NetworkRegistrationHelper$private val nextIdleDuration: (Duration?) -&gt; Duration? = FixedPeriodLimitedRetrialStrategy(10, Duration.ofMinutes(1))</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NetworkRegistrationHelper$protected open fun onSuccess(publicKey: PublicKey, contentSigner: ContentSigner, certificates: List&lt;X509Certificate&gt;, tlsCrlCertificateIssuer: X500Name?)</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NetworkRegistrationHelper$throw CertificateRequestException("Received certificate contains incorrect public key, expected '$registeringPublicKey', got '${certificates.first().publicKey}'.")</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NetworkRegistrationHelper$throw CertificateRequestException("Received certificate contains invalid cert role, expected '$certRole', got '$nodeCaCertRole'.")</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NetworkRegistrationHelper$throw CertificateRequestException("Subject of received node CA cert doesn't match with node legal name: $nodeCaSubject")</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NetworkRegistrationHelper$throw NodeRegistrationException("Compatibility Zone registration service is currently unavailable, " + "try again later!.", e)</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NetworkRegistrationHelper$val certStore: CertificateStore = if (cryptoService is BCCryptoService) cryptoService.certificateStore else certificateStore</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NetworkRegistrationHelper$val request = X509Utilities.createCertificateSigningRequest(myLegalName.x500Principal, emailAddress, publicKey, contentSigner, certRole)</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NetworkRegistrationHelper$val requestId = submitOrResumeCertificateSigningRequest(nodeCaPublicKey, cryptoService.getSigner(nodeCaKeyAlias))</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NetworkRegistrationHelper${ // Create or load self signed keypair from the key store. // We use the self sign certificate to store the key temporarily in the keystore while waiting for the request approval. if (alias !in this) { // NODE_CA should be TLS compatible due to the cert hierarchy structure. val keyPair = Crypto.generateKeyPair(X509Utilities.DEFAULT_TLS_SIGNATURE_SCHEME) val selfSignCert = X509Utilities.createSelfSignedCACertificate(myLegalName.x500Principal, keyPair) // Save to the key store. with(value) { setPrivateKey(alias, keyPair.private, listOf(selfSignCert), keyPassword = entryPassword) save() } } return query { getCertificateAndKeyPair(alias, entryPassword) }.keyPair }</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NetworkRegistrationHelper${ certificatesDirectory.createDirectories() // We need this in case cryptoService and certificateStore share the same KeyStore (for backwards compatibility purposes). // If we didn't, then an update to cryptoService wouldn't be reflected to certificateStore that is already loaded in memory. val certStore: CertificateStore = if (cryptoService is BCCryptoService) cryptoService.certificateStore else certificateStore // SELF_SIGNED_PRIVATE_KEY is used as progress indicator. if (certStore.contains(nodeCaKeyAlias) &amp;&amp; !certStore.contains(SELF_SIGNED_PRIVATE_KEY)) { logProgress("Certificate already exists, Corda node will now terminate...") return } val tlsCrlIssuerCert = getTlsCrlIssuerCert() // We use SELF_SIGNED_PRIVATE_KEY as progress indicator so we just store a dummy key and cert. // When registration succeeds, this entry should be deleted. certStore.query { setPrivateKey(SELF_SIGNED_PRIVATE_KEY, AliasPrivateKey(SELF_SIGNED_PRIVATE_KEY), listOf(NOT_YET_REGISTERED_MARKER_KEYS_AND_CERTS.ECDSAR1_CERT), certificateStore.entryPassword) } val nodeCaPublicKey = loadOrGenerateKeyPair() val requestId = submitOrResumeCertificateSigningRequest(nodeCaPublicKey, cryptoService.getSigner(nodeCaKeyAlias)) val nodeCaCertificates = pollServerForCertificates(requestId) validateCertificates(nodeCaPublicKey, nodeCaCertificates) certStore.setCertPathOnly(nodeCaKeyAlias, nodeCaCertificates) certStore.value.internal.deleteEntry(SELF_SIGNED_PRIVATE_KEY) certStore.value.save() logProgress("Private key '$nodeCaKeyAlias' and its certificate-chain stored successfully.") onSuccess(nodeCaPublicKey, cryptoService.getSigner(nodeCaKeyAlias), nodeCaCertificates, tlsCrlIssuerCert?.subjectX500Principal?.toX500Name()) // All done, clean up temp files. requestIdStore.deleteIfExists() }</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NetworkRegistrationHelper${ val nodeCACertificate = certificates.first() val nodeCaSubject = try { CordaX500Name.build(nodeCACertificate.subjectX500Principal) } catch (e: IllegalArgumentException) { throw CertificateRequestException("Received node CA cert has invalid subject name: ${e.message}") } if (nodeCaSubject != myLegalName) { throw CertificateRequestException("Subject of received node CA cert doesn't match with node legal name: $nodeCaSubject") } val nodeCaCertRole = try { CertRole.extract(nodeCACertificate) } catch (e: IllegalArgumentException) { throw CertificateRequestException("Unable to extract cert role from received node CA cert: ${e.message}") } if (certRole != nodeCaCertRole) { throw CertificateRequestException("Received certificate contains invalid cert role, expected '$certRole', got '$nodeCaCertRole'.") } // Validate returned certificate is for the correct public key. if (Crypto.toSupportedPublicKey(certificates.first().publicKey) != Crypto.toSupportedPublicKey(registeringPublicKey)) { throw CertificateRequestException("Received certificate contains incorrect public key, expected '$registeringPublicKey', got '${certificates.first().publicKey}'.") } // Validate certificate chain returned from the doorman with the root cert obtained via out-of-band process, to prevent MITM attack on doorman server. X509Utilities.validateCertificateChain(rootCert, certificates) logProgress("Certificate signing request approved, storing private key with the certificate chain.") }</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NodeRegistrationConfiguration$cryptoService = CryptoServiceFactory.makeCryptoService(SupportedCryptoServices.BC_SIMPLE, config.myLegalName, config.signingCertificateStore)</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NodeRegistrationHelper$computeNextIdleDoormanConnectionPollInterval: (Duration?) -&gt; Duration? = FixedPeriodLimitedRetrialStrategy(10, Duration.ofMinutes(1))</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NodeRegistrationHelper$logger.info("Copying trusted certificate to the node's trust store: Alias: $it, Certificate: $certificate")</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NodeRegistrationHelper$logger.warn("The node's trust store already exists. The following certificates will be overridden: ${this.aliases().asSequence()}")</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NodeRegistrationHelper$override</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NodeRegistrationHelper$private</ID>
    <ID>MaxLineLength:NetworkRegistrationHelper.kt$NodeRegistrationHelper$val validityWindow = X509Utilities.getCertificateValidityWindow(DEFAULT_VALIDITY_WINDOW.first, DEFAULT_VALIDITY_WINDOW.second, issuerCertificate)</ID>
    <ID>MaxLineLength:NetworkRegistrationService.kt$NetworkRegistrationService$ @Throws(CertificateRequestException::class) fun retrieveCertificates(requestId: String): CertificateResponse</ID>
    <ID>MaxLineLength:Node.kt$Node$ override fun startDatabase()</ID>
    <ID>MaxLineLength:Node.kt$Node$ private fun registerDefaultExceptionHandler()</ID>
    <ID>MaxLineLength:Node.kt$Node$"To disable autodetect set detectPublicIp = false in the node.conf, or consider using messagingServerAddress and messagingServerExternal"</ID>
    <ID>MaxLineLength:Node.kt$Node$ArtemisRpcBroker.withSsl(configuration.p2pSslOptions, this.address, adminAddress, sslConfig!!, securityManager, MAX_RPC_MESSAGE_SIZE, jmxMonitoringHttpPort != null, rpcBrokerDirectory, shouldStartLocalShell())</ID>
    <ID>MaxLineLength:Node.kt$Node$ArtemisRpcBroker.withoutSsl(configuration.p2pSslOptions, this.address, adminAddress, securityManager, MAX_RPC_MESSAGE_SIZE, jmxMonitoringHttpPort != null, rpcBrokerDirectory, shouldStartLocalShell())</ID>
    <ID>MaxLineLength:Node.kt$Node$ObjectName("$domain:type=$category,${if (component.isNotEmpty()) "component=$component," else ""}name=$subName")</ID>
    <ID>MaxLineLength:Node.kt$Node$System.setProperty("h2.allowedClasses", "org.h2.mvstore.db.MVTableEngine,org.locationtech.jts.geom.Geometry,org.h2.server.TcpServer")</ID>
    <ID>MaxLineLength:Node.kt$Node$System.setProperty("io.netty.allocator.numHeapArenas", min(memBasedArenas, NettyRuntime.availableProcessors() * 2L).toString())</ID>
    <ID>MaxLineLength:Node.kt$Node$if (configuration.shouldStartLocalShell()) RPCSecurityManagerWithAdditionalUser(this, User(INTERNAL_SHELL_USER, INTERNAL_SHELL_USER, setOf(Permissions.all()))) else this</ID>
    <ID>MaxLineLength:Node.kt$Node$internalRpcMessagingClient = InternalRPCMessagingClient(configuration.p2pSslOptions, it.admin, MAX_RPC_MESSAGE_SIZE, CordaX500Name.build(configuration.p2pSslOptions.keyStore.get()[X509Utilities.CORDA_CLIENT_TLS].subjectX500Principal), rpcServerConfiguration)</ID>
    <ID>MaxLineLength:Node.kt$Node$log</ID>
    <ID>MaxLineLength:Node.kt$Node$log.info("Detected public IP: ${foundPublicIP.hostAddress}. This will be used instead of the provided \"$host\" as the advertised address.")</ID>
    <ID>MaxLineLength:Node.kt$Node$log.info("Retrieved public IP from Network Map Service: $this. This will be used instead of the provided \"$host\" as the advertised address.")</ID>
    <ID>MaxLineLength:Node.kt$Node$override</ID>
    <ID>MaxLineLength:Node.kt$Node$override fun myAddresses(): List&lt;NetworkHostAndPort&gt;</ID>
    <ID>MaxLineLength:Node.kt$Node$private</ID>
    <ID>MaxLineLength:Node.kt$Node$registerScheme(AMQPClientSerializationScheme(cordappLoader.cordapps, Caffeine.newBuilder().maximumSize(128).build&lt;SerializationFactoryCacheKey, SerializerFactory&gt;().asMap()))</ID>
    <ID>MaxLineLength:Node.kt$Node$registerScheme(AMQPServerSerializationScheme(cordappLoader.cordapps, Caffeine.newBuilder().maximumSize(128).build&lt;SerializationFactoryCacheKey, SerializerFactory&gt;().asMap()))</ID>
    <ID>MaxLineLength:Node.kt$Node$require(nodeInfo.legalIdentities.size in 1..2) { "Currently nodes must have a primary address and optionally one serviced address" }</ID>
    <ID>MaxLineLength:Node.kt$Node$return BridgeControlListener(configuration.p2pSslOptions, networkParameters.maxMessageSize, configuration.crlCheckSoftFail, artemisMessagingClientFactory)</ID>
    <ID>MaxLineLength:Node.kt$Node$rpcClientContext = if (configuration.shouldInitCrashShell()) AMQP_RPC_CLIENT_CONTEXT.withClassLoader(classloader) else null</ID>
    <ID>MaxLineLength:Node.kt$Node$serviceIdentity = if (nodeInfo.legalIdentities.size == 1) null else nodeInfo.legalIdentities[1].owningKey</ID>
    <ID>MaxLineLength:Node.kt$Node$throw CouldNotCreateDataSourceException("Database password is required for H2 server listening on ${InetAddress.getByName(effectiveH2Settings.address.host)}.")</ID>
    <ID>MaxLineLength:Node.kt$Node${ // Netty arenas are approx 16MB each when max'd out. Set arenas based on memory, not core count, unless memory is abundant. val memBasedArenas = max(Runtime.getRuntime().maxMemory() / 256.MB, 1L) // We set the min of the above and the default. System.setProperty("io.netty.allocator.numHeapArenas", min(memBasedArenas, NettyRuntime.availableProcessors() * 2L).toString()) }</ID>
    <ID>MaxLineLength:Node.kt$Node${ check(!serverThread.isOnThread) synchronized(this) { if (shutdown) return shutdown = true // Unregister shutdown hook to prevent any unnecessary second calls to stop shutdownHook?.cancel() shutdownHook = null } printBasicNodeInfo("Shutting down ...") // All the Node started subsystems were registered with the runOnStop list at creation. // So now simply call the parent to stop everything in reverse order. // In particular this prevents premature shutdown of the Database by AbstractNode whilst the serverThread is active super.stop() shutdown = false log.info("Shutdown complete") }</ID>
    <ID>MaxLineLength:Node.kt$Node${ override fun createStartedNode(nodeInfo: NodeInfo, rpcOps: CordaRPCOps, notaryService: NotaryService?): NodeInfo = nodeInfo companion object { private val staticLog = contextLogger() var renderBasicInfoToConsole = true /** Used for useful info that we always want to show, even when not logging to the console */ fun printBasicNodeInfo(description: String, info: String? = null) { val msg = if (info == null) description else "${description.padEnd(40)}: $info" val loggerName = if (renderBasicInfoToConsole) "BasicInfo" else "Main" LoggerFactory.getLogger(loggerName).info(msg) } fun printInRed(message: String) { println("${ShellConstants.RED}$message${ShellConstants.RESET}") } fun printWarning(message: String) { Emoji.renderIfSupported { printInRed("${Emoji.warningSign} ATTENTION: $message") } staticLog.warn(message) } internal fun failStartUp(message: String): Nothing { println(message) println("Corda will now exit...") exitProcess(1) } private fun createClock(configuration: NodeConfiguration): CordaClock { return (if (configuration.useTestClock) ::DemoClock else ::SimpleClock)(Clock.systemUTC()) } private val sameVmNodeCounter = AtomicInteger() // TODO: make this configurable. const val MAX_RPC_MESSAGE_SIZE = 10485760 fun isInvalidJavaVersion(): Boolean { if (!hasMinimumJavaVersion()) { println("You are using a version of Java that is not supported (${SystemUtils.JAVA_VERSION}). Please upgrade to the latest version of Java 8.") println("Corda will now exit...") return true } return false } private fun hasMinimumJavaVersion(): Boolean { // when the ext.java8_minUpdateVersion gradle constant changes, so must this check return try { val update = getJavaUpdateVersion(SystemUtils.JAVA_VERSION) // To filter out cases like 1.8.0_202-ea SystemUtils.IS_JAVA_1_8 &amp;&amp; update &gt;= 171 } catch (e: NumberFormatException) { // custom JDKs may not have the update version (e.g. 1.8.0-adoptopenjdk) false } } } override val log: Logger get() = staticLog override val transactionVerifierWorkerCount: Int get() = 4 private var internalRpcMessagingClient: InternalRPCMessagingClient? = null private var rpcBroker: ArtemisBroker? = null private var shutdownHook: ShutdownHook? = null // DISCUSSION // // We use a single server thread for now, which means all message handling is serialized. // // Writing thread safe code is hard. In this project we are writing most node services and code to be thread safe, but // the possibility of mistakes is always present. Thus we make a deliberate decision here to trade off some multi-core // scalability in order to gain developer productivity by setting the size of the serverThread pool to one, which will // reduce the number of threading bugs we will need to tackle. // // This leaves us with four possibilities in future: // // (1) We discover that processing messages is fast and that our eventual use cases do not need very high // processing rates. We have benefited from the higher productivity and not lost anything. // // (2) We discover that we need greater multi-core scalability, but that the bulk of our time goes into particular CPU // hotspots that are easily multi-threaded e.g. signature checking. We successfully multi-thread those hotspots // and find that our software now scales sufficiently well to satisfy our user's needs. // // (3) We discover that it wasn't enough, but that we only need to run some messages in parallel and that the bulk of // the work can stay single threaded. For example perhaps we find that latency sensitive UI requests must be handled // on a separate thread pool where long blocking operations are not allowed, but that the bulk of the heavy lifting // can stay single threaded. In this case we would need a separate thread pool, but we still minimise the amount of // thread safe code we need to write and test. // // (4) None of the above are sufficient and we need to run all messages in parallel to get maximum (single machine) // scalability and fully saturate all cores. In that case we can go fully free-threaded, e.g. change the number '1' // below to some multiple of the core count. Alternatively by using the ForkJoinPool and let it figure out the right // number of threads by itself. This will require some investment in stress testing to build confidence that we // haven't made any mistakes, but it will only be necessary if eventual deployment scenarios demand it. // // Note that the messaging subsystem schedules work onto this thread in a blocking manner. That means if the server // thread becomes too slow and a backlog of work starts to builds up it propagates back through into the messaging // layer, which can then react to the backpressure. Artemis MQ in particular knows how to do flow control by paging // messages to disk rather than letting us run out of RAM. // // The primary work done by the server thread is execution of flow logics, and related // serialisation/deserialisation work. override fun makeMessagingService(): MessagingService { return P2PMessagingClient( config = configuration, versionInfo = versionInfo, serverAddress = configuration.messagingServerAddress ?: NetworkHostAndPort("localhost", configuration.p2pAddress.port), nodeExecutor = serverThread, database = database, networkMap = networkMapCache, isDrainingModeOn = nodeProperties.flowsDrainingMode::isEnabled, drainingModeWasChangedEvents = nodeProperties.flowsDrainingMode.values, metricRegistry = metricRegistry, cacheFactory = cacheFactory ) } override fun startMessagingService(rpcOps: RPCOps, nodeInfo: NodeInfo, myNotaryIdentity: PartyAndCertificate?, networkParameters: NetworkParameters) { require(nodeInfo.legalIdentities.size in 1..2) { "Currently nodes must have a primary address and optionally one serviced address" } network as P2PMessagingClient if (System.getProperty("io.netty.allocator.numHeapArenas").isNullOrBlank()) { // Netty arenas are approx 16MB each when max'd out. Set arenas based on memory, not core count, unless memory is abundant. val memBasedArenas = max(Runtime.getRuntime().maxMemory() / 256.MB, 1L) // We set the min of the above and the default. System.setProperty("io.netty.allocator.numHeapArenas", min(memBasedArenas, NettyRuntime.availableProcessors() * 2L).toString()) } // Construct security manager reading users data either from the 'security' config section // if present or from rpcUsers list if the former is missing from config. val securityManagerConfig = configuration.security?.authService ?: SecurityConfiguration.AuthService.fromUsers(configuration.rpcUsers) val securityManager = with(RPCSecurityManagerImpl(securityManagerConfig, cacheFactory)) { if (configuration.shouldStartLocalShell()) RPCSecurityManagerWithAdditionalUser(this, User(INTERNAL_SHELL_USER, INTERNAL_SHELL_USER, setOf(Permissions.all()))) else this } val messageBroker = if (!configuration.messagingServerExternal) { val brokerBindAddress = configuration.messagingServerAddress ?: NetworkHostAndPort("0.0.0.0", configuration.p2pAddress.port) ArtemisMessagingServer(configuration, brokerBindAddress, networkParameters.maxMessageSize) } else { null } val rpcServerAddresses = if (configuration.rpcOptions.standAloneBroker) { BrokerAddresses(configuration.rpcOptions.address, configuration.rpcOptions.adminAddress) } else { startLocalRpcBroker(securityManager) } val bridgeControlListener = makeBridgeControlListener(network.serverAddress, networkParameters) printBasicNodeInfo("Advertised P2P messaging addresses", nodeInfo.addresses.joinToString()) val rpcServerConfiguration = RPCServerConfiguration.DEFAULT rpcServerAddresses?.let { internalRpcMessagingClient = InternalRPCMessagingClient(configuration.p2pSslOptions, it.admin, MAX_RPC_MESSAGE_SIZE, CordaX500Name.build(configuration.p2pSslOptions.keyStore.get()[X509Utilities.CORDA_CLIENT_TLS].subjectX500Principal), rpcServerConfiguration) printBasicNodeInfo("RPC connection address", it.primary.toString()) printBasicNodeInfo("RPC admin connection address", it.admin.toString()) } // Start up the embedded MQ server messageBroker?.apply { closeOnStop() start() } rpcBroker?.apply { closeOnStop() start() } // Start P2P bridge service bridgeControlListener.apply { closeOnStop() start() } // Start up the MQ clients. internalRpcMessagingClient?.run { closeOnStop() init(rpcOps, securityManager, cacheFactory) } network.closeOnStop() network.start( myIdentity = nodeInfo.legalIdentities[0].owningKey, serviceIdentity = if (nodeInfo.legalIdentities.size == 1) null else nodeInfo.legalIdentities[1].owningKey, advertisedAddress = nodeInfo.addresses[0], maxMessageSize = networkParameters.maxMessageSize ) } private fun makeBridgeControlListener(serverAddress: NetworkHostAndPort, networkParameters: NetworkParameters): BridgeControlListener { val artemisMessagingClientFactory = { ArtemisMessagingClient( configuration.p2pSslOptions, serverAddress, networkParameters.maxMessageSize, failoverCallback = { errorAndTerminate("ArtemisMessagingClient failed. Shutting down.", null) } ) } return BridgeControlListener(configuration.p2pSslOptions, networkParameters.maxMessageSize, configuration.crlCheckSoftFail, artemisMessagingClientFactory) } private fun startLocalRpcBroker(securityManager: RPCSecurityManager): BrokerAddresses? { return with(configuration) { rpcOptions.address.let { val rpcBrokerDirectory: Path = baseDirectory / "brokers" / "rpc" with(rpcOptions) { rpcBroker = if (useSsl) { ArtemisRpcBroker.withSsl(configuration.p2pSslOptions, this.address, adminAddress, sslConfig!!, securityManager, MAX_RPC_MESSAGE_SIZE, jmxMonitoringHttpPort != null, rpcBrokerDirectory, shouldStartLocalShell()) } else { ArtemisRpcBroker.withoutSsl(configuration.p2pSslOptions, this.address, adminAddress, securityManager, MAX_RPC_MESSAGE_SIZE, jmxMonitoringHttpPort != null, rpcBrokerDirectory, shouldStartLocalShell()) } } rpcBroker!!.addresses } } } override fun myAddresses(): List&lt;NetworkHostAndPort&gt; = listOf(getAdvertisedAddress()) + configuration.additionalP2PAddresses private fun getAdvertisedAddress(): NetworkHostAndPort { return with(configuration) { require(p2pAddress.host != "0.0.0.0") { "Invalid p2pAddress: $p2pAddress contains 0.0.0.0 which is not suitable as an advertised node address" } val host = if (detectPublicIp) { tryDetectIfNotPublicHost(p2pAddress.host) ?: p2pAddress.host } else { p2pAddress.host } NetworkHostAndPort(host, p2pAddress.port) } } /** * Checks whether the specified [host] is a public IP address or hostname. If not, tries to discover the current * machine's public IP address to be used instead by looking through the network interfaces. */ private fun tryDetectIfNotPublicHost(host: String): String? { return if (host.toLowerCase() == "localhost") { log.warn("p2pAddress specified as localhost. Trying to autodetect a suitable public address to advertise in network map." + "To disable autodetect set detectPublicIp = false in the node.conf, or consider using messagingServerAddress and messagingServerExternal") val foundPublicIP = AddressUtils.tryDetectPublicIP() if (foundPublicIP == null) { try { val retrievedHostName = networkMapClient?.myPublicHostname() if (retrievedHostName != null) { log.info("Retrieved public IP from Network Map Service: $this. This will be used instead of the provided \"$host\" as the advertised address.") } retrievedHostName } catch (ignore: Exception) { // Cannot reach the network map service, ignore the exception and use provided P2P address instead. log.warn("Cannot connect to the network map service for public IP detection.") null } } else { log.info("Detected public IP: ${foundPublicIP.hostAddress}. This will be used instead of the provided \"$host\" as the advertised address.") foundPublicIP.hostAddress } } else { null } } /** * If the node is persisting to an embedded H2 database, then expose this via TCP with a DB URL of the form: * jdbc:h2:tcp://&lt;host&gt;:&lt;port&gt;/node * with username and password as per the DataSource connection details. The key element to enabling this support is to * ensure that you specify a DB connection URL of the form jdbc:h2:file: in the node config and that you include * the H2 option AUTO_SERVER_PORT set to the port you desire to use (0 will give a dynamically allocated port number) * but exclude the H2 option AUTO_SERVER=TRUE. * This is not using the H2 "automatic mixed mode" directly but leans on many of the underpinnings. For more details * on H2 URLs and configuration see: http://www.h2database.com/html/features.html#database_url */ override fun startDatabase() { val databaseUrl = configuration.dataSourceProperties.getProperty("dataSource.url") val h2Prefix = "jdbc:h2:file:" if (databaseUrl != null &amp;&amp; databaseUrl.startsWith(h2Prefix)) { val effectiveH2Settings = configuration.effectiveH2Settings //forbid execution of arbitrary code via SQL except those classes required by H2 itself System.setProperty("h2.allowedClasses", "org.h2.mvstore.db.MVTableEngine,org.locationtech.jts.geom.Geometry,org.h2.server.TcpServer") if (effectiveH2Settings?.address != null) { if (!InetAddress.getByName(effectiveH2Settings.address.host).isLoopbackAddress &amp;&amp; configuration.dataSourceProperties.getProperty("dataSource.password").isBlank()) { throw CouldNotCreateDataSourceException("Database password is required for H2 server listening on ${InetAddress.getByName(effectiveH2Settings.address.host)}.") } val databaseName = databaseUrl.removePrefix(h2Prefix).substringBefore(';') val baseDir = Paths.get(databaseName).parent.toString() val server = org.h2.tools.Server.createTcpServer( "-tcpPort", effectiveH2Settings.address.port.toString(), "-tcpAllowOthers", "-tcpDaemon", "-baseDir", baseDir, "-key", "node", databaseName) // override interface that createTcpServer listens on (which is always 0.0.0.0) System.setProperty("h2.bindAddress", effectiveH2Settings.address.host) runOnStop += server::stop val url = try { server.start().url } catch (e: JdbcSQLNonTransientConnectionException) { if (e.cause is BindException) { throw AddressBindingException(effectiveH2Settings.address) } else { throw e } } printBasicNodeInfo("Database connection url is", "jdbc:h2:$url/node") } } super.startDatabase() database.closeOnStop() } private val _startupComplete = openFuture&lt;Unit&gt;() val startupComplete: CordaFuture&lt;Unit&gt; get() = _startupComplete override fun generateAndSaveNodeInfo(): NodeInfo { initialiseSerialization() return super.generateAndSaveNodeInfo() } override fun start(): NodeInfo { registerDefaultExceptionHandler() initialiseSerialization() val nodeInfo: NodeInfo = super.start() nodeReadyFuture.thenMatch({ serverThread.execute { registerJmxReporter(services.monitoringService.metrics) _startupComplete.set(Unit) } }, { th -&gt; staticLog.error("Unexpected exception", th) } // XXX: Why not use log? ) shutdownHook = addShutdownHook { stop() } return nodeInfo } /** * Register a default exception handler for all threads that terminates the process if the database connection goes away and * cannot be recovered. */ private fun registerDefaultExceptionHandler() { Thread.setDefaultUncaughtExceptionHandler(DbExceptionHandler(Thread.getDefaultUncaughtExceptionHandler())) } /** * A hook to allow configuration override of the JmxReporter being used. */ fun registerJmxReporter(metrics: MetricRegistry) { log.info("Registering JMX reporter:") when (configuration.jmxReporterType) { JmxReporterType.JOLOKIA -&gt; registerJolokiaReporter(metrics) JmxReporterType.NEW_RELIC -&gt; registerNewRelicReporter(metrics) } } private fun registerJolokiaReporter(registry: MetricRegistry) { log.info("Registering Jolokia JMX reporter:") // Begin exporting our own metrics via JMX. These can be monitored using any agent, e.g. Jolokia: // // https://jolokia.org/agent/jvm.html JmxReporter.forRegistry(registry).inDomain("net.corda").createsObjectNamesWith { _, domain, name -&gt; // Make the JMX hierarchy a bit better organised. val category = name.substringBefore('.').substringBeforeLast('/') val component = name.substringBefore('.').substringAfterLast('/', "") val subName = name.substringAfter('.', "") (if (subName == "") ObjectName("$domain:name=$category${if (component.isNotEmpty()) ",component=$component," else ""}") else ObjectName("$domain:type=$category,${if (component.isNotEmpty()) "component=$component," else ""}name=$subName")) }.build().start() } private fun registerNewRelicReporter(registry: MetricRegistry) { log.info("Registering New Relic JMX Reporter:") val reporter = NewRelicReporter.forRegistry(registry) .name("New Relic Reporter") .filter(MetricFilter.ALL) .attributeFilter(AllEnabledMetricAttributeFilter()) .rateUnit(TimeUnit.SECONDS) .durationUnit(TimeUnit.MILLISECONDS) .metricNamePrefix("corda/") .build() reporter.start(1, TimeUnit.MINUTES) } override val rxIoScheduler: Scheduler get() = Schedulers.io() private fun initialiseSerialization() { if (!initialiseSerialization) return val classloader = cordappLoader.appClassLoader nodeSerializationEnv = SerializationEnvironment.with( SerializationFactoryImpl().apply { registerScheme(AMQPServerSerializationScheme(cordappLoader.cordapps, Caffeine.newBuilder().maximumSize(128).build&lt;SerializationFactoryCacheKey, SerializerFactory&gt;().asMap())) registerScheme(AMQPClientSerializationScheme(cordappLoader.cordapps, Caffeine.newBuilder().maximumSize(128).build&lt;SerializationFactoryCacheKey, SerializerFactory&gt;().asMap())) }, p2pContext = AMQP_P2P_CONTEXT.withClassLoader(classloader), rpcServerContext = AMQP_RPC_SERVER_CONTEXT.withClassLoader(classloader), rpcClientContext = if (configuration.shouldInitCrashShell()) AMQP_RPC_CLIENT_CONTEXT.withClassLoader(classloader) else null, //even Shell embeded in the node connects via RPC to the node storageContext = AMQP_STORAGE_CONTEXT.withClassLoader(classloader), checkpointSerializer = KryoCheckpointSerializer, checkpointContext = KRYO_CHECKPOINT_CONTEXT.withClassLoader(classloader) ) } /** Starts a blocking event loop for message dispatch. */ fun run() { internalRpcMessagingClient?.start(rpcBroker!!.serverControl) (network as P2PMessagingClient).run() } private var shutdown = false override fun stop() { check(!serverThread.isOnThread) synchronized(this) { if (shutdown) return shutdown = true // Unregister shutdown hook to prevent any unnecessary second calls to stop shutdownHook?.cancel() shutdownHook = null } printBasicNodeInfo("Shutting down ...") // All the Node started subsystems were registered with the runOnStop list at creation. // So now simply call the parent to stop everything in reverse order. // In particular this prevents premature shutdown of the Database by AbstractNode whilst the serverThread is active super.stop() shutdown = false log.info("Shutdown complete") } fun &lt;T : FlowLogic&lt;*&gt;&gt; registerInitiatedFlow(smm: StateMachineManager, initiatedFlowClass: Class&lt;T&gt;) { this.flowManager.registerInitiatedFlow(initiatedFlowClass) } }</ID>
    <ID>MaxLineLength:Node.kt$Node.Companion$println("You are using a version of Java that is not supported (${SystemUtils.JAVA_VERSION}). Please upgrade to the latest version of Java 8.")</ID>
    <ID>MaxLineLength:Node.kt$Node.Companion${ val update = getJavaUpdateVersion(SystemUtils.JAVA_VERSION) // To filter out cases like 1.8.0_202-ea SystemUtils.IS_JAVA_1_8 &amp;&amp; update &gt;= 171 }</ID>
    <ID>MaxLineLength:Node.kt$NodeWithInfo$fun &lt;T : FlowLogic&lt;*&gt;&gt; registerInitiatedFlow(initiatedFlowClass: Class&lt;T&gt;)</ID>
    <ID>MaxLineLength:Node.kt$NodeWithInfo$val services: StartedNodeServices = object : StartedNodeServices, ServiceHubInternal by node.services, FlowStarter by node.flowStarter {}</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService$/** * This caches contract attachment versions by contract class name. For each version, we support one signed and one unsigned attachment, since that is allowed. * * It is correctly invalidated as new attachments are uploaded. */ private val contractsCache = InfrequentlyMutatedCache&lt;ContractClassName, NavigableMap&lt;Version, AttachmentIds&gt;&gt;("NodeAttachmentService_contractAttachmentVersions", cacheFactory)</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService$AttachmentSort.AttachmentSortColumn(AttachmentSort.AttachmentSortAttribute.INSERTION_DATE, Sort.Direction.DESC)</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService$ContractAttachment</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService$HashCheckingStream : FilterInputStream</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService$HashMismatchException : CordaRuntimeException</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService$log.warn("(Dev Mode) Multiple signed attachments ${signed.map { it.toString() }} for contract $contractClassName version '${it.key}'.")</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService$log.warn("Selecting attachment ${unsigned.first()} from duplicated, unsigned attachments ${unsigned.map { it.toString() }} for contract $contractClassName version '${it.key}'.")</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService$log.warn("Several versions based on whitelistedContractImplementations position are available: ${versions.toSet()}. $msg")</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService$private</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService$require(inputStream !is JarInputStream) { "Input stream must not be a JarInputStream" } // Read the file into RAM and then calculate its hash. The attachment must fit into memory. // TODO: Switch to a two-phase insert so we can handle attachments larger than RAM. // To do this we must pipe stream into the database without knowing its hash, which we will learn only once // the insert/upload is complete. We can then query to see if it's a duplicate and if so, erase, and if not // set the hash field of the new attachment record. val bytes = inputStream.readFully() val id = bytes.sha256() if (!hasAttachment(id)) { checkIsAValidJAR(bytes.inputStream()) val jarSigners = getSigners(bytes) val contractVersion = increaseDefaultVersionIfWhitelistedAttachment(contractClassNames, getVersion(bytes), id) val session = currentDBSession() val attachment = NodeAttachmentService.DBAttachment( attId = id.toString(), content = bytes, uploader = uploader, filename = filename, contractClassNames = contractClassNames, signers = jarSigners, version = contractVersion ) session.save(attachment) attachmentCount.inc() log.info("Stored new attachment: id=$id uploader=$uploader filename=$filename") contractClassNames.forEach { contractsCache.invalidate(it) } return@withContractsInJar id } if (isUploaderTrusted(uploader)) { val session = currentDBSession() val attachment = session.get(NodeAttachmentService.DBAttachment::class.java, id.toString()) // update the `uploader` field (as the existing attachment may have been resolved from a peer) if (attachment.uploader != uploader) { attachment.uploader = uploader log.info("Updated attachment $id with uploader $uploader") contractClassNames.forEach { contractsCache.invalidate(it) } loadAttachmentContent(id)?.let { attachmentAndContent -&gt; // TODO: this is racey. ENT-2870 attachmentContentCache.put(id, Optional.of(attachmentAndContent)) attachmentCache.put(id, Optional.of(attachmentAndContent.first)) } return@withContractsInJar id } // If the uploader is the same, throw the exception because the attachment cannot be overridden by the same uploader. } throw DuplicateAttachmentException(id.toString())</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService$val attachmentImpl = AttachmentImpl(id, { attachment.content }, checkAttachmentsOnLoad, attachment.uploader).let { val contracts = attachment.contractClassNames if (contracts != null &amp;&amp; contracts.isNotEmpty()) { ContractAttachment.create(it, contracts.first(), contracts.drop(1).toSet(), attachment.uploader, attachment.signers?.toList() ?: emptyList(), attachment.version) } else { it } }</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService$val attachmentQueryCriteria = AttachmentQueryCriteria.AttachmentsQueryCriteria(contractClassNamesCondition = Builder.equal(listOf(name)), versionCondition = Builder.greaterThanOrEqual(0), uploaderCondition = Builder.`in`(TRUSTED_UPLOADERS))</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService$val attachmentSort = AttachmentSort(listOf(AttachmentSort.AttachmentSortColumn(AttachmentSort.AttachmentSortAttribute.VERSION, Sort.Direction.DESC), AttachmentSort.AttachmentSortColumn(AttachmentSort.AttachmentSortAttribute.INSERTION_DATE, Sort.Direction.DESC)))</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService$val contractVersion = increaseDefaultVersionIfWhitelistedAttachment(contractClassNames, getVersion(bytes), id)</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService$val versions = contractClassNames.mapNotNull { servicesForResolution.networkParameters.whitelistedContractImplementations[it]?.indexOf(attachmentId) } .filter { it &gt;= 0 }.map { it + 1 } // +1 as versions starts from 1 not 0</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService$weigher = Weigher&lt;SecureHash, Optional&lt;Pair&lt;Attachment, ByteArray&gt;&gt;&gt; { key, value -&gt; key.size + if (value.isPresent) value.get().second.size else 0 }</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService${ val session = currentDBSession() val attachment = session.get(NodeAttachmentService.DBAttachment::class.java, id.toString()) // update the `uploader` field (as the existing attachment may have been resolved from a peer) if (attachment.uploader != uploader) { attachment.uploader = uploader log.info("Updated attachment $id with uploader $uploader") contractClassNames.forEach { contractsCache.invalidate(it) } loadAttachmentContent(id)?.let { attachmentAndContent -&gt; // TODO: this is racey. ENT-2870 attachmentContentCache.put(id, Optional.of(attachmentAndContent)) attachmentCache.put(id, Optional.of(attachmentAndContent.first)) } return@withContractsInJar id } // If the uploader is the same, throw the exception because the attachment cannot be overridden by the same uploader. }</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService.AttachmentImpl$private</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService.AttachmentImpl$return if (checkOnLoad &amp;&amp; id is SecureHash.SHA256) HashCheckingStream(id, attachmentData.size, stream) else stream</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService.AttachmentImpl.Token$override fun fromToken(context: SerializeAsTokenContext)</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService.AttachmentImpl.Token$private</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService.Companion$// Just iterate over the entries with verification enabled: should be good enough to catch mistakes. // Note that JarInputStream won't throw any kind of error at all if the file stream is in fact not // a ZIP! It'll just pretend it's an empty archive, which is kind of stupid but that's how it works. // So we have to check to ensure we found at least one item. // // For signed Jars add additional checks to close security holes left by the default jarSigner verifier: // - All entries listed in the Manifest are in the JAR file. // - No extra files in the JAR that were not listed in the Manifest. // Together with the check that all entries need to be signed by the same signers that is performed when the signers are read, // it should close any possibility of foul play. internal fun checkIsAValidJAR(stream: InputStream)</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService.Companion$if (manifestHasEntries &amp;&amp; !allManifestEntries!!.remove(cursor.name)) extraFilesNotFoundInEntries.add(cursor)</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService.Companion$private val PRIVILEGED_UPLOADERS = listOf(DEPLOYED_CORDAPP_UPLOADER, RPC_UPLOADER, P2P_UPLOADER, UNKNOWN_UPLOADER)</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService.Companion$require(!('\\' in cursor.name || cursor.name == "." || cursor.name == "..")) { "Bad character in $entryPath" }</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService.Companion$throw SecurityException("Signed jar has been tampered with. Files ${allManifestEntries} have been removed.")</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService.Companion$throw SecurityException("Signed jar has been tampered with. Files ${extraSignableFiles} have been added to the JAR.")</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService.Companion$val extraSignableFiles = extraFilesNotFoundInEntries.filterNot { JarSignatureCollector.isNotSignable(it) }</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService.DBAttachment$( @Id @Column(name = "att_id", nullable = false) var attId: String, @Column(name = "content", nullable = false) @Lob var content: ByteArray, @Column(name = "insertion_date", nullable = false, updatable = false) var insertionDate: Instant = Instant.now(), @Column(name = "uploader", nullable = true) var uploader: String? = null, @Column(name = "filename", updatable = false, nullable = true) var filename: String? = null, @ElementCollection @Column(name = "contract_class_name", nullable = false) @CollectionTable(name = "${NODE_DATABASE_PREFIX}attachments_contracts", joinColumns = [(JoinColumn(name = "att_id", referencedColumnName = "att_id"))], foreignKey = ForeignKey(name = "FK__ctr_class__attachments")) var contractClassNames: List&lt;ContractClassName&gt;? = null, @ElementCollection(targetClass = PublicKey::class, fetch = FetchType.EAGER) @Column(name = "signer", nullable = false) @CollectionTable(name = "${NODE_DATABASE_PREFIX}attachments_signers", joinColumns = [(JoinColumn(name = "att_id", referencedColumnName = "att_id"))], foreignKey = ForeignKey(name = "FK__signers__attachments")) var signers: List&lt;PublicKey&gt;? = null, // Assumption: only Contract Attachments are versioned, version unknown or value for other attachments other than Contract Attachment defaults to 1 @Column(name = "version", nullable = false) var version: Int = DEFAULT_CORDAPP_VERSION )</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService.DBAttachment$@CollectionTable(name = "${NODE_DATABASE_PREFIX}attachments_contracts", joinColumns = [(JoinColumn(name = "att_id", referencedColumnName = "att_id"))], foreignKey = ForeignKey(name = "FK__ctr_class__attachments"))</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService.DBAttachment$@CollectionTable(name = "${NODE_DATABASE_PREFIX}attachments_signers", joinColumns = [(JoinColumn(name = "att_id", referencedColumnName = "att_id"))], foreignKey = ForeignKey(name = "FK__signers__attachments"))</ID>
    <ID>MaxLineLength:NodeAttachmentService.kt$NodeAttachmentService.HashCheckingStream$private val stream: HashingInputStream = HashingInputStream(Hashing.sha256(), counter)</ID>
    <ID>MaxLineLength:NodeCmdLineOptions.kt$InitialRegistrationCmdLineOptions$"Cannot perform initial registration when 'devMode' is true, unless 'devModeOptions.allowCompatibilityZone' is also true."</ID>
    <ID>MaxLineLength:NodeCmdLineOptions.kt$InitialRegistrationCmdLineOptions$"compatibilityZoneURL or networkServices must be present in the node configuration file in registration mode."</ID>
    <ID>MaxLineLength:NodeCmdLineOptions.kt$NodeCmdLineOptions$"compatibilityZoneURL or networkServices must be present in the node configuration file in registration mode."</ID>
    <ID>MaxLineLength:NodeCmdLineOptions.kt$NodeCmdLineOptions$description = ["DEPRECATED. Clears local copy of network map, on node startup it will be restored from server or file system."]</ID>
    <ID>MaxLineLength:NodeCmdLineOptions.kt$NodeCmdLineOptions$description = ["DEPRECATED. Performs the node start-up tasks necessary to generate the nodeInfo file, saves it to disk, then exits."]</ID>
    <ID>MaxLineLength:NodeCmdLineOptions.kt$NodeCmdLineOptions$description = ["DEPRECATED. Starts initial node registration with Corda network to obtain certificate from the permissioning server."]</ID>
    <ID>MaxLineLength:NodeCmdLineOptions.kt$NodeCmdLineOptions$valid(ConfigHelper.loadConfig(baseDirectory, configFile, configOverrides = ConfigFactory.parseMap(configOverrides)))</ID>
    <ID>MaxLineLength:NodeConfiguration.kt$CertChainPolicyConfig$@Deprecated("Do not use") data</ID>
    <ID>MaxLineLength:NodeConfiguration.kt$DevModeOptions$data</ID>
    <ID>MaxLineLength:NodeConfiguration.kt$NetworkParameterAcceptanceSettings</ID>
    <ID>MaxLineLength:NodeConfiguration.kt$NodeConfiguration$@Deprecated(message = "Use of single compatibility zone URL is deprecated", replaceWith = ReplaceWith("networkServices.networkMapURL"))</ID>
    <ID>MaxLineLength:NodeConfiguration.kt$NodeConfiguration$val flowMonitorSuspensionLoggingThresholdMillis: Duration get() = DEFAULT_FLOW_MONITOR_SUSPENSION_LOGGING_THRESHOLD_MILLIS</ID>
    <ID>MaxLineLength:NodeConfiguration.kt$SecurityConfiguration.AuthService.DataSource$AuthDataSourceType.DB -&gt; require(users == null &amp;&amp; connection != null) { "Database-backed authentication must not specify a user list, and must configure a database" }</ID>
    <ID>MaxLineLength:NodeConfiguration.kt$SecurityConfiguration.AuthService.DataSource$AuthDataSourceType.INMEMORY -&gt; require(users != null &amp;&amp; connection == null) { "In-memory authentication must specify a user list, and must not configure a database" }</ID>
    <ID>MaxLineLength:NodeConfiguration.kt$fun Config.parseAsNodeConfiguration(options: Configuration.Validation.Options = Configuration.Validation.Options(strict = true)): Valid&lt;NodeConfiguration&gt;</ID>
    <ID>MaxLineLength:NodeConfigurationImpl.kt$NodeConfigurationImpl$// TODO: There are two implications here: // 1. "signingCertificateStore" and "p2pKeyStore" have the same passwords. In the future we should re-visit this "rule" and see of they can be made different; // 2. The passwords for store and for keys in this store are the same, this is due to limitations of Artemis. override val signingCertificateStore = FileBasedCertificateStoreSupplier(signingCertificateStorePath, keyStorePassword, keyStorePassword)</ID>
    <ID>MaxLineLength:NodeConfigurationImpl.kt$NodeConfigurationImpl$@Suppress("DEPRECATION") @Deprecated("Do not configure") override</ID>
    <ID>MaxLineLength:NodeConfigurationImpl.kt$NodeConfigurationImpl$logger</ID>
    <ID>MaxLineLength:NodeConfigurationImpl.kt$NodeConfigurationImpl$logger.warn("Top-level declaration of property 'rpcAddress' is deprecated. Please use 'rpcSettings.address' instead.")</ID>
    <ID>MaxLineLength:NodeConfigurationImpl.kt$NodeConfigurationImpl$override</ID>
    <ID>MaxLineLength:NodeConfigurationImpl.kt$NodeConfigurationImpl$override val flowMonitorSuspensionLoggingThresholdMillis: Duration = Defaults.flowMonitorSuspensionLoggingThresholdMillis</ID>
    <ID>MaxLineLength:NodeConfigurationImpl.kt$NodeConfigurationImpl$override val networkParameterAcceptanceSettings: NetworkParameterAcceptanceSettings = Defaults.networkParameterAcceptanceSettings</ID>
    <ID>MaxLineLength:NodeConfigurationImpl.kt$NodeConfigurationImpl$private val p2pTrustStore = FileBasedCertificateStoreSupplier(p2pTrustStoreFilePath, trustStorePassword, trustStorePassword)</ID>
    <ID>MaxLineLength:NodeConfigurationImpl.kt$NodeConfigurationImpl$require(h2port == null || h2Settings == null) { "Cannot specify both 'h2port' and 'h2Settings' in configuration" }</ID>
    <ID>MaxLineLength:NodeConfigurationImpl.kt$NodeConfigurationImpl$require(rpcSettings.address == null) { "Can't provide top-level rpcAddress and rpcSettings.address (they control the same property)." }</ID>
    <ID>MaxLineLength:NodeConfigurationImpl.kt$NodeConfigurationImpl$return listOf("cannot specify 'compatibilityZoneURL' when 'devMode' is true, unless 'devModeOptions.allowCompatibilityZone' is also true")</ID>
    <ID>MaxLineLength:NodeConfigurationImpl.kt$NodeConfigurationImpl$return listOf("cannot specify 'networkServices' when 'devMode' is true, unless 'devModeOptions.allowCompatibilityZone' is also true")</ID>
    <ID>MaxLineLength:NodeConfigurationImpl.kt$NodeConfigurationImpl.Defaults$initialiseAppSchema = if(devMode) SchemaInitializationType.UPDATE else SchemaInitializationType.VALIDATE</ID>
    <ID>MaxLineLength:NodeConfigurationImpl.kt$NodeConfigurationImpl.Defaults$val flowMonitorSuspensionLoggingThresholdMillis: Duration = NodeConfiguration.DEFAULT_FLOW_MONITOR_SUSPENSION_LOGGING_THRESHOLD_MILLIS</ID>
    <ID>MaxLineLength:NodeConfigurationImpl.kt$NodeConfigurationImpl.Defaults$val networkParameterAcceptanceSettings: NetworkParameterAcceptanceSettings = NetworkParameterAcceptanceSettings()</ID>
    <ID>MaxLineLength:NodeConfigurationImpl.kt$NodeRpcSettings.&lt;no name provided&gt;$return "address: $address, adminAddress: $adminAddress, standAloneBroker: $standAloneBroker, useSsl: $useSsl, sslConfig: $sslConfig"</ID>
    <ID>MaxLineLength:NodeInfoSchema.kt$NodeInfoSchemaV1$mappedTypes = listOf(PersistentNodeInfo::class.java, DBPartyAndCertificate::class.java, DBHostAndPort::class.java, NodePropertiesPersistentStore.DBNodeProperty::class.java)</ID>
    <ID>MaxLineLength:NodeInfoSchema.kt$NodeInfoSchemaV1.DBPartyAndCertificate$@ManyToMany(mappedBy = "legalIdentitiesAndCerts", cascade = [(CascadeType.ALL)])</ID>
    <ID>MaxLineLength:NodeInfoSchema.kt$NodeInfoSchemaV1.PersistentNodeInfo$(this.legalIdentitiesAndCerts.filter { it.isMain } + this.legalIdentitiesAndCerts.filter { !it.isMain }).map { it.toLegalIdentityAndCert() }</ID>
    <ID>MaxLineLength:NodeInfoSchema.kt$NodeInfoSchemaV1.PersistentNodeInfo$inverseJoinColumns = [(JoinColumn(name = "party_name", foreignKey = ForeignKey(name = "FK__link_ni_p__info_p_cert")))]</ID>
    <ID>MaxLineLength:NodeInfoSchema.kt$NodeInfoSchemaV1.PersistentNodeInfo$joinColumns = [(JoinColumn(name = "node_info_id", foreignKey = ForeignKey(name = "FK__link_nodeinfo_party__infos")))]</ID>
    <ID>MaxLineLength:NodeInfoWatcher.kt$NodeInfoWatcher$ fun nodeInfoUpdates(): Observable&lt;List&lt;NodeInfoUpdate&gt;&gt;</ID>
    <ID>MaxLineLength:NodeInfoWatcher.kt$NodeInfoWatcher$nodeInfoFilesMap[file] = NodeInfoFromFile(nodeInfoSigned.signed.raw.hash, file.lastModifiedTime())</ID>
    <ID>MaxLineLength:NodeInfoWatcher.kt$NodeInfoWatcher$val newOrChangedFile = previousLastModifiedTime == null || lastModifiedTime &gt; previousLastModifiedTime</ID>
    <ID>MaxLineLength:NodeInfoWatcher.kt$NodeInfoWatcher.Companion${ // By using the hash of the node's first name we ensure: // 1) node info files for the same node map to the same filename and thus avoid having duplicate files for // the same node // 2) avoid having to deal with characters in the X.500 name which are incompatible with the local filesystem val fileNameHash = nodeInfoAndSigned.nodeInfo.legalIdentities[0].name.serialize().hash nodeInfoAndSigned .signed .serialize() .open() .copyTo(path / "${NodeInfoFilesCopier.NODE_INFO_FILE_NAME_PREFIX}$fileNameHash", REPLACE_EXISTING) }</ID>
    <ID>MaxLineLength:NodeNamedCache.kt$DefaultNamedCacheFactory$name == "HibernateConfiguration_sessionFactories" -&gt; caffeine.maximumSize(database.mappedSchemaCacheSize)</ID>
    <ID>MaxLineLength:NodeNamedCache.kt$DefaultNamedCacheFactory$name == "NodeAttachmentService_attachmentContent" -&gt; caffeine.maximumWeight(attachmentContentCacheSizeBytes)</ID>
    <ID>MaxLineLength:NodeNamedCache.kt$DefaultNamedCacheFactory$name.startsWith("RPCSecurityManagerShiroCache_") -&gt; with(security?.authService?.options?.cache!!) { caffeine.maximumSize(maxEntries).expireAfterWrite(expireAfterSecs, TimeUnit.SECONDS) }</ID>
    <ID>MaxLineLength:NodeNamedCache.kt$DefaultNamedCacheFactory$open</ID>
    <ID>MaxLineLength:NodeNamedCache.kt$DefaultNamedCacheFactory$override</ID>
    <ID>MaxLineLength:NodeNamedCache.kt$DefaultNamedCacheFactory$override fun bindWithConfig(nodeConfiguration: NodeConfiguration): BindableNamedCacheFactory</ID>
    <ID>MaxLineLength:NodeNamedCache.kt$DefaultNamedCacheFactory$override fun bindWithMetrics(metricRegistry: MetricRegistry): BindableNamedCacheFactory</ID>
    <ID>MaxLineLength:NodePropertiesPersistentStore.kt$FlowsDrainingModeOperationsImpl : FlowsDrainingModeOperations</ID>
    <ID>MaxLineLength:NodePropertiesPersistentStore.kt$NodePropertiesPersistentStore : NodePropertiesStore</ID>
    <ID>MaxLineLength:NodeSchedulerService.kt$NodeSchedulerService : SchedulerServiceAutoCloseableSingletonSerializeAsToken</ID>
    <ID>MaxLineLength:NodeSchedulerService.kt$NodeSchedulerService$nextScheduledAction = schedulerRepo.getLatest(deduplicate.size + 1).firstOrNull { !deduplicate.contains(it.second) }?.second</ID>
    <ID>MaxLineLength:NodeSchedulerService.kt$NodeSchedulerService$private val schedulerRepo: ScheduledFlowRepository = PersistentScheduledFlowRepository(database)</ID>
    <ID>MaxLineLength:NodeSchedulerService.kt$NodeSchedulerService$val deduplicate = HashSet(startingStateRefs) // Take an immutable copy to remove races with afterDatabaseCommit.</ID>
    <ID>MaxLineLength:NodeSchedulerService.kt$NodeSchedulerService${ // We are earliest rescheduleWakeUp() }</ID>
    <ID>MaxLineLength:NodeSchedulerService.kt$NodeSchedulerService${ log.trace { "Scheduler starting FlowLogic $flowLogic" } //Add this to the in memory list of starting refs so it is not picked up on the next rescheduleWakeUp() startingStateRefs.add(scheduledState) flowLogic }</ID>
    <ID>MaxLineLength:NodeSchedulerService.kt$NodeSchedulerService.Companion$ // We should try to make the Clock used in our code injectable (for tests etc) and to use the extension below // to wait in our code, rather than &lt;code&gt;Thread.sleep()&lt;/code&gt; or other time-based pauses. @Suspendable @VisibleForTesting // We specify full classpath on SettableFuture to differentiate it from the Quasar class of the same name fun awaitWithDeadline(clock: CordaClock, deadline: Instant, future: Future&lt;*&gt; = GuavaSettableFuture.create&lt;Any&gt;()): Boolean</ID>
    <ID>MaxLineLength:NodeSchedulerService.kt$NodeSchedulerService.Companion$ private fun &lt;T : Any&gt; makeStrandFriendlySettableFuture(future: Future&lt;T&gt;)</ID>
    <ID>MaxLineLength:NodeSchedulerService.kt$NodeSchedulerService.Companion$private</ID>
    <ID>MaxLineLength:NodeSchedulerService.kt$NodeSchedulerService.Companion${ // This will return when it times out, or when the clock mutates or when when the original future completes. originalFutureCompleted.get(nanos, TimeUnit.NANOSECONDS) }</ID>
    <ID>MaxLineLength:NodeSchedulerService.kt$NodeSchedulerService.FlowStartDeduplicationHandler$private inner</ID>
    <ID>MaxLineLength:NodeSchemaService.kt$NodeSchemaService : SchemaServiceSingletonSerializeAsToken</ID>
    <ID>MaxLineLength:NodeSchemaService.kt$NodeSchemaService$fun internalSchemas()</ID>
    <ID>MaxLineLength:NodeSchemaService.kt$NodeSchemaService$override val schemaOptions: Map&lt;MappedSchema, SchemaService.SchemaOptions&gt; = requiredSchemas + extraSchemas.associateBy({ it }, { SchemaOptions() })</ID>
    <ID>MaxLineLength:NodeSchemaService.kt$NodeSchemaService$return VaultSchemaV1.VaultFungibleStates(owner = null, quantity = state.amount.quantity, issuer = null, issuerRef = null)</ID>
    <ID>MaxLineLength:NodeSchemaService.kt$NodeSchemaService$return VaultSchemaV1.VaultFungibleStates(state.owner, state.amount.quantity, state.amount.token.issuer.party, state.amount.token.issuer.reference)</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeCliCommand$abstract</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartup$"""\____/ /_/ \__,_/\__,_/"""</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartup$"Check your contracts carefully. The fine print\nis usually a clause for suspicion ${Emoji.santaClaus}"</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartup$"How did my parents fight boredom before the internet?\nI asked my 17 siblings and they didn't know either."</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartup$"My boss asked me who is the stupid one, me or him?\nI said everyone knows he doesn't hire stupid people."</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartup$"Please see https://docs.corda.net/troubleshooting.html#slow-localhost-resolution for information on how to fix this. "</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartup$"The good thing about lending out your time machine\nis that you basically get it back immediately."</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartup$"Your computer took over a second to resolve localhost due an incorrect configuration. Corda will work but start very slowly until this is fixed. "</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartup$Node.printWarning("This node is running in development mode! ${Emoji.developer} This is not safe for production deployment.")</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartup$fun initialiseAndRun(cmdLineOptions: SharedNodeCmdLineOptions, afterNodeInitialisation: RunAfterNodeInitialisation, requireCertificates: Boolean = false): Int</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartup$if (attempt { banJavaSerialisation(configuration) }.doOnFailure(Consumer { error -&gt; error.logAsUnexpected("Exception while configuring serialisation") }) !is Try.Success) return ExitCodes.FAILURE</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartup$if (attempt { preNetworkRegistration(configuration) }.doOnFailure(Consumer(::handleRegistrationError)) !is Try.Success) return ExitCodes.FAILURE</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartup$if (requireCertificates &amp;&amp; !canReadCertificatesDirectory(configuration.certificatesDirectory, configuration.devMode)) return ExitCodes.FAILURE</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartup$logger.info("The Corda node is running in production mode. If this is a developer environment you can set 'devMode=true' in the node.conf file.")</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartup$logger.warn("${it.info} will be unable to run on Corda in the future due to missing entries in JAR's manifest file.")</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartup$nodeStartedMessage = "$nodeStartedMessage with additional Network Map keys ${conf.extraNetworkMapKeys.joinToString(prefix = "[", postfix = "]", separator = ", ")}"</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartup$printError("Unable to access certificates directory ${certDirectory}. This could be because the node has not been registered with the Identity Operator.")</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartup$println("Application user '$appUser' does not have necessary permissions for Node base directory '$baseDirectory'.")</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartup$println("Corda Node process in now exiting. Please check directory permissions and try starting the Node again.")</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartup$val configuration = cmdLineOptions.parseConfiguration(rawConfig).doIfValid { logRawConfig(rawConfig) }.doOnErrors(::logConfigurationErrors).optional ?: return ExitCodes.FAILURE</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartup.Companion$private val logger by lazy { loggerFor&lt;Node&gt;() } // I guess this is lazy to allow for logging init, but why Node?</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartupCli$Node.printWarning("The --clear-network-map-cache flag has been deprecated and will be removed in a future version. Use the clear-network-cache command instead.")</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartupCli$Node.printWarning("The --initial-registration flag has been deprecated and will be removed in a future version. Use the initial-registration command instead.")</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartupCli$Node.printWarning("The --just-generate-node-info flag has been deprecated and will be removed in a future version. Use the generate-node-info command instead.")</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartupCli$Node.printWarning("The --just-generate-rpc-ssl-settings flag has been deprecated and will be removed in a future version. Use the generate-rpc-ssl-settings command instead.")</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartupCli$initialRegistrationCli.networkRootTrustStorePathParameter = cmdLineOptions.networkRootTrustStorePathParameter</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartupCli$override fun additionalSubCommands()</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartupCli$println("Node was started before in `initial-registration` mode, but the registration was not completed.\nResuming registration.")</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartupCli$requireNotNull(cmdLineOptions.networkRootTrustStorePassword) { "Network root trust store password must be provided in registration mode using --network-root-truststore-password." }</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartupLogging$error is Errors.NativeIoException &amp;&amp; error.message?.contains("Address already in use") == true -&gt; error.logAsExpected("One of the ports required by the Corda node is already in use.")</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartupLogging$error is Errors.NativeIoException &amp;&amp; error.message?.contains("Can't assign requested address") == true -&gt; error.logAsExpected("Exception during node startup. Check that addresses in node config resolve correctly.")</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartupLogging$error is UnresolvedAddressException -&gt; error.logAsExpected("Exception during node startup. Check that addresses in node config resolve correctly.")</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartupLogging$error.isOpenJdkKnownIssue() -&gt; error.logAsExpected("Exception during node startup - ${error.message}. This is a known OpenJDK issue on some Linux distributions, please use OpenJDK from zulu.org or Oracle JDK.")</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartupLogging$fun Throwable.logAsExpected(message: String? = this.message, print: (String?) -&gt; Unit = logger::error)</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartupLogging$fun Throwable.logAsUnexpected(message: String? = this.message, error: Throwable = this, print: (String?, Throwable) -&gt; Unit = logger::error)</ID>
    <ID>MaxLineLength:NodeStartup.kt$NodeStartupLogging.Companion$val startupErrors = setOf(MultipleCordappsForFlowException::class, CheckpointIncompatibleException::class, AddressBindingException::class, NetworkParametersReader::class, DatabaseIncompatibleException::class)</ID>
    <ID>MaxLineLength:NodeStartup.kt$System.setProperty("defaultLogLevel", specifiedLogLevel)</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$ @Throws(VaultQueryException::class) override fun &lt;T : ContractState&gt; _trackBy(criteria: QueryCriteria, paging: PageSpecification, sorting: Sort, contractStateType: Class&lt;out T&gt;): DataFeed&lt;Vault.Page&lt;T&gt;, Vault.Update&lt;T&gt;&gt;</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$ private fun &lt;T: ContractState&gt; hasBeenSeen(update: Vault.Update&lt;T&gt;, snapshotStatesRefs: Set&lt;StateRef&gt;, snapshotConsumedStatesRefs: Set&lt;StateRef&gt;): Boolean</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$// Only update the state if it has not previously been consumed (this could have happened if the transaction is being // re-recorded. if (stateStatus != Vault.StateStatus.CONSUMED) { stateStatus = Vault.StateStatus.CONSUMED consumedTime = clock.instant() // remove lock (if held) if (lockId != null) { lockId = null lockUpdateTime = clock.instant() log.trace("Releasing soft lock on consumed state: $stateRef") } session.save(state) }</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$// Returns only output states that can be deserialised successfully. fun WireTransaction.deserializableOutputStates(): Map&lt;Int, TransactionState&lt;ContractState&gt;&gt;</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$// Returns only reference states that can be deserialised successfully. fun LedgerTransaction.deserializableRefStates(): Map&lt;Int, StateAndRef&lt;ContractState&gt;&gt;</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$@Throws(VaultQueryException::class) override</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$@Throws(VaultQueryException::class) private</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$Vault.Page(states = statesAndRefs, statesMetadata = statesMeta, stateTypes = criteriaParser.stateTypes, totalStatesAvailable = totalStates, otherResults = otherResults)</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$fun &lt;T&gt; withValidDeserialization(list: List&lt;T&gt;, txId: SecureHash): Map&lt;Int, T&gt;</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$fun execute(configure: Root&lt;*&gt;.(CriteriaUpdate&lt;*&gt;, Array&lt;Predicate&gt;) -&gt; Any?)</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$if (paging.pageNumber &lt; DEFAULT_PAGE_NUM) throw VaultQueryException("Page specification: invalid page number ${paging.pageNumber} [page numbers start from $DEFAULT_PAGE_NUM]")</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$if (paging.pageSize &lt; 1) throw VaultQueryException("Page specification: invalid page size ${paging.pageSize} [minimum is 1]")</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$if (paging.pageSize &gt; MAX_PAGE_SIZE) throw VaultQueryException("Page specification: invalid page size ${paging.pageSize} [maximum is $MAX_PAGE_SIZE]")</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$isRelevant(value.data, keyManagementService.filterMyKeys(outputs.values.flatMap { it.data.participants.map { it.owningKey } }).toSet())</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$log.debug { "Vault Query for contract type: $contractStateType, criteria: $criteria, pagination: $paging, sorting: $sorting" }</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$log.trace { "Removing $consumedStateRefs consumed contract states and adding $producedStateRefs produced contract states to the database." }</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$log.warn("There are unknown contract state types in the vault, which will prevent these states from being used. The relevant CorDapps must be loaded for these states to be used. The types not on the classpath are ${unknownTypes.joinToString(", ", "[", "]")}.")</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$log.warn("trackBy is called with an already existing, open DB transaction. As a result, there might be states missing from both the snapshot and observable, included in the returned data feed, because of race conditions.")</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$override</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$private</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$private val criteriaBuilder: CriteriaBuilder by lazy { database.hibernateConfig.sessionFactoryForRegisteredSchemas.criteriaBuilder }</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$query.maxResults = if (pageSize &gt; 0) pageSize else Integer.MAX_VALUE</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$relevancyStatus = if (isRelevant) Vault.RelevancyStatus.RELEVANT else Vault.RelevancyStatus.NOT_RELEVANT</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$return Vault.Update(consumedStateAndRefs.toSet(), producedStateAndRefs.toSet(), null, updateType, referenceStateAndRefs.toSet())</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$return Vault.Update(consumedStates.toSet(), ourNewStates.toSet(), references = newReferenceStateAndRefs.toSet())</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$return snapshotStatesRefs.containsAll(updateProducedStatesRefs) &amp;&amp; snapshotConsumedStatesRefs.containsAll(updateConsumedStatesRefs)</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$softLockingCondition = QueryCriteria.SoftLockingCondition(QueryCriteria.SoftLockingType.UNLOCKED_AND_SPECIFIED, listOf(lockId))</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$throw StatesNotAvailableException("Attempted to reserve $stateRefs for $lockId but only $updatedRows rows available")</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$throw VaultQueryException("There are ${results.size} results, which exceeds the limit of $DEFAULT_PAGE_SIZE for queries that do not specify paging. In order to retrieve these results, provide a `PageSpecification(pageNumber, pageSize)` to the method invoked.")</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$update.set(get&lt;String&gt;(VaultSchemaV1.VaultStates::lockId.name), criteriaBuilder.nullLiteral(String::class.java))</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$update.set&lt;String&gt;(get&lt;String&gt;(VaultSchemaV1.VaultStates::lockId.name), criteriaBuilder.nullLiteral(String::class.java))</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$val criteriaParser = HibernateQueryCriteriaParser(contractStateType, contractStateTypeMappings, criteriaBuilder, criteriaQuery, queryRootVaultStates)</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$val lockIdPredicate = criteriaBuilder.equal(get&lt;String&gt;(VaultSchemaV1.VaultStates::lockId.name), lockId.toString())</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$val lockUpdateTime = criteriaBuilder.equal(get&lt;Instant&gt;(VaultSchemaV1.VaultStates::lockUpdateTime.name), softLockTimestamp)</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$val myKeys by lazy { keyManagementService.filterMyKeys(ltx.outputs.flatMap { it.data.participants.map { it.owningKey } }) }</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$val persistentStateRefs = stateRefs.map { PersistentStateRef(it.txhash.bytes.toHexString(), it.index) }</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$val results = _queryBy(criteria.and(countCriteria), PageSpecification(), Sort(emptyList()), contractStateType, true) // only skip pagination checks for total results count query</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$val state = session.get&lt;VaultSchemaV1.VaultStates&gt;(VaultSchemaV1.VaultStates::class.java, PersistentStateRef(stateRef))</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$val stateOnly = stateAndRef.value.state.data // TODO: Optimise this. // // For EVERY state to be committed to the vault, this checks whether it is spendable by the recording // node. The behaviour is as follows: // // 1) All vault updates marked as RELEVANT will, of course, all have relevancy_status = 1 in the // "vault_states" table. // 2) For ALL_VISIBLE updates, those which are not relevant according to the relevancy rules will have // relevancy_status = 0 in the "vault_states" table. // // This is useful when it comes to querying for fungible states, when we do not want irrelevant states // included in the result. // // The same functionality could be obtained by passing in a list of participants to the vault query, // however this: // // * requires a join on the participants table which results in slow queries // * states may flip from being non-relevant to relevant // * it's more complicated for CorDapp developers // // Adding a new column in the "VaultStates" table was considered the best approach. val keys = stateOnly.participants.map { it.owningKey } val persistentStateRef = PersistentStateRef(stateAndRef.key) // This check is done to set the "relevancyStatus". When one performs a vault query, it is possible to return ALL states, ONLY // RELEVANT states or NOT relevant states. val isRelevant = isRelevant(stateOnly, keyManagementService.filterMyKeys(keys).toSet()) val constraintInfo = Vault.ConstraintInfo(stateAndRef.value.state.constraint) // Save a row for each party in the state_party table. // TODO: Perhaps these can be stored in a batch? stateOnly.participants.groupBy { it.owningKey }.forEach { participants -&gt; val persistentParty = VaultSchemaV1.PersistentParty(persistentStateRef, participants.value.first()) session.save(persistentParty) } val stateToAdd = VaultSchemaV1.VaultStates( notary = stateAndRef.value.state.notary, contractStateClassName = stateAndRef.value.state.data.javaClass.name, stateStatus = Vault.StateStatus.UNCONSUMED, recordedTime = clock.instant(), relevancyStatus = if (isRelevant) Vault.RelevancyStatus.RELEVANT else Vault.RelevancyStatus.NOT_RELEVANT, constraintType = constraintInfo.type(), constraintData = constraintInfo.data() ) stateToAdd.stateRef = persistentStateRef session.save(stateToAdd)</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$val stateRef = StateRef(SecureHash.parse(vaultState.stateRef!!.txId), vaultState.stateRef!!.index)</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$val stateStatusPredication = criteriaBuilder.equal(get&lt;Vault.StateStatus&gt;(VaultSchemaV1.VaultStates::stateStatus.name), Vault.StateStatus.UNCONSUMED)</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService$val txIdPredicate = criteriaBuilder.equal(vaultStates.get&lt;Vault.StateStatus&gt;(VaultSchemaV1.VaultTxnNote::txId.name), txnId.toString())</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService${ // For transactions being re-recorded, the node must check its vault to find out what states it has already seen. Note // that some of the outputs previously seen may have been consumed in the meantime, so the check must look for all state // statuses. val outputRefs = tx.outRefsOfType&lt;ContractState&gt;().map { it.ref } val seenRefs = loadStates(outputRefs).map { it.ref } val unseenRefs = outputRefs - seenRefs val unseenOutputIdxs = unseenRefs.map { it.index }.toSet() outputs.filter { it.key in unseenOutputIdxs } }</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService${ // We decrement by one if the client requests MAX_PAGE_SIZE, assuming they can not notice this because they don't have enough memory // to request `MAX_PAGE_SIZE` states at once. val paging = if (paging_.pageSize == Integer.MAX_VALUE) { paging_.copy(pageSize = Integer.MAX_VALUE - 1) } else { paging_ } log.debug { "Vault Query for contract type: $contractStateType, criteria: $criteria, pagination: $paging, sorting: $sorting" } return database.transaction { // calculate total results where a page specification has been defined var totalStates = -1L if (!skipPagingChecks &amp;&amp; !paging.isDefault) { val count = builder { VaultSchemaV1.VaultStates::recordedTime.count() } val countCriteria = QueryCriteria.VaultCustomQueryCriteria(count, Vault.StateStatus.ALL) val results = _queryBy(criteria.and(countCriteria), PageSpecification(), Sort(emptyList()), contractStateType, true) // only skip pagination checks for total results count query totalStates = results.otherResults.last() as Long } val session = getSession() val criteriaQuery = criteriaBuilder.createQuery(Tuple::class.java) val queryRootVaultStates = criteriaQuery.from(VaultSchemaV1.VaultStates::class.java) // TODO: revisit (use single instance of parser for all queries) val criteriaParser = HibernateQueryCriteriaParser(contractStateType, contractStateTypeMappings, criteriaBuilder, criteriaQuery, queryRootVaultStates) // parse criteria and build where predicates criteriaParser.parse(criteria, sorting) // prepare query for execution val query = session.createQuery(criteriaQuery) // pagination checks if (!skipPagingChecks &amp;&amp; !paging.isDefault) { // pagination if (paging.pageNumber &lt; DEFAULT_PAGE_NUM) throw VaultQueryException("Page specification: invalid page number ${paging.pageNumber} [page numbers start from $DEFAULT_PAGE_NUM]") if (paging.pageSize &lt; 1) throw VaultQueryException("Page specification: invalid page size ${paging.pageSize} [minimum is 1]") if (paging.pageSize &gt; MAX_PAGE_SIZE) throw VaultQueryException("Page specification: invalid page size ${paging.pageSize} [maximum is $MAX_PAGE_SIZE]") } // For both SQLServer and PostgresSQL, firstResult must be &gt;= 0. So we set a floor at 0. // TODO: This is a catch-all solution. But why is the default pageNumber set to be -1 in the first place? // Even if we set the default pageNumber to be 1 instead, that may not cover the non-default cases. // So the floor may be necessary anyway. query.firstResult = maxOf(0, (paging.pageNumber - 1) * paging.pageSize) val pageSize = paging.pageSize + 1 query.maxResults = if (pageSize &gt; 0) pageSize else Integer.MAX_VALUE // detection too many results, protected against overflow // execution val results = query.resultList // final pagination check (fail-fast on too many results when no pagination specified) if (!skipPagingChecks &amp;&amp; paging.isDefault &amp;&amp; results.size &gt; DEFAULT_PAGE_SIZE) { throw VaultQueryException("There are ${results.size} results, which exceeds the limit of $DEFAULT_PAGE_SIZE for queries that do not specify paging. In order to retrieve these results, provide a `PageSpecification(pageNumber, pageSize)` to the method invoked.") } val statesAndRefs: MutableList&lt;StateAndRef&lt;T&gt;&gt; = mutableListOf() val statesMeta: MutableList&lt;Vault.StateMetadata&gt; = mutableListOf() val otherResults: MutableList&lt;Any&gt; = mutableListOf() val stateRefs = mutableSetOf&lt;StateRef&gt;() results.asSequence() .forEachIndexed { index, result -&gt; if (result[0] is VaultSchemaV1.VaultStates) { if (!paging.isDefault &amp;&amp; index == paging.pageSize) // skip last result if paged return@forEachIndexed val vaultState = result[0] as VaultSchemaV1.VaultStates val stateRef = StateRef(SecureHash.parse(vaultState.stateRef!!.txId), vaultState.stateRef!!.index) stateRefs.add(stateRef) statesMeta.add(Vault.StateMetadata(stateRef, vaultState.contractStateClassName, vaultState.recordedTime, vaultState.consumedTime, vaultState.stateStatus, vaultState.notary, vaultState.lockId, vaultState.lockUpdateTime, vaultState.relevancyStatus, constraintInfo(vaultState.constraintType, vaultState.constraintData) )) } else { // TODO: improve typing of returned other results log.debug { "OtherResults: ${Arrays.toString(result.toArray())}" } otherResults.addAll(result.toArray().asList()) } } if (stateRefs.isNotEmpty()) statesAndRefs.addAll(uncheckedCast(servicesForResolution.loadStates(stateRefs))) Vault.Page(states = statesAndRefs, statesMetadata = statesMeta, stateTypes = criteriaParser.stateTypes, totalStatesAvailable = totalStates, otherResults = otherResults) } }</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService${ // When resolving transaction dependencies we might encounter contracts we haven't installed locally. // This will cause a failure as we can't deserialize such states in the context of the `appClassloader`. // For now we ignore these states. // In the future we will use the AttachmentsClassloader to correctly deserialize and asses the relevancy. log.debug { "Could not deserialize state $idx from transaction $txId. Cause: $e" } null }</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService${ val outputs: Map&lt;Int, TransactionState&lt;ContractState&gt;&gt; = tx.deserializableOutputStates() val ourNewStates = when (statesToRecord) { StatesToRecord.NONE -&gt; throw AssertionError("Should not reach here") StatesToRecord.ONLY_RELEVANT -&gt; outputs.filter { (_, value) -&gt; isRelevant(value.data, keyManagementService.filterMyKeys(outputs.values.flatMap { it.data.participants.map { it.owningKey } }).toSet()) } StatesToRecord.ALL_VISIBLE -&gt; if (previouslySeen) { // For transactions being re-recorded, the node must check its vault to find out what states it has already seen. Note // that some of the outputs previously seen may have been consumed in the meantime, so the check must look for all state // statuses. val outputRefs = tx.outRefsOfType&lt;ContractState&gt;().map { it.ref } val seenRefs = loadStates(outputRefs).map { it.ref } val unseenRefs = outputRefs - seenRefs val unseenOutputIdxs = unseenRefs.map { it.index }.toSet() outputs.filter { it.key in unseenOutputIdxs } } else { outputs } }.map { (idx, _) -&gt; tx.outRef&lt;ContractState&gt;(idx) } // Retrieve all unconsumed states for this transaction's inputs. val consumedStates = loadStates(tx.inputs) // Is transaction irrelevant? If so, then we don't care about the reference states either. if (consumedStates.isEmpty() &amp;&amp; ourNewStates.isEmpty()) { log.trace { "tx ${tx.id} was irrelevant to this vault, ignoring" } return null } // This list should only contain NEW states which we have not seen before as an output in another transaction. If we can't // obtain the references from the vault then the reference must be a state we have not seen before, therefore we should store it // in the vault. If StateToRecord is set to ALL_VISIBLE or ONLY_RELEVANT then we should store all of the previously unseen // states in the reference list. The assumption is that we might need to inspect them at some point if they were referred to // in the contracts of the input or output states. If states to record is none then we shouldn't record any reference states. val newReferenceStateAndRefs = if (tx.references.isEmpty()) { emptyList() } else { when (statesToRecord) { StatesToRecord.NONE -&gt; throw AssertionError("Should not reach here") StatesToRecord.ALL_VISIBLE, StatesToRecord.ONLY_RELEVANT -&gt; { val notSeenReferences = tx.references - loadStates(tx.references).map { it.ref } // TODO: This is expensive - is there another way? tx.toLedgerTransaction(servicesForResolution).deserializableRefStates() .filter { (_, stateAndRef) -&gt; stateAndRef.ref in notSeenReferences } .values } } } return Vault.Update(consumedStates.toSet(), ourNewStates.toSet(), references = newReferenceStateAndRefs.toSet()) }</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService.Companion$ fun isRelevant(state: ContractState, myKeys: Set&lt;PublicKey&gt;): Boolean</ID>
    <ID>MaxLineLength:NodeVaultService.kt$NodeVaultService.InnerState$// For use during publishing only. val updatesPublisher: rx.Observer&lt;Vault.Update&lt;ContractState&gt;&gt; get() = _updatesPublisher.bufferUntilDatabaseCommit().tee(_rawUpdatesPublisher)</ID>
    <ID>MaxLineLength:NodeVaultService.kt$private</ID>
    <ID>MaxLineLength:NonInvalidatingCache.kt$NonInvalidatingCache.Companion$private</ID>
    <ID>MaxLineLength:NonInvalidatingCache.kt$NonInvalidatingWeightBasedCache.Companion$private</ID>
    <ID>MaxLineLength:NonInvalidatingUnboundCache.kt$NonInvalidatingUnboundCache$constructor(name: String, cacheFactory: NamedCacheFactory, loadFunction: (K) -&gt; V, removalListener: RemovalListener&lt;K, V&gt; = RemovalListener { _, _, _ -&gt; }, keysToPreload: () -&gt; Iterable&lt;K&gt; = { emptyList() }) : this(buildCache(name, cacheFactory, loadFunction, removalListener, keysToPreload))</ID>
    <ID>MaxLineLength:NonInvalidatingUnboundCache.kt$NonInvalidatingUnboundCache.Companion$private</ID>
    <ID>MaxLineLength:NonInvalidatingUnboundCache.kt$NonInvalidatingUnboundCache.Companion$val builder = Caffeine.newBuilder().removalListener(removalListener).executor(SameThreadExecutor.getExecutor())</ID>
    <ID>MaxLineLength:NonValidatingNotaryFlow.kt$NonValidatingNotaryFlow : NotaryServiceFlow</ID>
    <ID>MaxLineLength:NonValidatingNotaryFlow.kt$NonValidatingNotaryFlow$"Notary specified by the transaction ($notary) is not on the network parameter whitelist: ${notaryWhitelist.joinToString()}"</ID>
    <ID>MaxLineLength:NonValidatingNotaryFlow.kt$NonValidatingNotaryFlow$"expected either ${FilteredTransaction::class.java.simpleName} or ${NotaryChangeWireTransaction::class.java.simpleName}"</ID>
    <ID>MaxLineLength:NonValidatingNotaryFlow.kt$NonValidatingNotaryFlow$?:</ID>
    <ID>MaxLineLength:NonValidatingNotaryFlow.kt$NonValidatingNotaryFlow$is FilteredTransaction -&gt; TransactionParts(tx.id, tx.inputs, tx.timeWindow, tx.notary, tx.references, networkParametersHash = tx.networkParametersHash)</ID>
    <ID>MaxLineLength:NonValidatingNotaryFlow.kt$NonValidatingNotaryFlow$is NotaryChangeWireTransaction</ID>
    <ID>MaxLineLength:NotaryLoader.kt$NotaryLoader$ private fun maybeInstallSerializationFilter(serviceClass: Class&lt;out NotaryService&gt;)</ID>
    <ID>MaxLineLength:NotaryLoader.kt$NotaryLoader$ private fun scanCorDapps(cordappLoader: CordappLoader): Class&lt;out NotaryService&gt;</ID>
    <ID>MaxLineLength:NotaryLoader.kt$NotaryLoader$ private fun validateNotaryType(myNotaryIdentity: PartyAndCertificate?, services: ServiceHubInternal)</ID>
    <ID>MaxLineLength:NotaryLoader.kt$NotaryLoader$+</ID>
    <ID>MaxLineLength:NotaryLoader.kt$NotaryLoader$?:</ID>
    <ID>MaxLineLength:NotaryLoader.kt$NotaryLoader$fun loadService(myNotaryIdentity: PartyAndCertificate?, services: ServiceHubInternal, cordappLoader: CordappLoader): NotaryService</ID>
    <ID>MaxLineLength:NotaryLoader.kt$NotaryLoader$throw IllegalStateException("There is a discrepancy in the configured notary type and the one advertised in the network parameters - shutting down. " + "Configured as validating: ${configuredAsValidatingNotary}. Advertised as validating: ${validatingNotaryInNetworkMapCache}")</ID>
    <ID>MaxLineLength:NotaryLoader.kt$NotaryLoader$val notaryParty = myNotaryIdentity?.party ?: throw IllegalStateException("Could not establish notary identity of this node")</ID>
    <ID>MaxLineLength:ObjectDiffer.kt$DiffTree$is Step -&gt; branches.flatMap { (step, tree) -&gt; tree.toPaths().map { it.copy(path = listOf(step) + it.path) } }</ID>
    <ID>MaxLineLength:ObjectDiffer.kt$ObjectDiffer$val branches = aFields.mapNotNull { field -&gt; diff(field.get(a), field.get(b))?.let { field.name to it } }</ID>
    <ID>MaxLineLength:P2PMessageDeduplicator.kt$P2PMessageDeduplicator$fromPersistentEntity = { Pair(DeduplicationId(it.id), MessageMeta(it.insertionTime, it.hash, it.seqNo)) }</ID>
    <ID>MaxLineLength:P2PMessageDeduplicator.kt$P2PMessageDeduplicator$private</ID>
    <ID>MaxLineLength:P2PMessageDeduplicator.kt$P2PMessageDeduplicator$private fun isDuplicateInDatabase(msg: ReceivedMessage): Boolean</ID>
    <ID>MaxLineLength:P2PMessageDeduplicator.kt$P2PMessageDeduplicator$val senderHash: String? = if (receivedSenderUUID != null &amp;&amp; receivedSenderSeqNo != null) senderHash(SenderKey(receivedSenderUUID, msg.peer, msg.isSessionInit)) else null</ID>
    <ID>MaxLineLength:P2PMessagingClient.kt$P2PMessagingClient : SingletonSerializeAsTokenMessagingServiceAddressToArtemisQueueResolver</ID>
    <ID>MaxLineLength:P2PMessagingClient.kt$P2PMessagingClient$ fun start(myIdentity: PublicKey, serviceIdentity: PublicKey?, maxMessageSize: Int, advertisedAddress: NetworkHostAndPort = serverAddress)</ID>
    <ID>MaxLineLength:P2PMessagingClient.kt$P2PMessagingClient$// Never time out on our loopback Artemis connections. If we switch back to using the InVM transport this // would be the default and the two lines below can be deleted. connectionTTL = 60000 clientFailureCheckPeriod = 30000 minLargeMessageSize = maxMessageSize + JOURNAL_HEADER_SIZE isUseGlobalPools = nodeSerializationEnv != null</ID>
    <ID>MaxLineLength:P2PMessagingClient.kt$P2PMessagingClient$deliverTo(msg, HandlerRegistration(msg.topic, deliverTo), MessageDeduplicationHandler(artemisMessage, msg))</ID>
    <ID>MaxLineLength:P2PMessagingClient.kt$P2PMessagingClient$log.trace { "Received message from: ${message.address} user: $user topic: $topic id: $uniqueMessageId senderUUID: $receivedSenderUUID senderSeqNo: $receivedSenderSeqNo isSessionInit: $isSessionInit" }</ID>
    <ID>MaxLineLength:P2PMessagingClient.kt$P2PMessagingClient$log.warn("Received message ${msg.uniqueMessageId} for ${msg.topic} that doesn't have any registered handlers yet")</ID>
    <ID>MaxLineLength:P2PMessagingClient.kt$P2PMessagingClient$override</ID>
    <ID>MaxLineLength:P2PMessagingClient.kt$P2PMessagingClient$p2pConsumer = P2PMessagingConsumer(inboxes, createNewSession, isDrainingModeOn, drainingModeWasChangedEvents, metricRegistry)</ID>
    <ID>MaxLineLength:P2PMessagingClient.kt$P2PMessagingClient$p2pConsumer!!.messages // this `run()` method is semantically meant to block until the message consumption runs, hence the latch here .doOnCompleted(latch::countDown)</ID>
    <ID>MaxLineLength:P2PMessagingClient.kt$P2PMessagingClient$return ArtemisReceivedMessage(topic, CordaX500Name.parse(user), platformVersion, uniqueMessageId, receivedSenderUUID, receivedSenderSeqNo, isSessionInit, message)</ID>
    <ID>MaxLineLength:P2PMessagingClient.kt$P2PMessagingClient$return NodeClientMessage(topic, OpaqueBytes(data), deduplicationId.deduplicationId, deduplicationId.senderUUID, additionalHeaders)</ID>
    <ID>MaxLineLength:P2PMessagingClient.kt$P2PMessagingClient$throw IllegalStateException("Cannot add another acking handler for $topic, there is already an acking one")</ID>
    <ID>MaxLineLength:P2PMessagingClient.kt$P2PMessagingClient$val createNewSession = { sessionFactory!!.createSession(ArtemisMessagingComponent.NODE_P2P_USER, ArtemisMessagingComponent.NODE_P2P_USER, false, true, true, false, ActiveMQClient.DEFAULT_ACK_BATCH_SIZE) }</ID>
    <ID>MaxLineLength:P2PMessagingClient.kt$P2PMessagingClient$val isSessionInit = message.getStringProperty(P2PMessagingHeaders.Type.KEY) == P2PMessagingHeaders.Type.SESSION_INIT_VALUE</ID>
    <ID>MaxLineLength:P2PMessagingClient.kt$P2PMessagingClient$val receivedSenderSeqNo = if (message.containsProperty(P2PMessagingHeaders.senderSeqNo)) message.getLongProperty(P2PMessagingHeaders.senderSeqNo) else null</ID>
    <ID>MaxLineLength:P2PMessagingClient.kt$P2PMessagingClient$val uniqueMessageId = message.required(HDR_DUPLICATE_DETECTION_ID) { DeduplicationId(message.getStringProperty(it)) }</ID>
    <ID>MaxLineLength:P2PMessagingClient.kt$P2PMessagingClient${ val running = state.locked { // We allow stop() to be called without a run() in between, but it must have at least been started. check(started) val prevRunning = running running = false networkChangeSubscription?.unsubscribe() require(p2pConsumer != null, { "stop can't be called twice" }) require(producer != null, { "stop can't be called twice" }) close(p2pConsumer) p2pConsumer = null close(producer) producer = null producerSession!!.commit() close(executorProducer) executorProducer = null executorSession!!.commit() close(bridgeNotifyConsumer) knownQueues.clear() eventsSubscription?.unsubscribe() eventsSubscription = null prevRunning } synchronized(handlersChangedSignal) { handlersChangedSignal.notifyAll() } if (running &amp;&amp; !nodeExecutor.isOnThread) { // Wait for the main loop to notice the consumer has gone and finish up. shutdownLatch.await() } // Only first caller to gets running true to protect against double stop, which seems to happen in some integration tests. state.locked { locator?.close() } }</ID>
    <ID>MaxLineLength:P2PMessagingClient.kt$P2PMessagingClient.ArtemisReceivedMessage$override val data: ByteSequence by lazy { OpaqueBytes(ByteArray(message.bodySize).apply { message.bodyBuffer.readBytes(this) }) }</ID>
    <ID>MaxLineLength:P2PMessagingClient.kt$P2PMessagingClient.MessageDeduplicationHandler$private inner</ID>
    <ID>MaxLineLength:P2PMessagingClient.kt$P2PMessagingConsumer$logger.warn("Node is currently in draining mode, new flows will not be processed! Flows in flight: ${metricsRegistry.gauges["Flows.InFlight"]?.value}")</ID>
    <ID>MaxLineLength:P2PMessagingClient.kt$P2PMessagingConsumer.Companion$private const val initialSessionMessages = "${P2PMessagingHeaders.Type.KEY}&lt;&gt;'${P2PMessagingHeaders.Type.SESSION_INIT_VALUE}'"</ID>
    <ID>MaxLineLength:PathManager.kt$PathManager&lt;T : PathManager&lt;T&gt;&gt; : Closeable</ID>
    <ID>MaxLineLength:PersistentIdentityMigration.kt$PersistentIdentityMigration$generatedStatements.addAll(MigrationData(oldPkHash, partyAndCertificate).let { listOf(updateHashToIdentityRow(it, dataSource), updateNameToHashRow(it, dataSource)) })</ID>
    <ID>MaxLineLength:PersistentIdentityMigration.kt$PersistentIdentityMigration$return UpdateStatement(dataSource.connection.catalog, dataSource.connection.schema, PUB_KEY_HASH_TO_PARTY_AND_CERT_TABLE) .setWhereClause("pk_hash=?") .addNewColumnValue("pk_hash", migrationData.newPkHash) .addWhereParameter(migrationData.oldPkHash)</ID>
    <ID>MaxLineLength:PersistentIdentityMigration.kt$PersistentIdentityMigration$return UpdateStatement(dataSource.connection.catalog, dataSource.connection.schema, X500_NAME_TO_PUB_KEY_HASH_TABLE) .setWhereClause("pk_hash=? AND name=?") .addNewColumnValue("pk_hash", migrationData.newPkHash) .addWhereParameters(migrationData.oldPkHash, migrationData.x500.toString())</ID>
    <ID>MaxLineLength:PersistentIdentityMigration.kt$PersistentIdentityMigration$val partyAndCertificate = PartyAndCertificate(X509CertificateFactory().delegate.generateCertPath(identityBytes.inputStream()))</ID>
    <ID>MaxLineLength:PersistentIdentityMigrationNewTable.kt$PersistentIdentitiesMigrationSchema</ID>
    <ID>MaxLineLength:PersistentIdentityMigrationNewTable.kt$PersistentIdentitiesMigrationSchemaV1 : MappedSchema</ID>
    <ID>MaxLineLength:PersistentIdentityMigrationNewTable.kt$PersistentIdentityMigrationNewTable : CordaMigration</ID>
    <ID>MaxLineLength:PersistentIdentityMigrationNewTable.kt$PersistentIdentityMigrationNewTable$logger.info("Migrating persistent identities with certificates table into persistent table with no certificate data.")</ID>
    <ID>MaxLineLength:PersistentIdentityMigrationNewTable.kt$PersistentIdentityMigrationNewTable$throw PersistentIdentitiesMigrationException("Cannot migrate persistent states as liquibase failed to provide a suitable database connection")</ID>
    <ID>MaxLineLength:PersistentIdentityMigrationNewTable.kt$PersistentIdentityMigrationNewTable$val name = PartyAndCertificate(X509CertificateFactory().delegate.generateCertPath(partyBytes.inputStream())).party.name</ID>
    <ID>MaxLineLength:PersistentIdentityMigrationNewTable.kt$TestIdentity</ID>
    <ID>MaxLineLength:PersistentIdentityService.kt$PersistentIdentityService$ @Throws(CertificateExpiredException::class, CertificateNotYetValidException::class, InvalidAlgorithmParameterException::class) private fun verifyAndRegisterIdentity(trustAnchor: TrustAnchor, identity: PartyAndCertificate): PartyAndCertificate?</ID>
    <ID>MaxLineLength:PersistentIdentityService.kt$PersistentIdentityService$/** Stores notary identities obtained from the network parameters, for which we don't need to perform a database lookup. */ private val notaryIdentityCache = HashSet&lt;Party&gt;()</ID>
    <ID>MaxLineLength:PersistentIdentityService.kt$PersistentIdentityService$// Allows us to eliminate keys we know belong to others by using the cache contents that might have been seen during other identity activity. // Concentrating activity on the identity cache works better than spreading checking across identity and key management, because we cache misses too. fun stripNotOurKeys(keys: Iterable&lt;PublicKey&gt;): Iterable&lt;PublicKey&gt;</ID>
    <ID>MaxLineLength:PersistentIdentityService.kt$PersistentIdentityService$@Throws(CertificateExpiredException::class, CertificateNotYetValidException::class, InvalidAlgorithmParameterException::class)</ID>
    <ID>MaxLineLength:PersistentIdentityService.kt$PersistentIdentityService$@Throws(CertificateExpiredException::class, CertificateNotYetValidException::class, InvalidAlgorithmParameterException::class) private</ID>
    <ID>MaxLineLength:PersistentIdentityService.kt$PersistentIdentityService$@Throws(UnknownAnonymousPartyException::class) override</ID>
    <ID>MaxLineLength:PersistentIdentityService.kt$PersistentIdentityService$_caCertStore = CertStore.getInstance("Collection", CollectionCertStoreParameters(caCertificates.toSet() + trustRoot))</ID>
    <ID>MaxLineLength:PersistentIdentityService.kt$PersistentIdentityService$fun loadIdentities(identities: Collection&lt;PartyAndCertificate&gt; = emptySet(), confidentialIdentities: Collection&lt;PartyAndCertificate&gt; = emptySet())</ID>
    <ID>MaxLineLength:PersistentIdentityService.kt$PersistentIdentityService$fun start(trustRoot: X509Certificate, caCertificates: List&lt;X509Certificate&gt; = emptyList(), notaryIdentities: List&lt;Party&gt; = emptyList())</ID>
    <ID>MaxLineLength:PersistentIdentityService.kt$PersistentIdentityService$it.filter { x500Matches(query, exactMatch, it.first) }.map { keyToPartyAndCert[it.second]!!.party }.toSet()</ID>
    <ID>MaxLineLength:PersistentIdentityService.kt$PersistentIdentityService$log.warn("Certificate validation failed for ${identity.name} against trusted root ${trustAnchor.trustedCert.subjectX500Principal}.")</ID>
    <ID>MaxLineLength:PersistentIdentityService.kt$PersistentIdentityService$throw IllegalArgumentException("The public key ${key.hash} is already assigned to a different party than the supplied .")</ID>
    <ID>MaxLineLength:PersistentIdentityService.kt$PersistentIdentityService${ // If there is no entry in the legal keyToPartyAndCert table then the party must be a confidential identity so we perform // a lookup in the keyToName table. If an entry for that public key exists, then we attempt val name = keyToName[party.owningKey.toStringShort()] if (name != null) { wellKnownPartyFromX500Name(name) } else { null } }</ID>
    <ID>MaxLineLength:PersistentIdentityService.kt$PersistentIdentityService${ // Skip database lookup if the party is a notary identity. // This also prevents an issue where the notary identity can't be resolved if it's not in the network map cache. The node obtains // a trusted list of notary identities from the network parameters automatically. return if (party is Party &amp;&amp; party in notaryIdentityCache) { party } else { database.transaction { // Try and resolve the party from the table to public keys to party and certificates // If we cannot find it then we perform a lookup on the public key to X500 name table val legalIdentity = super.wellKnownPartyFromAnonymous(party) if (legalIdentity == null) { // If there is no entry in the legal keyToPartyAndCert table then the party must be a confidential identity so we perform // a lookup in the keyToName table. If an entry for that public key exists, then we attempt val name = keyToName[party.owningKey.toStringShort()] if (name != null) { wellKnownPartyFromX500Name(name) } else { null } } else { legalIdentity } } } }</ID>
    <ID>MaxLineLength:PersistentIdentityService.kt$PersistentIdentityService.Companion$PartyAndCertificate(X509CertificateFactory().delegate.generateCertPath(it.identity.inputStream()))</ID>
    <ID>MaxLineLength:PersistentIdentityService.kt$PersistentIdentityService.Companion$fun createKeyToPartyAndCertMap(cacheFactory: NamedCacheFactory): AppendOnlyPersistentMap&lt;String, PartyAndCertificate, PersistentPublicKeyHashToCertificate, String&gt;</ID>
    <ID>MaxLineLength:PersistentIdentityService.kt$PersistentIdentityService.Companion$fun createKeyToX500Map(cacheFactory: NamedCacheFactory): AppendOnlyPersistentMap&lt;String, CordaX500Name, PersistentPublicKeyHashToParty, String&gt;</ID>
    <ID>MaxLineLength:PersistentIdentityService.kt$PersistentIdentityService.Companion$fun createX500ToKeyMap(cacheFactory: NamedCacheFactory): AppendOnlyPersistentMap&lt;CordaX500Name, String, PersistentPartyToPublicKeyHash, String&gt;</ID>
    <ID>MaxLineLength:PersistentMap.kt$PersistentMap$ExplicitRemoval&lt;K, V, E, EK&gt; : RemovalListener</ID>
    <ID>MaxLineLength:PersistentMap.kt$PersistentMap$cache.getAll(session.createQuery(criteriaQuery).resultList.map { e -&gt; fromPersistentEntity(e as E).first }.asIterable())</ID>
    <ID>MaxLineLength:PersistentMap.kt$PersistentMap${ // This happens when the key was queried before with no value associated. We invalidate the cached null // value and recursively call set again. This is to avoid race conditions where another thread queries after // the invalidate but before the set. cache.invalidate(key) return set(key, value) }</ID>
    <ID>MaxLineLength:PersistentMap.kt$PersistentMap.NotReallyMutableEntry$private</ID>
    <ID>MaxLineLength:PersistentNetworkMapCache.kt$PersistentNetworkMapCache$"SELECT DISTINCT l FROM ${NodeInfoSchemaV1.PersistentNodeInfo::class.java.name} n JOIN n.legalIdentitiesAndCerts l WHERE l.name = :name"</ID>
    <ID>MaxLineLength:PersistentNetworkMapCache.kt$PersistentNetworkMapCache$"SELECT n FROM ${NodeInfoSchemaV1.PersistentNodeInfo::class.java.name} n JOIN n.addresses a WHERE a.host = :host AND a.port = :port"</ID>
    <ID>MaxLineLength:PersistentNetworkMapCache.kt$PersistentNetworkMapCache$"SELECT n FROM ${NodeInfoSchemaV1.PersistentNodeInfo::class.java.name} n JOIN n.legalIdentitiesAndCerts l WHERE l.name = :name"</ID>
    <ID>MaxLineLength:PersistentNetworkMapCache.kt$PersistentNetworkMapCache$"SELECT n FROM ${NodeInfoSchemaV1.PersistentNodeInfo::class.java.name} n JOIN n.legalIdentitiesAndCerts l WHERE l.owningKeyHash = :owningKeyHash"</ID>
    <ID>MaxLineLength:PersistentNetworkMapCache.kt$PersistentNetworkMapCache$logger.info("Previous node was found for ${node.legalIdentities.first().name} as: $previousNode")</ID>
    <ID>MaxLineLength:PersistentNetworkMapCache.kt$PersistentNetworkMapCache$private</ID>
    <ID>MaxLineLength:PersistentNetworkMapCache.kt$PersistentNetworkMapCache$private val identityService: IdentityService</ID>
    <ID>MaxLineLength:PersistentNetworkMapCache.kt$PersistentNetworkMapCache$val failures = node.legalIdentitiesAndCerts.mapNotNull { Try.on { it.verify(identityService.trustAnchor) } as? Try.Failure }</ID>
    <ID>MaxLineLength:PersistentNetworkMapCache.kt$PersistentNetworkMapCache$val info = findByIdentityKey(session, nodeInfo.legalIdentitiesAndCerts.first().owningKey).singleOrNull { it.serial == nodeInfo.serial }</ID>
    <ID>MaxLineLength:PersistentNetworkMapCache.kt$PersistentNetworkMapCache$where(builder.equal(get&lt;String&gt;(NodeInfoSchemaV1.PersistentNodeInfo::hash.name), nodeHash.toString()))</ID>
    <ID>MaxLineLength:PersistentNetworkMapCache.kt$PersistentNetworkMapCache${ // TODO For now the main legal identity is left in NodeInfo, this should be set comparision/come up with index for NodeInfo? val info = findByIdentityKey(session, nodeInfo.legalIdentitiesAndCerts.first().owningKey) val nodeInfoEntry = generateMappedObject(nodeInfo) if (info.isNotEmpty()) { nodeInfoEntry.id = info.first().id } session.merge(nodeInfoEntry) // invalidate cache last - this way, we might serve up the wrong info for a short time, but it will get refreshed // on the next load invalidateCaches(nodeInfo) }</ID>
    <ID>MaxLineLength:PersistentNetworkMapCache.kt$PersistentNetworkMapCache${ // findByIdentityKey might returns multiple node info with the same key, need to pick the right one by comparing serial. val info = findByIdentityKey(session, nodeInfo.legalIdentitiesAndCerts.first().owningKey).singleOrNull { it.serial == nodeInfo.serial } info?.let { session.remove(it) } // invalidate cache last - this way, we might serve up the wrong info for a short time, but it will get refreshed // on the next load invalidateCaches(nodeInfo) }</ID>
    <ID>MaxLineLength:PersistentScheduledFlowRepository.kt$PersistentScheduledFlowRepository$criteriaQuery.orderBy(session.criteriaBuilder.asc(shed.get&lt;NodeSchedulerService.PersistentScheduledState&gt;("scheduledAt")))</ID>
    <ID>MaxLineLength:PersistentScheduledFlowRepository.kt$PersistentScheduledFlowRepository$private</ID>
    <ID>MaxLineLength:PersistentScheduledFlowRepository.kt$PersistentScheduledFlowRepository$return Pair(StateRef(SecureHash.parse(txId), index), ScheduledStateRef(StateRef(SecureHash.parse(txId), index), scheduledStateRecord.scheduledAt))</ID>
    <ID>MaxLineLength:PersistentScheduledFlowRepository.kt$PersistentScheduledFlowRepository$val criteriaQuery = session.criteriaBuilder.createQuery(NodeSchedulerService.PersistentScheduledState::class.java)</ID>
    <ID>MaxLineLength:PersistentScheduledFlowRepository.kt$PersistentScheduledFlowRepository$val elem = session.find(NodeSchedulerService.PersistentScheduledState::class.java, toPersistentEntityKey(key))</ID>
    <ID>MaxLineLength:PersistentScheduledFlowRepository.kt$PersistentScheduledFlowRepository$val existingEntry = session.find(NodeSchedulerService.PersistentScheduledState::class.java, toPersistentEntityKey(value.ref))</ID>
    <ID>MaxLineLength:PersistentStateService.kt$PersistentStateService</ID>
    <ID>MaxLineLength:PersistentUniquenessProvider.kt$PersistentUniquenessProvider : UniquenessProviderSingletonSerializeAsToken</ID>
    <ID>MaxLineLength:PersistentUniquenessProvider.kt$PersistentUniquenessProvider$commitOne(request.states, request.txId, request.callerIdentity, request.requestSignature, request.timeWindow, request.references)</ID>
    <ID>MaxLineLength:PersistentUniquenessProvider.kt$PersistentUniquenessProvider$if (consumingTx != null) conflictingStates[stateRef] = StateConsumptionDetails(consumingTx.sha256(), type)</ID>
    <ID>MaxLineLength:PersistentUniquenessProvider.kt$PersistentUniquenessProvider$private</ID>
    <ID>MaxLineLength:PersistentUniquenessProvider.kt$PersistentUniquenessProvider$request.future.setException(NotaryInternalException(NotaryError.General(Exception("Internal service error."))))</ID>
    <ID>MaxLineLength:PersistentUniquenessProvider.kt$PersistentUniquenessProvider.Companion$fun createMap(cacheFactory: NamedCacheFactory): AppendOnlyPersistentMap&lt;StateRef, SecureHash, CommittedState, PersistentStateRef&gt;</ID>
    <ID>MaxLineLength:PrintingInterceptor.kt$PrintingInterceptor$val (continuation, nextState) = delegate.executeTransition(fiber, previousState, event, transition, actionExecutor)</ID>
    <ID>MaxLineLength:PrintingInterceptor.kt$PrintingInterceptor$val transitionRecord = TransitionDiagnosticRecord(Instant.now(), fiber.id, previousState, nextState, event, transition, continuation)</ID>
    <ID>MaxLineLength:PublicKeyToOwningIdentityCacheImpl.kt$PublicKeyToOwningIdentityCacheImpl : WritablePublicKeyToOwningIdentityCache</ID>
    <ID>MaxLineLength:PublicKeyToOwningIdentityCacheImpl.kt$PublicKeyToOwningIdentityCacheImpl$ override operator fun get(key: PublicKey): KeyOwningIdentity?</ID>
    <ID>MaxLineLength:PublicKeyToOwningIdentityCacheImpl.kt$PublicKeyToOwningIdentityCacheImpl$ override operator fun set(key: PublicKey, value: KeyOwningIdentity)</ID>
    <ID>MaxLineLength:PublicKeyToOwningIdentityCacheImpl.kt$PublicKeyToOwningIdentityCacheImpl$ private fun isKeyIdentityKey(key: PublicKey): Boolean</ID>
    <ID>MaxLineLength:PublicKeyToOwningIdentityCacheImpl.kt$PublicKeyToOwningIdentityCacheImpl$ private fun isKeyPartOfNodeKeyPairs(key: PublicKey): Boolean</ID>
    <ID>MaxLineLength:PublicKeyToOwningIdentityCacheImpl.kt$PublicKeyToOwningIdentityCacheImpl$criteriaBuilder.equal(queryRoot.get&lt;String&gt;(BasicHSMKeyManagementService.PersistentKey::publicKeyHash.name), key.toStringShort())</ID>
    <ID>MaxLineLength:PublicKeyToOwningIdentityCacheImpl.kt$PublicKeyToOwningIdentityCacheImpl$criteriaBuilder.equal(queryRoot.get&lt;String&gt;(PersistentIdentityService.PersistentPublicKeyHashToCertificate::publicKeyHash.name), key.toStringShort())</ID>
    <ID>MaxLineLength:PublicKeyToOwningIdentityCacheImpl.kt$PublicKeyToOwningIdentityCacheImpl$criteriaBuilder.equal(queryRoot.get&lt;String&gt;(PublicKeyHashToExternalId::publicKeyHash.name), key.toStringShort())</ID>
    <ID>MaxLineLength:PublicKeyToOwningIdentityCacheImpl.kt$PublicKeyToOwningIdentityCacheImpl$log.debug { "Attempted to find owning identity for public key ${key.toStringShort()}, but key is unknown to node" }</ID>
    <ID>MaxLineLength:PublicKeyToOwningIdentityCacheImpl.kt$PublicKeyToOwningIdentityCacheImpl$log.debug { "Database lookup for public key ${key.toStringShort()}, found signing entity $signingEntity" }</ID>
    <ID>MaxLineLength:PublicKeyToOwningIdentityCacheImpl.kt$PublicKeyToOwningIdentityCacheImpl$private val cache = cacheFactory.buildNamed&lt;PublicKey, KeyOwningIdentity&gt;(Caffeine.newBuilder(), "PublicKeyToOwningIdentityCache_cache")</ID>
    <ID>MaxLineLength:PublicKeyToOwningIdentityCacheImpl.kt$PublicKeyToOwningIdentityCacheImpl$val queryRoot = criteriaQuery.from(PersistentIdentityService.PersistentPublicKeyHashToCertificate::class.java)</ID>
    <ID>MaxLineLength:PublicKeyToTextConverter.kt$PublicKeyToTextConverter$override fun convertToEntityAttribute(text: String?): PublicKey?</ID>
    <ID>MaxLineLength:RPCSecurityManagerImpl.kt$RPCPermission$/** * Helper constructor directly setting actions and target field * * @param methods Set of allowed RPC methods * @param target An optional "target" type on which methods act */ constructor(methods: Set&lt;String&gt;, target: String? = null) : super(methods, target?.let { setOf(it.replace(".", ":")) })</ID>
    <ID>MaxLineLength:RPCSecurityManagerWithAdditionalUser.kt$RPCSecurityManagerWithAdditionalUser : RPCSecurityManager</ID>
    <ID>MaxLineLength:RPCSecurityManagerWithAdditionalUser.kt$RPCSecurityManagerWithAdditionalUser$private</ID>
    <ID>MaxLineLength:RPCServer.kt$// TODO replace this by creating a new CordaRPCImpl for each request, passing the context, after we fix Shell and WebServer @JvmField internal val CURRENT_RPC_CONTEXT: ThreadLocal&lt;RpcAuthContext&gt; = CurrentRpcContext()</ID>
    <ID>MaxLineLength:RPCServer.kt$RPCServer$consumerSession = sessionFactory!!.createSession(rpcServerUsername, rpcServerPassword, false, true, true, false, DEFAULT_ACK_BATCH_SIZE)</ID>
    <ID>MaxLineLength:RPCServer.kt$RPCServer$private</ID>
    <ID>MaxLineLength:RPCServer.kt$RPCServer$private val deduplicationChecker = DeduplicationChecker(rpcConfiguration.deduplicationCacheExpiry, cacheFactory = cacheFactory)</ID>
    <ID>MaxLineLength:RPCServer.kt$RPCServer$producerSession = sessionFactory!!.createSession(rpcServerUsername, rpcServerPassword, false, true, true, false, DEFAULT_ACK_BATCH_SIZE)</ID>
    <ID>MaxLineLength:RPCServer.kt$RPCServer$require(notificationType == CoreNotificationType.BINDING_ADDED.name){"Message contained notification type of $notificationType instead of expected ${CoreNotificationType.BINDING_ADDED.name}"}</ID>
    <ID>MaxLineLength:RPCServer.kt$RPCServer$require(notificationType == CoreNotificationType.BINDING_REMOVED.name){"Message contained notification type of $notificationType instead of expected ${CoreNotificationType.BINDING_REMOVED.name}"}</ID>
    <ID>MaxLineLength:RPCServer.kt$RPCServer$return Pair(Actor(Id(validatedUser), securityManager.id, targetLegalIdentity), securityManager.buildSubject(validatedUser))</ID>
    <ID>MaxLineLength:RPCServer.kt$RPCServer$return RpcAuthContext(InvocationContext.rpc(rpcActor.first, trace, externalTrace, impersonatedActor), rpcActor.second)</ID>
    <ID>MaxLineLength:RPCServer.kt$RPCServer$return cacheFactory.buildNamed(Caffeine.newBuilder().removalListener(onObservableRemove).executor(SameThreadExecutor.getExecutor()), "RPCServer_observableSubscription")</ID>
    <ID>MaxLineLength:RPCServer.kt$RPCServer$throw RPCException("Received RPC for unknown method $methodName - possible client/server version skew?")</ID>
    <ID>MaxLineLength:RPCServer.kt$RPCServer$val deduplicationSequenceNumber = artemisMessage.getLongProperty(RPCApi.DEDUPLICATION_SEQUENCE_NUMBER_FIELD_NAME)</ID>
    <ID>MaxLineLength:RPCServer.kt$RPCServer$val targetLegalIdentity = message.getStringProperty(RPCApi.RPC_TARGET_LEGAL_IDENTITY)?.let(CordaX500Name.Companion::parse) ?: nodeLegalName</ID>
    <ID>MaxLineLength:RPCServer.kt$RPCServer$val validatedUser = message.getStringProperty(Message.HDR_VALIDATED_USER) ?: throw IllegalArgumentException("Missing validated user from the Artemis message")</ID>
    <ID>MaxLineLength:RPCServer.kt$RPCServer${ lifeCycle.requireState(State.UNSTARTED) log.info("Starting RPC server with configuration $rpcConfiguration") senderThread = startSenderThread() rpcExecutor = Executors.newScheduledThreadPool( rpcConfiguration.rpcThreadPoolSize, ThreadFactoryBuilder().setNameFormat("rpc-server-handler-pool-%d").build() ) reaperExecutor = Executors.newSingleThreadScheduledExecutor( ThreadFactoryBuilder().setNameFormat("rpc-server-reaper-%d").build() ) reaperScheduledFuture = reaperExecutor!!.scheduleAtFixedRate( this::reapSubscriptions, rpcConfiguration.reapInterval.toMillis(), rpcConfiguration.reapInterval.toMillis(), TimeUnit.MILLISECONDS ) sessionFactory = serverLocator.createSessionFactory() producerSession = sessionFactory!!.createSession(rpcServerUsername, rpcServerPassword, false, true, true, false, DEFAULT_ACK_BATCH_SIZE) createRpcProducer(producerSession!!) consumerSession = sessionFactory!!.createSession(rpcServerUsername, rpcServerPassword, false, true, true, false, DEFAULT_ACK_BATCH_SIZE) createRpcConsumer(consumerSession!!) createNotificationConsumers(consumerSession!!) serverControl = activeMqServerControl deduplicationIdentity = UUID.randomUUID().toString() lifeCycle.transition(State.UNSTARTED, State.STARTED) // We delay the consumer session start because Artemis starts delivering messages immediately, so we need to be // fully initialised. producerSession!!.start() consumerSession!!.start() }</ID>
    <ID>MaxLineLength:RaftNotaryService.kt$RaftNotaryService$?:</ID>
    <ID>MaxLineLength:RaftTransactionCommitLog.kt$RaftTransactionCommitLog$fun checkConflict(states: List&lt;StateRef&gt;, type: StateConsumptionDetails.ConsumedStateType)</ID>
    <ID>MaxLineLength:RaftTransactionCommitLog.kt$RaftTransactionCommitLog$log.debug("State machine commit: attempting to store entries with keys (${commitCommand.states.joinToString()})")</ID>
    <ID>MaxLineLength:RaftTransactionCommitLog.kt$RaftTransactionCommitLog$private</ID>
    <ID>MaxLineLength:RaftTransactionCommitLog.kt$RaftTransactionCommitLog$val deleteQuery = session.criteriaBuilder.createCriteriaDelete(PersistentUniquenessProvider.Request::class.java)</ID>
    <ID>MaxLineLength:RaftTransactionCommitLog.kt$RaftTransactionCommitLog.Companion.CordaKryoSerializer$private val context = CheckpointSerializationDefaults.CHECKPOINT_CONTEXT.withEncoding(CordaSerializationEncoding.SNAPPY)</ID>
    <ID>MaxLineLength:RaftUniquenessProvider.kt$RaftUniquenessProvider : UniquenessProviderSingletonSerializeAsToken</ID>
    <ID>MaxLineLength:RaftUniquenessProvider.kt$RaftUniquenessProvider.Companion$fun createMap(cacheFactory: NamedCacheFactory): AppendOnlyPersistentMap&lt;StateRef, Pair&lt;Long, SecureHash&gt;, CommittedState, String&gt;</ID>
    <ID>MaxLineLength:RaftUniquenessProvider.kt$RaftUniquenessProvider.Companion$it.value.deserialize&lt;SecureHash&gt;(context = SerializationDefaults.STORAGE_CONTEXT)</ID>
    <ID>MaxLineLength:ReactiveArtemisConsumer.kt$MultiplexingReactiveArtemisConsumer$private</ID>
    <ID>MaxLineLength:ReactiveArtemisConsumer.kt$ReactiveArtemisConsumer.Companion$fun multiplex(createSession: () -&gt; ClientSession, queueName: String, filter: String? = null, vararg queueNames: String): ReactiveArtemisConsumer</ID>
    <ID>MaxLineLength:ReactiveArtemisConsumer.kt$ReactiveArtemisConsumer.Companion$fun multiplex(queueNames: Set&lt;String&gt;, createSession: () -&gt; ClientSession, filter: String? = null): ReactiveArtemisConsumer</ID>
    <ID>MaxLineLength:RolesAdderOnLogin.kt$RolesAdderOnLogin$internal</ID>
    <ID>MaxLineLength:RpcBrokerConfiguration.kt$RpcBrokerConfiguration$deleteNonDurableQueue: Boolean = false</ID>
    <ID>MaxLineLength:RpcBrokerConfiguration.kt$RpcBrokerConfiguration$internal</ID>
    <ID>MaxLineLength:RpcBrokerConfiguration.kt$RpcBrokerConfiguration$journalBufferSize_AIO = maxMessageSize</ID>
    <ID>MaxLineLength:RpcBrokerConfiguration.kt$RpcBrokerConfiguration$journalBufferSize_NIO = maxMessageSize</ID>
    <ID>MaxLineLength:RpcBrokerConfiguration.kt$RpcBrokerConfiguration$private</ID>
    <ID>MaxLineLength:RpcBrokerConfiguration.kt$RpcBrokerConfiguration$return Role(name, send, consume, createDurableQueue, deleteDurableQueue, createNonDurableQueue, deleteNonDurableQueue, manage, browse, createDurableQueue || createNonDurableQueue, deleteDurableQueue || deleteNonDurableQueue)</ID>
    <ID>MaxLineLength:RpcBrokerConfiguration.kt$RpcBrokerConfiguration$securityRoles[RPCApi.RPC_SERVER_QUEUE_NAME] = setOf(nodeInternalRole, restrictedRole(BrokerJaasLoginModule.RPC_ROLE, send = true))</ID>
    <ID>MaxLineLength:RpcBrokerConfiguration.kt$RpcBrokerConfiguration$val addRPCRoleToUsers = if (shouldStartLocalShell) listOf(ArtemisMessagingComponent.INTERNAL_SHELL_USER) else emptyList()</ID>
    <ID>MaxLineLength:RpcBrokerConfiguration.kt$RpcBrokerConfiguration$val nodeInternalRole = Role(BrokerJaasLoginModule.NODE_RPC_ROLE, true, true, true, true, true, true, true, true, true, true)</ID>
    <ID>MaxLineLength:RpcServerObservableSerializer.kt$RpcServerObservableSerializer.&lt;no name provided&gt;$observableContext.clientAddressToObservables</ID>
    <ID>MaxLineLength:ScheduledActivityObserver.kt$ScheduledActivityObserver</ID>
    <ID>MaxLineLength:ScheduledActivityObserver.kt$ScheduledActivityObserver$val scheduledAt = sandbox { producedState.nextScheduledActivity(produced.ref, FlowLogicRefFactory)?.scheduledAt } ?: return</ID>
    <ID>MaxLineLength:ScheduledActivityObserver.kt$ScheduledActivityObserver.Companion$@JvmStatic fun install(vaultService: VaultService, schedulerService: SchedulerService, flowLogicRefFactory: FlowLogicRefFactory)</ID>
    <ID>MaxLineLength:ScheduledActivityObserver.kt$ScheduledActivityObserver.Companion$consumed.forEach { if (it.state.data is SchedulableState) schedulerService.unscheduleStateActivity(it.ref) }</ID>
    <ID>MaxLineLength:SecureArtemisConfiguration.kt$SecureArtemisConfiguration${ // Artemis allows multiple servers to be grouped together into a cluster for load balancing purposes. The cluster // user is used for connecting the nodes together. It has super-user privileges and so it's imperative that its // password be changed from the default (as warned in the docs). Since we don't need this feature we turn it off // by having its password be an unknown securely random 128-bit value. clusterPassword = BigInteger(128, newSecureRandom()).toString(16) }</ID>
    <ID>MaxLineLength:SerializeAsTokenSerializer.kt$SerializeAsTokenSerializer$?:</ID>
    <ID>MaxLineLength:ServiceHubInternal.kt$ServiceHubInternal$TopologicalSort</ID>
    <ID>MaxLineLength:ServiceHubInternal.kt$ServiceHubInternal$override fun createTransactionsResolver(flow: ResolveTransactionsFlow): TransactionsResolver</ID>
    <ID>MaxLineLength:ServiceHubInternal.kt$ServiceHubInternal$txs as? Collection ?: txs.toList()</ID>
    <ID>MaxLineLength:ServiceHubInternal.kt$ServiceHubInternal.Companion$require(txs.isNotEmpty()) { "No transactions passed in for recording" } val orderedTxs = topologicalSort(txs) // Divide transactions into those seen before and those that are new to this node if ALL_VISIBLE states are being recorded. // This allows the node to re-record transactions that have previously only been seen at the ONLY_RELEVANT level. Note that // for transactions being recorded at ONLY_RELEVANT, if this transaction has been seen before its outputs should already // have been recorded at ONLY_RELEVANT, so there shouldn't be anything to re-record here. val (recordedTransactions, previouslySeenTxs) = if (statesToRecord != StatesToRecord.ALL_VISIBLE) { orderedTxs.filter(validatedTransactions::addTransaction) to emptyList() } else { orderedTxs.partition(validatedTransactions::addTransaction) } val stateMachineRunId = FlowStateMachineImpl.currentStateMachine()?.id if (stateMachineRunId != null) { recordedTransactions.forEach { stateMachineRecordedTransactionMapping.addMapping(stateMachineRunId, it.id) } } else { log.warn("Transactions recorded from outside of a state machine") } // When the user has requested StatesToRecord.ALL we may end up recording and relationally mapping states // that do not involve us and that we cannot sign for. This will break coin selection and thus a warning // is present in the documentation for this feature (see the "Observer nodes" tutorial on docs.corda.net). // // The reason for this is three-fold: // // 1) We are putting in place the observer mode feature relatively quickly to meet specific customer // launch target dates. // // 2) The right design for vaults which mix observations and relevant states isn't entirely clear yet. // // 3) If we get the design wrong it could create security problems and business confusions. // // Back in the bitcoinj days I did add support for "watching addresses" to the wallet code, which is the // Bitcoin equivalent of observer nodes: // // https://bitcoinj.github.io/working-with-the-wallet#watching-wallets // // The ability to have a wallet containing both irrelevant and relevant states complicated everything quite // dramatically, even methods as basic as the getBalance() API which required additional modes to let you // query "balance I can spend" vs "balance I am observing". In the end it might have been better to just // require the user to create an entirely separate wallet for observing with. // // In Corda we don't support a single node having multiple vaults (at the time of writing), and it's not // clear that's the right way to go: perhaps adding an "origin" column to the VAULT_STATES table is a better // solution. Then you could select subsets of states depending on where the report came from. // // The risk of doing this is that apps/developers may use 'canned SQL queries' not written by us that forget // to add a WHERE clause for the origin column. Those queries will seem to work most of the time until // they're run on an observer node and mix in irrelevant data. In the worst case this may result in // erroneous data being reported to the user, which could cause security problems. // // Because the primary use case for recording irrelevant states is observer/regulator nodes, who are unlikely // to make writes to the ledger very often or at all, we choose to punt this issue for the time being. vaultService.notifyAll(statesToRecord, recordedTransactions.map { it.coreTransaction }, previouslySeenTxs.map { it.coreTransaction })</ID>
    <ID>MaxLineLength:ServiceHubInternal.kt$ServiceHubInternal.Companion$vaultService.notifyAll(statesToRecord, recordedTransactions.map { it.coreTransaction }, previouslySeenTxs.map { it.coreTransaction })</ID>
    <ID>MaxLineLength:ServiceHubInternal.kt$ServiceHubInternal.TopologicalSort$// Note that we use a LinkedHashSet here to make the traversal deterministic (as long as the input list is). forwardGraph.computeIfAbsent(it) { LinkedHashSet() }.add(stx)</ID>
    <ID>MaxLineLength:ServiceHubInternal.kt$WritableTransactionStorage$ // TODO: Throw an exception if trying to add a transaction with fewer signatures than an existing entry. fun addTransaction(transaction: SignedTransaction): Boolean</ID>
    <ID>MaxLineLength:ServiceHubInternal.kt$WritableTransactionStorage$ fun getTransactionInternal(id: SecureHash): Pair&lt;SignedTransaction, Boolean&gt;?</ID>
    <ID>MaxLineLength:ServicesForResolutionImpl.kt$ServicesForResolutionImpl$else -&gt; throw UnsupportedOperationException("Attempting to resolve attachment for index ${stateRef.index} of a ${ctx.javaClass} transaction. This is not supported.")</ID>
    <ID>MaxLineLength:ServicesForResolutionImpl.kt$ServicesForResolutionImpl$if (attachment is ContractAttachment &amp;&amp; (forContractClassName ?: transactionState.contract) in attachment.allContracts) { return attachment }</ID>
    <ID>MaxLineLength:ServicesForResolutionImpl.kt$ServicesForResolutionImpl$override</ID>
    <ID>MaxLineLength:ServicesForResolutionImpl.kt$ServicesForResolutionImpl$return attachments.openAttachment(ctx.upgradedContractAttachmentId) ?: throw AttachmentResolutionException(stateRef.txhash)</ID>
    <ID>MaxLineLength:ServicesForResolutionImpl.kt$ServicesForResolutionImpl$return ctx.inputs.map { inner(it, transactionState.contract) }.firstOrNull() ?: throw AttachmentResolutionException(stateRef.txhash)</ID>
    <ID>MaxLineLength:ServicesForResolutionImpl.kt$ServicesForResolutionImpl$val stx = validatedTransactions.getTransaction(stateRef.txhash) ?: throw TransactionResolutionException(stateRef.txhash)</ID>
    <ID>MaxLineLength:ServicesForResolutionImpl.kt$ServicesForResolutionImpl$val transactionState = SerializedStateAndRef(resolveStateRefBinaryComponent(stateRef, this)!!, stateRef).toStateAndRef().state</ID>
    <ID>MaxLineLength:SessionMessage.kt$ErrorSessionMessage : ExistingSessionMessagePayload</ID>
    <ID>MaxLineLength:SessionRejectException.kt$SessionRejectException$NotRegistered : SessionRejectException</ID>
    <ID>MaxLineLength:SessionRejectException.kt$SessionRejectException$UnknownClass : SessionRejectException</ID>
    <ID>MaxLineLength:SimpleNotaryService.kt$SimpleNotaryService : SinglePartyNotaryService</ID>
    <ID>MaxLineLength:SimpleNotaryService.kt$SimpleNotaryService$?:</ID>
    <ID>MaxLineLength:SimpleNotaryService.kt$SimpleNotaryService$override val uniquenessProvider = PersistentUniquenessProvider(services.clock, services.database, services.cacheFactory)</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$ #See https://docs.corda.net/head/testing.html#running-tests-in-intellij - 'Fiber classes not instrumented' for more details.</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$ override fun stop(allowedUnsuspendedFiberCount: Int)</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$"""Missing the '-javaagent' JVM argument. Make sure you run the tests with the Quasar java agent attached to your JVM. #See https://docs.corda.net/head/testing.html#running-tests-in-intellij - 'Fiber classes not instrumented' for more details."""</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$CheckpointSerializeAsTokenContextImpl(tokenizableServices, CheckpointSerializationDefaults.CHECKPOINT_SERIALIZER, CheckpointSerializationDefaults.CHECKPOINT_CONTEXT, serviceHub)</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$DataFeed(flows.values.map { it.fiber.logic }, changesPublisher.bufferUntilSubscribed().wrapWithDatabaseTransaction(database))</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$changesPublisher.onNext(StateMachineManager.Change.Removed(lastState.flowLogic, Try.Failure&lt;Nothing&gt;(exception)))</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$changesPublisher.onNext(StateMachineManager.Change.Removed(lastState.flowLogic, Try.Success(removalReason.flowReturnValue)))</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$check(!foundUnrestorableFibers) { "Unrestorable checkpoints were created, please check the logs for details." }</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$errorAndTerminate("Caught unrecoverable error from flow. Forcibly terminating the JVM, this might leave resources open, and most likely will.", throwable)</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$is ExistingSessionMessage -&gt; onExistingSessionMessage(sessionMessage, event.deduplicationHandler, sender)</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$is InitiatedFlowFactory.CorDapp -&gt; FlowInfo(initiatedFlowFactory.flowVersion, initiatedFlowFactory.appName)</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$logger.debug { "Ignoring request to set time-out on timed flow $flowId to $timeoutSeconds seconds which is shorter than default of ${serviceHub.configuration.flowTimeout.timeout.seconds} seconds." }</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$logger.debug("Unable to kill a flow unknown to physical node. Might be processed by another physical node.")</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$logger.error("Unable to deserialize database checkpoint for flow $flowId. Something is very wrong. The flow will not retry.")</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$logger.error("Unable to find database checkpoint for flow $flowId. Something is very wrong. The flow will not retry.")</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$private</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$private val fiberDeserializationChecker = if (serviceHub.configuration.shouldCheckCheckpoints()) FiberDeserializationChecker() else null</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$require(lastState.pendingDeduplicationHandlers.isEmpty()) { "Flow cannot be removed until all pending deduplications have completed" }</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$return serviceHub.getFlowFactory(initiatorFlowClass) ?: throw SessionRejectException.NotRegistered(initiatorFlowClass)</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$startInitiatedFlow(flowLogic, event.deduplicationHandler, senderSession, initiatedSessionId, sessionMessage, senderCoreFlowVersion, initiatedFlowInfo)</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$val externalEvents = currentState.pendingDeduplicationHandlers.map { it.externalCause } + unprocessedExternalEvents</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$val flowCorDappVersion = createSubFlowVersion(serviceHub.cordappProvider.getCordappForFlow(flowLogic), serviceHub.myInfo.platformVersion)</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$val flowStart = FlowStart.Initiated(peerSession, initiatedSessionId, initiatingMessage, senderCoreFlowVersion, initiatedFlowInfo)</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$val frozenFlowLogic = (flowLogic as FlowLogic&lt;*&gt;).checkpointSerialize(context = checkpointSerializationContext!!)</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$val future = startFlow(event.flowLogic, event.context, ourIdentity = null, deduplicationHandler = event.deduplicationHandler)</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$val timeoutDelaySeconds = timeout.seconds * Math.pow(backoffBase, min(retryCount, maxRestartCount).toDouble()).toLong()</ID>
    <ID>MaxLineLength:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager${ val flowId = StateMachineRunId.createRandom() // Before we construct the state machine state by freezing the FlowLogic we need to make sure that lazy properties // have access to the fiber (and thereby the service hub) val flowStateMachineImpl = FlowStateMachineImpl(flowId, flowLogic, scheduler) val resultFuture = openFuture&lt;Any?&gt;() flowStateMachineImpl.transientValues = TransientReference(createTransientValues(flowId, resultFuture)) flowLogic.stateMachine = flowStateMachineImpl val frozenFlowLogic = (flowLogic as FlowLogic&lt;*&gt;).checkpointSerialize(context = checkpointSerializationContext!!) val flowCorDappVersion = createSubFlowVersion(serviceHub.cordappProvider.getCordappForFlow(flowLogic), serviceHub.myInfo.platformVersion) val initialCheckpoint = Checkpoint.create( invocationContext, flowStart, flowLogic.javaClass, frozenFlowLogic, ourIdentity, flowCorDappVersion, flowLogic.isEnabledTimedFlow() ).getOrThrow() val startedFuture = openFuture&lt;Unit&gt;() val initialState = StateMachineState( checkpoint = initialCheckpoint, pendingDeduplicationHandlers = deduplicationHandler?.let { listOf(it) } ?: emptyList(), isFlowResumed = false, isTransactionTracked = false, isAnyCheckpointPersisted = false, isStartIdempotent = isStartIdempotent, isRemoved = false, flowLogic = flowLogic, senderUUID = ourSenderUUID ) flowStateMachineImpl.transientState = TransientReference(initialState) mutex.locked { startedFutures[flowId] = startedFuture } totalStartedFlows.inc() addAndStartFlow(flowId, Flow(flowStateMachineImpl, resultFuture)) return startedFuture.map { flowStateMachineImpl as FlowStateMachine&lt;A&gt; } }</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$StaffedFlowHospital$ fun dropSessionInit(id: UUID): Boolean</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$StaffedFlowHospital$ fun sessionInitErrored(sessionMessage: InitialSessionMessage, sender: Party, event: ExternalEvent.ExternalMessageEvent, error: Throwable)</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$StaffedFlowHospital$"the UUID $id (from the node shell you can run 'flow kill $id'). BE VERY CAUTIOUS OF THIS SECOND APPROACH AS THE "</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$StaffedFlowHospital$flowMessaging.sendSessionMessage(sender, replyError, SenderDeduplicationId(DeduplicationId.createRandom(secureRandom), ourSenderUUID))</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$StaffedFlowHospital$log</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$StaffedFlowHospital$log.info("Flow error discharged from hospital (delay ${backOff.seconds}s) by ${report.by} (error was ${report.error.message})")</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$StaffedFlowHospital$log.info("Flow error kept for overnight observation by ${report.by} (error was ${report.error.message})")</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$StaffedFlowHospital$private</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$StaffedFlowHospital$val diagnoses: Map&lt;Diagnosis, List&lt;Staff&gt;&gt; = staff.groupBy { it.consult(flowFiber, currentState, error, medicalHistory) }</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$StaffedFlowHospital$val record = MedicalRecord.Flow(time, flowFiber.id, currentState.checkpoint.numberOfSuspends, errors, report.by, outcome)</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$StaffedFlowHospital$val record = sessionMessage.run { MedicalRecord.SessionInit(id, time, outcome, initiatorFlowClassName, flowVersion, appName, sender, error) }</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$StaffedFlowHospital$val snapshot = (flowPatients.values.flatMap { it.records } + treatableSessionInits.values.map { it.publicRecord }).sortedBy { it.time }</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$StaffedFlowHospital${ log.info("Flow error kept for overnight observation by ${report.by} (error was ${report.error.message})") // We don't schedule a next event for the flow - it will automatically retry from its checkpoint on node restart Triple(Outcome.OVERNIGHT_OBSERVATION, null, 0.seconds) }</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$StaffedFlowHospital${ private companion object { private val log = contextLogger() private val staff = listOf( DeadlockNurse, DuplicateInsertSpecialist, DoctorTimeout, FinalityDoctor, TransientConnectionCardiologist ) } private val mutex = ThreadBox(object { val flowPatients = HashMap&lt;StateMachineRunId, FlowMedicalHistory&gt;() val treatableSessionInits = HashMap&lt;UUID, InternalSessionInitRecord&gt;() val recordsPublisher = PublishSubject.create&lt;MedicalRecord&gt;() }) private val secureRandom = newSecureRandom() private val delayedDischargeTimer = Timer("FlowHospitalDelayedDischargeTimer", true) /** * The node was unable to initiate the [InitialSessionMessage] from [sender]. */ fun sessionInitErrored(sessionMessage: InitialSessionMessage, sender: Party, event: ExternalEvent.ExternalMessageEvent, error: Throwable) { val time = Instant.now() val id = UUID.randomUUID() val outcome = if (error is SessionRejectException.UnknownClass) { // We probably don't have the CorDapp installed so let's pause the message in the hopes that the CorDapp is // installed on restart, at which point the message will be able proceed as normal. If not then it will need // to be dropped manually. Outcome.OVERNIGHT_OBSERVATION } else { Outcome.UNTREATABLE } val record = sessionMessage.run { MedicalRecord.SessionInit(id, time, outcome, initiatorFlowClassName, flowVersion, appName, sender, error) } mutex.locked { if (outcome != Outcome.UNTREATABLE) { treatableSessionInits[id] = InternalSessionInitRecord(sessionMessage, event, record) log.warn("$sender has sent a flow request for an unknown flow ${sessionMessage.initiatorFlowClassName}. Install the missing " + "CorDapp this flow belongs to and restart.") log.warn("If you know it's safe to ignore this flow request then it can be deleted permanently using the killFlow RPC and " + "the UUID $id (from the node shell you can run 'flow kill $id'). BE VERY CAUTIOUS OF THIS SECOND APPROACH AS THE " + "REQUEST MAY CONTAIN A NOTARISED TRANSACTION THAT NEEDS TO BE RECORDED IN YOUR VAULT.") } recordsPublisher.onNext(record) } if (outcome == Outcome.UNTREATABLE) { sendBackError(error, sessionMessage, sender, event) } } private fun sendBackError(error: Throwable, sessionMessage: InitialSessionMessage, sender: Party, event: ExternalEvent.ExternalMessageEvent) { val message = (error as? SessionRejectException)?.message ?: "Unable to establish session" val payload = RejectSessionMessage(message, secureRandom.nextLong()) val replyError = ExistingSessionMessage(sessionMessage.initiatorSessionId, payload) flowMessaging.sendSessionMessage(sender, replyError, SenderDeduplicationId(DeduplicationId.createRandom(secureRandom), ourSenderUUID)) event.deduplicationHandler.afterDatabaseTransaction() } /** * Drop the errored session-init message with the given ID ([MedicalRecord.SessionInit.id]). This will cause the node * to send back the relevant session error to the initiator party and acknowledge its receipt from the message broker * so that it never gets redelivered. */ fun dropSessionInit(id: UUID): Boolean { val (sessionMessage, event, publicRecord) = mutex.locked { treatableSessionInits.remove(id) ?: return false } log.info("Errored session-init permanently dropped: $publicRecord") sendBackError(publicRecord.error, sessionMessage, publicRecord.sender, event) return true } /** * The flow running in [flowFiber] has errored. */ fun flowErrored(flowFiber: FlowFiber, currentState: StateMachineState, errors: List&lt;Throwable&gt;) { val time = Instant.now() log.info("Flow ${flowFiber.id} admitted to hospital in state $currentState") val (event, backOffForChronicCondition) = mutex.locked { val medicalHistory = flowPatients.computeIfAbsent(flowFiber.id) { FlowMedicalHistory() } val report = consultStaff(flowFiber, currentState, errors, medicalHistory) val (outcome, event, backOffForChronicCondition) = when (report.diagnosis) { Diagnosis.DISCHARGE -&gt; { val backOff = calculateBackOffForChronicCondition(report, medicalHistory, currentState) log.info("Flow error discharged from hospital (delay ${backOff.seconds}s) by ${report.by} (error was ${report.error.message})") Triple(Outcome.DISCHARGE, Event.RetryFlowFromSafePoint, backOff) } Diagnosis.OVERNIGHT_OBSERVATION -&gt; { log.info("Flow error kept for overnight observation by ${report.by} (error was ${report.error.message})") // We don't schedule a next event for the flow - it will automatically retry from its checkpoint on node restart Triple(Outcome.OVERNIGHT_OBSERVATION, null, 0.seconds) } Diagnosis.NOT_MY_SPECIALTY -&gt; { // None of the staff care for these errors so we let them propagate log.info("Flow error allowed to propagate", report.error) Triple(Outcome.UNTREATABLE, Event.StartErrorPropagation, 0.seconds) } } val record = MedicalRecord.Flow(time, flowFiber.id, currentState.checkpoint.numberOfSuspends, errors, report.by, outcome) medicalHistory.records += record recordsPublisher.onNext(record) Pair(event, backOffForChronicCondition) } if (event != null) { if (backOffForChronicCondition.isZero) { flowFiber.scheduleEvent(event) } else { delayedDischargeTimer.schedule(object : TimerTask() { override fun run() { flowFiber.scheduleEvent(event) } }, backOffForChronicCondition.toMillis()) } } } private fun calculateBackOffForChronicCondition(report: ConsultationReport, medicalHistory: FlowMedicalHistory, currentState: StateMachineState): Duration { return report.by.firstOrNull { it is Chronic }?.let { chronicStaff -&gt; return medicalHistory.timesDischargedForTheSameThing(chronicStaff, currentState).let { if (it == 0) { 0.seconds } else { maxOf(10, (10 + (Math.random()) * (10 * 1.5.pow(it)) / 2).toInt()).seconds } } } ?: 0.seconds } private fun consultStaff(flowFiber: FlowFiber, currentState: StateMachineState, errors: List&lt;Throwable&gt;, medicalHistory: FlowMedicalHistory): ConsultationReport { return errors .asSequence() .mapIndexed { index, error -&gt; // Rely on the logging context to print details of the flow ID. log.info("Error ${index + 1} of ${errors.size}:", error) val diagnoses: Map&lt;Diagnosis, List&lt;Staff&gt;&gt; = staff.groupBy { it.consult(flowFiber, currentState, error, medicalHistory) } // We're only interested in the highest priority diagnosis for the error val (diagnosis, by) = diagnoses.entries.minBy { it.key }!! ConsultationReport(error, diagnosis, by) } // And we're only interested in the error with the highest priority diagnosis .minBy { it.diagnosis }!! } private data class ConsultationReport(val error: Throwable, val diagnosis: Diagnosis, val by: List&lt;Staff&gt;) /** * The flow has been removed from the state machine. */ fun flowRemoved(flowId: StateMachineRunId) { mutex.locked { flowPatients.remove(flowId) } } // TODO MedicalRecord subtypes can expose the Staff class, something which we probably don't want when wiring this method to RPC /** Returns a stream of medical records as flows pass through the hospital. */ fun track(): DataFeed&lt;List&lt;MedicalRecord&gt;, MedicalRecord&gt; { return mutex.locked { val snapshot = (flowPatients.values.flatMap { it.records } + treatableSessionInits.values.map { it.publicRecord }).sortedBy { it.time } DataFeed(snapshot, recordsPublisher.bufferUntilSubscribed()) } } operator fun contains(flowId: StateMachineRunId) = mutex.locked { flowId in flowPatients } class FlowMedicalHistory { internal val records: MutableList&lt;MedicalRecord.Flow&gt; = mutableListOf() fun notDischargedForTheSameThingMoreThan(max: Int, by: Staff, currentState: StateMachineState): Boolean { return timesDischargedForTheSameThing(by, currentState) &lt;= max } fun timesDischargedForTheSameThing(by: Staff, currentState: StateMachineState): Int { val lastAdmittanceSuspendCount = currentState.checkpoint.numberOfSuspends return records.count { it.outcome == Outcome.DISCHARGE &amp;&amp; by in it.by &amp;&amp; it.suspendCount == lastAdmittanceSuspendCount } } override fun toString(): String = "${this.javaClass.simpleName}(records = $records)" } private data class InternalSessionInitRecord(val sessionMessage: InitialSessionMessage, val event: ExternalEvent.ExternalMessageEvent, val publicRecord: MedicalRecord.SessionInit) sealed class MedicalRecord { abstract val time: Instant abstract val outcome: Outcome abstract val errors: List&lt;Throwable&gt; /** Medical record for a flow that has errored. */ data class Flow(override val time: Instant, val flowId: StateMachineRunId, val suspendCount: Int, override val errors: List&lt;Throwable&gt;, val by: List&lt;Staff&gt;, override val outcome: Outcome) : MedicalRecord() /** Medical record for a session initiation that was unsuccessful. */ data class SessionInit(val id: UUID, override val time: Instant, override val outcome: Outcome, val initiatorFlowClassName: String, val flowVersion: Int, val appName: String, val sender: Party, val error: Throwable) : MedicalRecord() { override val errors: List&lt;Throwable&gt; get() = listOf(error) } } enum class Outcome { DISCHARGE, OVERNIGHT_OBSERVATION, UNTREATABLE } /** The order of the enum values are in priority order. */ enum class Diagnosis { /** Retry from last safe point. */ DISCHARGE, /** Park and await intervention. */ OVERNIGHT_OBSERVATION, /** Please try another member of staff. */ NOT_MY_SPECIALTY } interface Staff { fun consult(flowFiber: FlowFiber, currentState: StateMachineState, newError: Throwable, history: FlowMedicalHistory): Diagnosis } interface Chronic /** * SQL Deadlock detection. */ object DeadlockNurse : Staff, Chronic { override fun consult(flowFiber: FlowFiber, currentState: StateMachineState, newError: Throwable, history: FlowMedicalHistory): Diagnosis { return if (mentionsDeadlock(newError)) { Diagnosis.DISCHARGE } else { Diagnosis.NOT_MY_SPECIALTY } } private fun mentionsDeadlock(exception: Throwable?): Boolean { return exception.mentionsThrowable(SQLException::class.java, "deadlock") } } /** * Primary key violation detection for duplicate inserts. Will detect other constraint violations too. */ object DuplicateInsertSpecialist : Staff { override fun consult(flowFiber: FlowFiber, currentState: StateMachineState, newError: Throwable, history: FlowMedicalHistory): Diagnosis { return if (newError.mentionsThrowable(ConstraintViolationException::class.java) &amp;&amp; history.notDischargedForTheSameThingMoreThan(3, this, currentState)) { Diagnosis.DISCHARGE } else { Diagnosis.NOT_MY_SPECIALTY } } } /** * Restarts [TimedFlow], keeping track of the number of retries and making sure it does not * exceed the limit specified by the [FlowTimeoutException]. */ object DoctorTimeout : Staff { override fun consult(flowFiber: FlowFiber, currentState: StateMachineState, newError: Throwable, history: FlowMedicalHistory): Diagnosis { if (newError is FlowTimeoutException) { return Diagnosis.DISCHARGE } return Diagnosis.NOT_MY_SPECIALTY } } object FinalityDoctor : Staff { override fun consult(flowFiber: FlowFiber, currentState: StateMachineState, newError: Throwable, history: FlowMedicalHistory): Diagnosis { return if (currentState.flowLogic is FinalityHandler || isFromReceiveFinalityFlow(newError)) { log.warn("Flow ${flowFiber.id} failed to be finalised. Manual intervention may be required before retrying " + "the flow by re-starting the node. State machine state: $currentState", newError) Diagnosis.OVERNIGHT_OBSERVATION } else { Diagnosis.NOT_MY_SPECIALTY } } private fun isFromReceiveFinalityFlow(throwable: Throwable): Boolean { return throwable.stackTrace.any { it.className == ReceiveFinalityFlow::class.java.name } } } /** * [SQLTransientConnectionException] detection that arise from failing to connect the underlying database/datasource */ object TransientConnectionCardiologist : Staff { override fun consult(flowFiber: FlowFiber, currentState: StateMachineState, newError: Throwable, history: FlowMedicalHistory): Diagnosis { return if (mentionsTransientConnection(newError)) { if (history.notDischargedForTheSameThingMoreThan(2, this, currentState)) { Diagnosis.DISCHARGE } else { Diagnosis.OVERNIGHT_OBSERVATION } } else { Diagnosis.NOT_MY_SPECIALTY } } private fun mentionsTransientConnection(exception: Throwable?): Boolean { return exception.mentionsThrowable(SQLTransientConnectionException::class.java, "connection is not available") } } }</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$StaffedFlowHospital.DeadlockNurse$override</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$StaffedFlowHospital.DoctorTimeout$override</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$StaffedFlowHospital.DuplicateInsertSpecialist$override</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$StaffedFlowHospital.DuplicateInsertSpecialist$return if (newError.mentionsThrowable(ConstraintViolationException::class.java) &amp;&amp; history.notDischargedForTheSameThingMoreThan(3, this, currentState)) { Diagnosis.DISCHARGE } else { Diagnosis.NOT_MY_SPECIALTY }</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$StaffedFlowHospital.FinalityDoctor$log</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$StaffedFlowHospital.FinalityDoctor$override</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$StaffedFlowHospital.FlowMedicalHistory$return records.count { it.outcome == Outcome.DISCHARGE &amp;&amp; by in it.by &amp;&amp; it.suspendCount == lastAdmittanceSuspendCount }</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$StaffedFlowHospital.Staff$fun consult(flowFiber: FlowFiber, currentState: StateMachineState, newError: Throwable, history: FlowMedicalHistory): Diagnosis</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$StaffedFlowHospital.TransientConnectionCardiologist$override</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$StaffedFlowHospital.TransientConnectionCardiologist$return exception.mentionsThrowable(SQLTransientConnectionException::class.java, "connection is not available")</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$private</ID>
    <ID>MaxLineLength:StaffedFlowHospital.kt$return (exceptionType.isAssignableFrom(this::class.java) &amp;&amp; containsMessage) || cause.mentionsThrowable(exceptionType, errorMessage)</ID>
    <ID>MaxLineLength:StandardConfigValueParsers.kt$internal fun &lt;RESULT&gt; badValue(message: String)</ID>
    <ID>MaxLineLength:StandardConfigValueParsers.kt$internal fun toCordaX500Name(rawValue: String)</ID>
    <ID>MaxLineLength:StandardConfigValueParsers.kt$internal fun toNetworkHostAndPort(rawValue: String)</ID>
    <ID>MaxLineLength:StandardConfigValueParsers.kt$internal fun toPrincipal(rawValue: String)</ID>
    <ID>MaxLineLength:StandardConfigValueParsers.kt$internal inline fun &lt;reified RESULT, reified ERROR : Exception&gt; attempt(action: () -&gt; RESULT)</ID>
    <ID>MaxLineLength:StandardConfigValueParsers.kt$private fun Config.toProperties()</ID>
    <ID>MaxLineLength:StandardConfigValueParsers.kt$private inline</ID>
    <ID>MaxLineLength:StartedFlowTransition.kt$StartedFlowTransition$actions.add(Action.SendExisting(existingSessionState.peerParty, existingMessage, SenderDeduplicationId(deduplicationId, startingState.senderUUID)))</ID>
    <ID>MaxLineLength:StartedFlowTransition.kt$StartedFlowTransition$actions.add(Action.SendInitial(existingSessionState.destination, initialMessage, SenderDeduplicationId(deduplicationId, startingState.senderUUID)))</ID>
    <ID>MaxLineLength:StartedFlowTransition.kt$StartedFlowTransition$actions.add(Action.SendInitial(sessionState.destination, initialMessage, SenderDeduplicationId(deduplicationId, startingState.senderUUID)))</ID>
    <ID>MaxLineLength:StartedFlowTransition.kt$StartedFlowTransition$collectErroredSessionErrors(sessionIds, checkpoint) + collectEndedEmptySessionErrors(sessionIds, checkpoint)</ID>
    <ID>MaxLineLength:StartedFlowTransition.kt$StartedFlowTransition$newSessionMessages[sessionId] = sessionState.copy(receivedMessages = messages.subList(1, messages.size).toList())</ID>
    <ID>MaxLineLength:StartedFlowTransition.kt$StartedFlowTransition$private</ID>
    <ID>MaxLineLength:StartedFlowTransition.kt$StartedFlowTransition$return freshErrorTransition(IllegalStateException("Tried to send to ended session $sourceSessionId"))</ID>
    <ID>MaxLineLength:StartedFlowTransition.kt$StartedFlowTransition$val initialMessage = createInitialSessionMessage(existingSessionState.initiatingSubFlow, sourceSessionId, existingSessionState.additionalEntropy, message)</ID>
    <ID>MaxLineLength:StartedFlowTransition.kt$StartedFlowTransition$val initialMessage = createInitialSessionMessage(sessionState.initiatingSubFlow, sourceSessionId, sessionState.additionalEntropy, null)</ID>
    <ID>MaxLineLength:StartedFlowTransition.kt$StartedFlowTransition$val newBufferedMessages = existingSessionState.bufferedMessages + Pair(deduplicationId, sessionMessage)</ID>
    <ID>MaxLineLength:StateMachineManager.kt$StateMachineManager</ID>
    <ID>MaxLineLength:StateMachineManager.kt$StateMachineManager$ fun deliverExternalEvent(event: ExternalEvent)</ID>
    <ID>MaxLineLength:StateMachineManager.kt$StateMachineManager$ fun killFlow(id: StateMachineRunId): Boolean</ID>
    <ID>MaxLineLength:StateMachineManagerUtils.kt$ //TODO: instead of replacing the progress tracker after constructing the flow logic, we should inject it during fiber deserialization fun StateMachineManagerInternal.injectOldProgressTracker(oldTracker: ProgressTracker?, newFlowLogic: FlowLogic&lt;*&gt;)</ID>
    <ID>MaxLineLength:StateMachineState.kt$StateMachineState</ID>
    <ID>MaxLineLength:StateMachineState.kt$SubFlowVersion$CorDappFlow : SubFlowVersion</ID>
    <ID>MaxLineLength:SubFlow.kt$SubFlow.Companion$Try.Success(Initiating(flowClass, initiatingAnnotation.first, flowContext, subFlowVersion, isEnabledTimedFlow))</ID>
    <ID>MaxLineLength:SubFlow.kt$SubFlow.Companion$fun create(flowClass: Class&lt;FlowLogic&lt;*&gt;&gt;, subFlowVersion: SubFlowVersion, isEnabledTimedFlow: Boolean): Try&lt;SubFlow&gt;</ID>
    <ID>MaxLineLength:SubFlow.kt$SubFlow.Companion$private</ID>
    <ID>MaxLineLength:SubFlow.kt$SubFlow.Inlined$data</ID>
    <ID>MaxLineLength:SwapIdentitiesHandler.kt$SwapIdentitiesHandler : FlowLogic</ID>
    <ID>MaxLineLength:SwapIdentitiesHandler.kt$SwapIdentitiesHandler$logger.warnOnce("Insecure API to swap anonymous identities was used by ${otherSide.counterparty} (${otherSide.getCounterpartyFlowInfo()})")</ID>
    <ID>MaxLineLength:ThreadContextAdjustingRpcOpsProxy.kt$ThreadContextAdjustingRpcOpsProxy : InternalCordaRPCOps</ID>
    <ID>MaxLineLength:ThreadContextAdjustingRpcOpsProxy.kt$ThreadContextAdjustingRpcOpsProxy$internal</ID>
    <ID>MaxLineLength:ThreadContextAdjustingRpcOpsProxy.kt$ThreadContextAdjustingRpcOpsProxy.Companion$return Proxy.newProxyInstance(delegate::class.java.classLoader, arrayOf(InternalCordaRPCOps::class.java), handler) as InternalCordaRPCOps</ID>
    <ID>MaxLineLength:ThreadContextAdjustingRpcOpsProxy.kt$ThreadContextAdjustingRpcOpsProxy.Companion$val handler = ThreadContextAdjustingRpcOpsProxy.ThreadContextAdjustingInvocationHandler(delegate, classLoader)</ID>
    <ID>MaxLineLength:ThreadContextAdjustingRpcOpsProxy.kt$ThreadContextAdjustingRpcOpsProxy.ThreadContextAdjustingInvocationHandler$private</ID>
    <ID>MaxLineLength:TimedFlowUtils.kt$ internal fun FlowLogic&lt;*&gt;.isEnabledTimedFlow(): Boolean</ID>
    <ID>MaxLineLength:TopLevelTransition.kt$TopLevelTransition$Action.PersistCheckpoint(context.id, newCheckpoint, isCheckpointUpdate = currentState.isAnyCheckpointPersisted)</ID>
    <ID>MaxLineLength:TopLevelTransition.kt$TopLevelTransition$Action.RemoveFlow(context.id, FlowRemovalReason.OrderlyFinish(event.returnValue), currentState)</ID>
    <ID>MaxLineLength:TopLevelTransition.kt$TopLevelTransition$Action.SendExisting(state.peerParty, message, SenderDeduplicationId(deduplicationId, currentState.senderUUID))</ID>
    <ID>MaxLineLength:TopLevelTransition.kt$TopLevelTransition$freshErrorTransition(IllegalStateException("Tried to initiate in a flow not annotated with @${InitiatingFlow::class.java.simpleName}"))</ID>
    <ID>MaxLineLength:TopLevelTransition.kt$TopLevelTransition$is Event.DeliverSessionMessage -&gt; DeliverSessionMessageTransition(context, startingState, event).transition()</ID>
    <ID>MaxLineLength:TopLevelTransition.kt$TopLevelTransition$val newSessions = checkpoint.sessions + (sourceSessionId to SessionState.Uninitiated(event.destination, initiatingSubFlow, sourceSessionId, context.secureRandom.nextLong()))</ID>
    <ID>MaxLineLength:TransitionBuilder.kt$CannotFindSessionException : IllegalStateException</ID>
    <ID>MaxLineLength:TransitionExecutor.kt$TransitionExecutor$ fun forceRemoveFlow(id: StateMachineRunId)</ID>
    <ID>MaxLineLength:TransitionExecutorImpl.kt$TransitionExecutorImpl$log.warn("Error while executing $action during transition to errored state, aborting transition", exception)</ID>
    <ID>MaxLineLength:TransitionExecutorImpl.kt$TransitionExecutorImpl${ // If we errored while transitioning to an error state then we cannot record the additional // error as that may result in an infinite loop, e.g. error propagation fails -&gt; record error -&gt; propagate fails again. // Instead we just keep around the old error state and wait for a new schedule, perhaps // triggered from a flow hospital log.warn("Error while executing $action during transition to errored state, aborting transition", exception) return Pair(FlowContinuation.Abort, previousState.copy(isFlowResumed = false)) }</ID>
    <ID>MaxLineLength:UnstartedFlowTransition.kt$UnstartedFlowTransition$Action.PersistCheckpoint(context.id, currentState.checkpoint, isCheckpointUpdate = currentState.isAnyCheckpointPersisted)</ID>
    <ID>MaxLineLength:UnstartedFlowTransition.kt$UnstartedFlowTransition$SenderDeduplicationId(DeduplicationId.createForNormal(currentState.checkpoint, 0, initiatedState), currentState.senderUUID)</ID>
    <ID>MaxLineLength:UnstartedFlowTransition.kt$UnstartedFlowTransition$deduplicationSeed = "D-${initiatingMessage.initiatorSessionId.toLong}-${initiatingMessage.initiationEntropy}"</ID>
    <ID>MaxLineLength:Utils.kt$return requireNotNull(getDeclaredAnnotation(A::class.java)) { "$name needs to be annotated with ${A::class.java.name}" }</ID>
    <ID>MaxLineLength:V1NodeConfigurationSpec.kt$V1NodeConfigurationSpec$flowMonitorSuspensionLoggingThresholdMillis = configuration[flowMonitorSuspensionLoggingThresholdMillis]</ID>
    <ID>MaxLineLength:V1NodeConfigurationSpec.kt$V1NodeConfigurationSpec$private val additionalNodeInfoPollingFrequencyMsec by long().optional().withDefaultValue(Defaults.additionalNodeInfoPollingFrequencyMsec)</ID>
    <ID>MaxLineLength:V1NodeConfigurationSpec.kt$V1NodeConfigurationSpec$private val additionalP2PAddresses by string().mapValid(::toNetworkHostAndPort).list().optional().withDefaultValue(Defaults.additionalP2PAddresses)</ID>
    <ID>MaxLineLength:V1NodeConfigurationSpec.kt$V1NodeConfigurationSpec$private val certificateChainCheckPolicies by nested(CertChainPolicyConfigSpec).list().optional().withDefaultValue(Defaults.certificateChainCheckPolicies)</ID>
    <ID>MaxLineLength:V1NodeConfigurationSpec.kt$V1NodeConfigurationSpec$private val cordappSignerKeyFingerprintBlacklist by string().list().optional().withDefaultValue(Defaults.cordappSignerKeyFingerprintBlacklist)</ID>
    <ID>MaxLineLength:V1NodeConfigurationSpec.kt$V1NodeConfigurationSpec$private val extraNetworkMapKeys by string().mapValid(::toUUID).list().optional().withDefaultValue(Defaults.extraNetworkMapKeys)</ID>
    <ID>MaxLineLength:V1NodeConfigurationSpec.kt$V1NodeConfigurationSpec$private val flowMonitorSuspensionLoggingThresholdMillis by duration().optional().withDefaultValue(Defaults.flowMonitorSuspensionLoggingThresholdMillis)</ID>
    <ID>MaxLineLength:V1NodeConfigurationSpec.kt$V1NodeConfigurationSpec$return result.mapValid { conf -&gt; Validated.withResult(conf as NodeConfiguration, conf.validate().map(::toError).toSet()) }</ID>
    <ID>MaxLineLength:V1NodeConfigurationSpec.kt$V1NodeConfigurationSpec$val messagingServerExternal = configuration[messagingServerExternal] ?: Defaults.messagingServerExternal(configuration[messagingServerAddress])</ID>
    <ID>MaxLineLength:V1NodeConfigurationSpec.kt$private fun toError(validationErrorMessage: String): Configuration.Validation.Error</ID>
    <ID>MaxLineLength:ValidateConfigurationCli.kt$ValidateConfigurationCli$internal</ID>
    <ID>MaxLineLength:ValidateConfigurationCli.kt$ValidateConfigurationCli$return cmdLineOptions.parseConfiguration(rawConfig).doIfValid { logRawConfig(rawConfig) }.doOnErrors(::logConfigurationErrors).optional?.let { ExitCodes.SUCCESS } ?: ExitCodes.FAILURE</ID>
    <ID>MaxLineLength:ValidateConfigurationCli.kt$ValidateConfigurationCli$val rawConfig = cmdLineOptions.rawConfiguration().doOnErrors(cmdLineOptions::logRawConfigurationErrors).optional ?: return ExitCodes.FAILURE</ID>
    <ID>MaxLineLength:ValidateConfigurationCli.kt$ValidateConfigurationCli.Companion$internal fun logRawConfig(config: Config)</ID>
    <ID>MaxLineLength:ValidateConfigurationCli.kt$ValidateConfigurationCli.Companion$logger.error(errors.joinToString(System.lineSeparator(), "Error(s) while parsing node configuration:${System.lineSeparator()}") { error -&gt; "\t- ${error.description()}" })</ID>
    <ID>MaxLineLength:ValidateConfigurationCli.kt$ValidateConfigurationCli.Companion$private val configRenderingOptions = ConfigRenderOptions.defaults().setFormatted(true).setComments(false).setOriginComments(false)</ID>
    <ID>MaxLineLength:ValidatingNotaryFlow.kt$ValidatingNotaryFlow : NotaryServiceFlow</ID>
    <ID>MaxLineLength:ValidatingNotaryFlow.kt$ValidatingNotaryFlow$open</ID>
    <ID>MaxLineLength:VaultSchema.kt$VaultSchemaV1.PersistentStateRefAndKey$@Embeddable @Immutable data</ID>
    <ID>MaxLineLength:VaultSchema.kt$VaultSchemaV1.VaultLinearStates$@Table(name = "vault_linear_states", indexes = [Index(name = "external_id_index", columnList = "external_id"), Index(name = "uuid_index", columnList = "uuid")])</ID>
    <ID>MaxLineLength:VaultSchema.kt$VaultSchemaV1.VaultStates$@Table(name = "vault_states", indexes = [Index(name = "state_status_idx", columnList = "state_status"), Index(name = "lock_id_idx", columnList = "lock_id, state_status")])</ID>
    <ID>MaxLineLength:VaultSchema.kt$VaultSchemaV1.VaultTxnNote$@Table(name = "vault_transaction_notes", indexes = [Index(name = "seq_no_index", columnList = "seq_no"), Index(name = "transaction_id_index", columnList = "transaction_id")])</ID>
    <ID>MaxLineLength:VaultServiceInternal.kt$VaultServiceInternal$ fun notify(statesToRecord: StatesToRecord, tx: CoreTransaction)</ID>
    <ID>MaxLineLength:VaultServiceInternal.kt$VaultServiceInternal$ fun notifyAll(statesToRecord: StatesToRecord, txns: Iterable&lt;CoreTransaction&gt;, previouslySeenTxns: Iterable&lt;CoreTransaction&gt; = emptyList())</ID>
    <ID>MaxLineLength:VaultStateMigration.kt$VaultMigrationSchema</ID>
    <ID>MaxLineLength:VaultStateMigration.kt$VaultStateIterator : Iterator</ID>
    <ID>MaxLineLength:VaultStateMigration.kt$VaultStateIterator$// The rest of this class is an attempt at multithreading that was ultimately scuppered by liquibase not providing a connection pool. // This may be useful as a starting point for improving performance of the migration, so is left here. To start using it, remove the // serialization environment changes in the execute function in the migration, and change forEach -&gt; parallelForEach. private val pool = ForkJoinPool.commonPool()</ID>
    <ID>MaxLineLength:VaultStateMigration.kt$VaultStateIterator$criteriaBuilder</ID>
    <ID>MaxLineLength:VaultStateMigration.kt$VaultStateIterator$logger.debug("Loaded page $pageNumber of ${(numStates - 1 / pageNumber.toLong()) + 1}. Current page has ${result.size} vault states")</ID>
    <ID>MaxLineLength:VaultStateMigration.kt$VaultStateIterator$private</ID>
    <ID>MaxLineLength:VaultStateMigration.kt$VaultStateIterator${ endTransaction() transaction = database.newTransaction() val query = createVaultStatesQuery(VaultSchemaV1.VaultStates::class.java) { it } // The above query excludes states that have entries in the state party table. As the iteration proceeds, each state has entries // added to this table. The result is that when the next page is retrieved, any results that were in the previous page are not in // the query at all! As such, the next set of states that need processing start at the first result. query.firstResult = 0 query.maxResults = pageSize pageNumber++ val result = query.resultList logger.debug("Loaded page $pageNumber of ${(numStates - 1 / pageNumber.toLong()) + 1}. Current page has ${result.size} vault states") return result }</ID>
    <ID>MaxLineLength:VaultStateMigration.kt$VaultStateIterator.Companion$effectiveSerializationEnv.serializationFactory</ID>
    <ID>MaxLineLength:VaultStateMigration.kt$VaultStateIterator.Companion.AMQPInspectorSerializationScheme$override</ID>
    <ID>MaxLineLength:VaultStateMigration.kt$VaultStateIterator.Companion.AMQPInspectorSerializationScheme$override fun rpcClientSerializerFactory(context: SerializationContext)</ID>
    <ID>MaxLineLength:VaultStateMigration.kt$VaultStateIterator.Companion.AMQPInspectorSerializationScheme$override fun rpcServerSerializerFactory(context: SerializationContext)</ID>
    <ID>MaxLineLength:VaultStateMigration.kt$VaultStateIterator.VaultPageTask$effectiveSerializationEnv.serializationFactory</ID>
    <ID>MaxLineLength:VaultStateMigration.kt$VaultStateIterator.VaultPageTask$return listOf(VaultPageTask(database, page.subList(0, pageSize / 2), block), VaultPageTask(database, page.subList(pageSize / 2, pageSize), block))</ID>
    <ID>MaxLineLength:VaultStateMigration.kt$VaultStateMigration$logger</ID>
    <ID>MaxLineLength:VaultStateMigration.kt$VaultStateMigration$logger.info("Finished performing vault state data migration for ${persistentStates.numStates - statesSkipped} states")</ID>
    <ID>MaxLineLength:VaultStateMigration.kt$VaultStateMigration$throw VaultStateMigrationException("Cannot add state parties for state ${stateAndRef.ref} as state class is not on the " + "classpath and participants cannot be synthesised")</ID>
    <ID>MaxLineLength:VaultStateMigration.kt$VaultStateMigration$throw VaultStateMigrationException("Cannot migrate vault states as liquibase failed to provide a suitable database connection")</ID>
    <ID>MaxLineLength:VaultStateMigration.kt$VaultStateMigration$throw VaultStateMigrationException("Failed to migrate $statesSkipped states in the vault. Check the logs for details of the " + "error for each state.")</ID>
    <ID>MaxLineLength:VaultStateMigration.kt$VaultStateMigration$val myKeys = identityService.stripNotOurKeys(stateAndRef.state.data.participants.map { participant -&gt; participant.owningKey }).toSet()</ID>
    <ID>MaxLineLength:VaultStateMigration.kt$VaultStateMigration${ // This should only happen if there was no attachment that could be used to deserialise the output states, and the state was // serialised such that the participants list cannot be accessed (participants is calculated and not marked as a // SerializableCalculatedProperty. throw VaultStateMigrationException("Cannot add state parties for state ${stateAndRef.ref} as state class is not on the " + "classpath and participants cannot be synthesised") }</ID>
    <ID>MaxLineLength:VaultStateMigration.kt$VaultStateMigration${ val stateAndRef = getStateAndRef(it) addStateParties(session, stateAndRef) // Can get away without checking for AbstractMethodErrors here as these will have already occurred when trying to add // state parties. val myKeys = identityService.stripNotOurKeys(stateAndRef.state.data.participants.map { participant -&gt; participant.owningKey }).toSet() if (!NodeVaultService.isRelevant(stateAndRef.state.data, myKeys)) { it.relevancyStatus = Vault.RelevancyStatus.NOT_RELEVANT } }</ID>
    <ID>MaxLineLength:VersionInfo.kt$VersionInfo$/** * Platform version of the node which is an integer value which increments on any release where any of the public * API of the entire Corda platform changes. This includes messaging, serialisation, node APIs, etc. */ val platformVersion: Int</ID>
    <ID>MaxLineLength:VirtualCordapps.kt$VirtualCordapp$info = Cordapp.Info.Default("corda-core", versionInfo.vendor, versionInfo.releaseVersion, "Open Source (Apache 2)")</ID>
    <ID>MaxLineLength:VirtualCordapps.kt$VirtualCordapp$info = Cordapp.Info.Default("corda-notary", versionInfo.vendor, versionInfo.releaseVersion, "Open Source (Apache 2)")</ID>
    <ID>MaxLineLength:VirtualCordapps.kt$VirtualCordapp$info = Cordapp.Info.Default("corda-notary-bft-smart", versionInfo.vendor, versionInfo.releaseVersion, "Open Source (Apache 2)")</ID>
    <ID>MaxLineLength:VirtualCordapps.kt$VirtualCordapp$info = Cordapp.Info.Default("corda-notary-raft", versionInfo.vendor, versionInfo.releaseVersion, "Open Source (Apache 2)")</ID>
    <ID>MaxLineLength:WritablePublicKeyToOwningIdentityCache.kt$WritablePublicKeyToOwningIdentityCache : PublicKeyToOwningIdentityCache</ID>
    <ID>ModifierOrder:NodeNamedCache.kt$DefaultNamedCacheFactory$open protected</ID>
    <ID>NestedBlockDepth:AbstractNode.kt$AbstractNode$private fun installCordaServices()</ID>
    <ID>NestedBlockDepth:AbstractNode.kt$AbstractNode$private fun registerCordappFlows()</ID>
    <ID>NestedBlockDepth:CheckpointVerifier.kt$CheckpointVerifier$ fun verifyCheckpointsCompatible( checkpointStorage: CheckpointStorage, currentCordapps: List&lt;Cordapp&gt;, platformVersion: Int, serviceHub: ServiceHub, tokenizableServices: List&lt;Any&gt; )</ID>
    <ID>NestedBlockDepth:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$override fun parseCriteria(criteria: CommonQueryCriteria): Collection&lt;Predicate&gt;</ID>
    <ID>NestedBlockDepth:NetworkRegistrationHelper.kt$NetworkRegistrationHelper$ private fun pollServerForCertificates(requestId: String): List&lt;X509Certificate&gt;</ID>
    <ID>NestedBlockDepth:Node.kt$Node$ override fun startDatabase()</ID>
    <ID>NestedBlockDepth:Node.kt$Node$ private fun tryDetectIfNotPublicHost(host: String): String?</ID>
    <ID>NestedBlockDepth:Node.kt$Node$private fun startLocalRpcBroker(securityManager: RPCSecurityManager): BrokerAddresses?</ID>
    <ID>NestedBlockDepth:NodeVaultService.kt$NodeVaultService$private fun recordUpdate(update: Vault.Update&lt;ContractState&gt;, previouslySeen: Boolean): Vault.Update&lt;ContractState&gt;</ID>
    <ID>NestedBlockDepth:NonValidatingNotaryFlow.kt$NonValidatingNotaryFlow$override fun verifyTransaction(requestPayload: NotarisationPayload)</ID>
    <ID>NestedBlockDepth:ObjectDiffer.kt$ObjectDiffer$fun diff(a: Any?, b: Any?): DiffTree?</ID>
    <ID>NestedBlockDepth:StartedFlowTransition.kt$StartedFlowTransition$private fun TransitionBuilder.sendToSessionsTransition(sourceSessionIdToMessage: Map&lt;SessionId, SerializedBytes&lt;Any&gt;&gt;)</ID>
    <ID>NewLineAtEndOfFile:AbstractNode.kt$net.corda.node.internal.AbstractNode.kt</ID>
    <ID>NewLineAtEndOfFile:AbstractPartyDescriptor.kt$net.corda.node.services.persistence.AbstractPartyDescriptor.kt</ID>
    <ID>NewLineAtEndOfFile:AddressUtils.kt$net.corda.node.utilities.AddressUtils.kt</ID>
    <ID>NewLineAtEndOfFile:ArtemisBroker.kt$net.corda.node.internal.artemis.ArtemisBroker.kt</ID>
    <ID>NewLineAtEndOfFile:AuthenticatedRpcOpsProxy.kt$net.corda.node.internal.rpc.proxies.AuthenticatedRpcOpsProxy.kt</ID>
    <ID>NewLineAtEndOfFile:AuthorizingSubject.kt$net.corda.node.internal.security.AuthorizingSubject.kt</ID>
    <ID>NewLineAtEndOfFile:BrokerJaasLoginModule.kt$net.corda.node.internal.artemis.BrokerJaasLoginModule.kt</ID>
    <ID>NewLineAtEndOfFile:CertificateChainCheckPolicy.kt$net.corda.node.internal.artemis.CertificateChainCheckPolicy.kt</ID>
    <ID>NewLineAtEndOfFile:CertificatesUtils.kt$net.corda.node.utilities.CertificatesUtils.kt</ID>
    <ID>NewLineAtEndOfFile:CheckpointStorage.kt$net.corda.node.services.api.CheckpointStorage.kt</ID>
    <ID>NewLineAtEndOfFile:ClearNetworkCacheCli.kt$net.corda.node.internal.subcommands.ClearNetworkCacheCli.kt</ID>
    <ID>NewLineAtEndOfFile:ConfigSections.kt$net.corda.node.services.config.schema.v1.ConfigSections.kt</ID>
    <ID>NewLineAtEndOfFile:ConfigUtilities.kt$net.corda.node.services.config.ConfigUtilities.kt</ID>
    <ID>NewLineAtEndOfFile:ContextualLoggingUtils.kt$net.corda.node.services.logging.ContextualLoggingUtils.kt</ID>
    <ID>NewLineAtEndOfFile:CordaClosureSerializer.kt$net.corda.node.serialization.kryo.CordaClosureSerializer.kt</ID>
    <ID>NewLineAtEndOfFile:CordappConfigProvider.kt$net.corda.node.internal.cordapp.CordappConfigProvider.kt</ID>
    <ID>NewLineAtEndOfFile:DbExceptionHandler.kt$net.corda.node.internal.DbExceptionHandler.kt</ID>
    <ID>NewLineAtEndOfFile:DbTransactionsResolver.kt$net.corda.node.services.DbTransactionsResolver.kt</ID>
    <ID>NewLineAtEndOfFile:DeduplicationId.kt$net.corda.node.services.statemachine.DeduplicationId.kt</ID>
    <ID>NewLineAtEndOfFile:DefaultKryoCustomizer.kt$net.corda.node.serialization.kryo.DefaultKryoCustomizer.kt</ID>
    <ID>NewLineAtEndOfFile:ExceptionSerialisingRpcOpsProxy.kt$net.corda.node.internal.rpc.proxies.ExceptionSerialisingRpcOpsProxy.kt</ID>
    <ID>NewLineAtEndOfFile:FlowMonitor.kt$net.corda.node.services.statemachine.FlowMonitor.kt</ID>
    <ID>NewLineAtEndOfFile:FlowTimeoutException.kt$net.corda.node.services.statemachine.FlowTimeoutException.kt</ID>
    <ID>NewLineAtEndOfFile:GenerateNodeInfoCli.kt$net.corda.node.internal.subcommands.GenerateNodeInfoCli.kt</ID>
    <ID>NewLineAtEndOfFile:HibernateQueryCriteriaParser.kt$net.corda.node.services.vault.HibernateQueryCriteriaParser.kt</ID>
    <ID>NewLineAtEndOfFile:InfrequentlyMutatedCache.kt$net.corda.node.utilities.InfrequentlyMutatedCache.kt</ID>
    <ID>NewLineAtEndOfFile:InvocationHandlerTemplate.kt$net.corda.node.internal.InvocationHandlerTemplate.kt</ID>
    <ID>NewLineAtEndOfFile:JVMAgentRegistry.kt$net.corda.node.utilities.JVMAgentRegistry.kt</ID>
    <ID>NewLineAtEndOfFile:LifecycleSupport.kt$net.corda.node.internal.LifecycleSupport.kt</ID>
    <ID>NewLineAtEndOfFile:MetricInterceptor.kt$net.corda.node.services.statemachine.interceptors.MetricInterceptor.kt</ID>
    <ID>NewLineAtEndOfFile:MigrationNamedCacheFactory.kt$net.corda.node.migration.MigrationNamedCacheFactory.kt</ID>
    <ID>NewLineAtEndOfFile:MigrationServicesForResolution.kt$net.corda.node.migration.MigrationServicesForResolution.kt</ID>
    <ID>NewLineAtEndOfFile:NetworkMapUpdater.kt$net.corda.node.services.network.NetworkMapUpdater.kt</ID>
    <ID>NewLineAtEndOfFile:NodeAttachmentService.kt$net.corda.node.services.persistence.NodeAttachmentService.kt</ID>
    <ID>NewLineAtEndOfFile:NodeBuildProperties.kt$net.corda.node.utilities.NodeBuildProperties.kt</ID>
    <ID>NewLineAtEndOfFile:NodeConfigurationImpl.kt$net.corda.node.services.config.NodeConfigurationImpl.kt</ID>
    <ID>NewLineAtEndOfFile:NodeNamedCache.kt$net.corda.node.utilities.NodeNamedCache.kt</ID>
    <ID>NewLineAtEndOfFile:NodePropertiesStore.kt$net.corda.node.services.api.NodePropertiesStore.kt</ID>
    <ID>NewLineAtEndOfFile:NodeRpcOptions.kt$net.corda.node.services.config.rpc.NodeRpcOptions.kt</ID>
    <ID>NewLineAtEndOfFile:NodeUniqueIdProvider.kt$net.corda.node.internal.NodeUniqueIdProvider.kt</ID>
    <ID>NewLineAtEndOfFile:NodeVaultService.kt$net.corda.node.services.vault.NodeVaultService.kt</ID>
    <ID>NewLineAtEndOfFile:NonInvalidatingCache.kt$net.corda.node.utilities.NonInvalidatingCache.kt</ID>
    <ID>NewLineAtEndOfFile:NonInvalidatingUnboundCache.kt$net.corda.node.utilities.NonInvalidatingUnboundCache.kt</ID>
    <ID>NewLineAtEndOfFile:NotaryLoader.kt$net.corda.node.utilities.NotaryLoader.kt</ID>
    <ID>NewLineAtEndOfFile:ObjectDiffer.kt$net.corda.node.utilities.ObjectDiffer.kt</ID>
    <ID>NewLineAtEndOfFile:ObservableContextInterface.kt$net.corda.node.services.rpc.ObservableContextInterface.kt</ID>
    <ID>NewLineAtEndOfFile:Password.kt$net.corda.node.internal.security.Password.kt</ID>
    <ID>NewLineAtEndOfFile:Permissions.kt$net.corda.node.services.Permissions.kt</ID>
    <ID>NewLineAtEndOfFile:PersistentIdentityMigration.kt$net.corda.node.migration.PersistentIdentityMigration.kt</ID>
    <ID>NewLineAtEndOfFile:PersistentIdentityMigrationNewTable.kt$net.corda.node.migration.PersistentIdentityMigrationNewTable.kt</ID>
    <ID>NewLineAtEndOfFile:PersistentIdentityService.kt$net.corda.node.services.identity.PersistentIdentityService.kt</ID>
    <ID>NewLineAtEndOfFile:PersistentScheduledFlowRepository.kt$net.corda.node.services.events.PersistentScheduledFlowRepository.kt</ID>
    <ID>NewLineAtEndOfFile:PublicKeyHashToExternalId.kt$net.corda.node.services.persistence.PublicKeyHashToExternalId.kt</ID>
    <ID>NewLineAtEndOfFile:PublicKeyToOwningIdentityCacheImpl.kt$net.corda.node.services.persistence.PublicKeyToOwningIdentityCacheImpl.kt</ID>
    <ID>NewLineAtEndOfFile:PublicKeyToTextConverter.kt$net.corda.node.services.persistence.PublicKeyToTextConverter.kt</ID>
    <ID>NewLineAtEndOfFile:RPCSecurityManagerImpl.kt$net.corda.node.internal.security.RPCSecurityManagerImpl.kt</ID>
    <ID>NewLineAtEndOfFile:RaftConfig.kt$net.corda.notary.experimental.raft.RaftConfig.kt</ID>
    <ID>NewLineAtEndOfFile:RaftTransactionCommitLog.kt$net.corda.notary.experimental.raft.RaftTransactionCommitLog.kt</ID>
    <ID>NewLineAtEndOfFile:ReactiveArtemisConsumer.kt$net.corda.node.internal.artemis.ReactiveArtemisConsumer.kt</ID>
    <ID>NewLineAtEndOfFile:RolesAdderOnLogin.kt$net.corda.node.services.rpc.RolesAdderOnLogin.kt</ID>
    <ID>NewLineAtEndOfFile:RpcBrokerConfiguration.kt$net.corda.node.services.rpc.RpcBrokerConfiguration.kt</ID>
    <ID>NewLineAtEndOfFile:RpcServerObservableSerializer.kt$net.corda.node.serialization.amqp.RpcServerObservableSerializer.kt</ID>
    <ID>NewLineAtEndOfFile:SchedulerService.kt$net.corda.node.services.api.SchedulerService.kt</ID>
    <ID>NewLineAtEndOfFile:Schema.kt$net.corda.notary.experimental.bftsmart.Schema.kt</ID>
    <ID>NewLineAtEndOfFile:Schema.kt$net.corda.notary.experimental.raft.Schema.kt</ID>
    <ID>NewLineAtEndOfFile:SecureArtemisConfiguration.kt$net.corda.node.internal.artemis.SecureArtemisConfiguration.kt</ID>
    <ID>NewLineAtEndOfFile:SerializeAsTokenSerializer.kt$net.corda.node.serialization.kryo.SerializeAsTokenSerializer.kt</ID>
    <ID>NewLineAtEndOfFile:StaffedFlowHospital.kt$net.corda.node.services.statemachine.StaffedFlowHospital.kt</ID>
    <ID>NewLineAtEndOfFile:StandardConfigValueParsers.kt$net.corda.node.services.config.schema.parsers.StandardConfigValueParsers.kt</ID>
    <ID>NewLineAtEndOfFile:StateMachineState.kt$net.corda.node.services.statemachine.StateMachineState.kt</ID>
    <ID>NewLineAtEndOfFile:ThreadContextAdjustingRpcOpsProxy.kt$net.corda.node.internal.rpc.proxies.ThreadContextAdjustingRpcOpsProxy.kt</ID>
    <ID>NewLineAtEndOfFile:TimedFlowUtils.kt$net.corda.node.utilities.TimedFlowUtils.kt</ID>
    <ID>NewLineAtEndOfFile:TopLevelTransition.kt$net.corda.node.services.statemachine.transitions.TopLevelTransition.kt</ID>
    <ID>NewLineAtEndOfFile:TypesafeCordappConfig.kt$net.corda.node.internal.cordapp.TypesafeCordappConfig.kt</ID>
    <ID>NewLineAtEndOfFile:Utils.kt$net.corda.node.internal.classloading.Utils.kt</ID>
    <ID>NewLineAtEndOfFile:V1NodeConfigurationSpec.kt$net.corda.node.services.config.schema.v1.V1NodeConfigurationSpec.kt</ID>
    <ID>NewLineAtEndOfFile:VaultStateMigration.kt$net.corda.node.migration.VaultStateMigration.kt</ID>
    <ID>NewLineAtEndOfFile:VersionInfo.kt$net.corda.node.VersionInfo.kt</ID>
    <ID>NewLineAtEndOfFile:VirtualCordapps.kt$net.corda.node.internal.cordapp.VirtualCordapps.kt</ID>
    <ID>NewLineAtEndOfFile:WritablePublicKeyToOwningIdentityCache.kt$net.corda.node.services.persistence.WritablePublicKeyToOwningIdentityCache.kt</ID>
    <ID>NewLineAtEndOfFile:errorAndTerminate.kt$net.corda.node.utilities.errorAndTerminate.kt</ID>
    <ID>ReturnCount:AbstractPartyDescriptor.kt$AbstractPartyDescriptor$override fun &lt;X : Any&gt; unwrap(value: AbstractParty?, type: Class&lt;X&gt;, options: WrapperOptions): X?</ID>
    <ID>ReturnCount:AbstractPartyDescriptor.kt$AbstractPartyDescriptor$override fun &lt;X : Any&gt; wrap(value: X?, options: WrapperOptions): AbstractParty?</ID>
    <ID>ReturnCount:CordaClassResolver.kt$CordaClassResolver$private fun checkClass(type: Class&lt;*&gt;): Registration?</ID>
    <ID>ReturnCount:FlowLogicRefFactoryImpl.kt$FlowLogicRefFactoryImpl$private fun buildParams(constructor: KFunction&lt;FlowLogic&lt;*&gt;&gt;, args: Map&lt;String, Any?&gt;): HashMap&lt;KParameter, Any?&gt;?</ID>
    <ID>ReturnCount:FlowManager.kt$NodeFlowManager.FlowWeightComparator$override fun compare(o1: NodeFlowManager.RegisteredFlowContainer, o2: NodeFlowManager.RegisteredFlowContainer): Int</ID>
    <ID>ReturnCount:JarScanningCordappLoader.kt$JarScanningCordappLoader$private fun parseCordappInfo(manifest: Manifest?, defaultName: String): Cordapp.Info</ID>
    <ID>ReturnCount:NetworkRegistrationHelper.kt$NodeRegistrationHelper$override fun validateAndGetTlsCrlIssuerCert(): X509Certificate?</ID>
    <ID>ReturnCount:NodeConfigurationImpl.kt$NodeConfigurationImpl$private fun validateDevModeOptions(): List&lt;String&gt;</ID>
    <ID>ReturnCount:NodeSchemaService.kt$NodeSchemaService$// Because schema is always one supported by the state, just delegate. override fun generateMappedObject(state: ContractState, schema: MappedSchema): PersistentState</ID>
    <ID>ReturnCount:NodeStartup.kt$NodeStartup$fun initialiseAndRun(cmdLineOptions: SharedNodeCmdLineOptions, afterNodeInitialisation: RunAfterNodeInitialisation, requireCertificates: Boolean = false): Int</ID>
    <ID>ReturnCount:NodeStartup.kt$NodeStartup$fun isNodeRunningAt(baseDirectory: Path): Boolean</ID>
    <ID>ReturnCount:NodeStartup.kt$NodeStartup$private fun canReadCertificatesDirectory(certDirectory: Path, devMode: Boolean): Boolean</ID>
    <ID>ReturnCount:NodeStartup.kt$fun CliWrapperBase.initLogging(baseDirectory: Path): Boolean</ID>
    <ID>ReturnCount:NodeVaultService.kt$NodeVaultService$@Suspendable @Throws(StatesNotAvailableException::class) override fun &lt;T : FungibleState&lt;*&gt;&gt; tryLockFungibleStatesForSpending( lockId: UUID, eligibleStatesQuery: QueryCriteria, amount: Amount&lt;*&gt;, contractStateType: Class&lt;out T&gt; ): List&lt;StateAndRef&lt;T&gt;&gt;</ID>
    <ID>ReturnCount:ObjectDiffer.kt$ObjectDiffer$fun diff(a: Any?, b: Any?): DiffTree?</ID>
    <ID>ReturnCount:PersistentNetworkMapCache.kt$PersistentNetworkMapCache$override fun getPartyInfo(party: Party): PartyInfo?</ID>
    <ID>ReturnCount:RPCSecurityManagerImpl.kt$RPCPermissionResolver$override fun resolvePermission(representation: String): Permission</ID>
    <ID>ReturnCount:SerialFilter.kt$SerialFilter$internal fun applyPredicate(acceptClass: (Class&lt;*&gt;) -&gt; Boolean, serialClass: Class&lt;*&gt;?): Boolean</ID>
    <ID>ReturnCount:ServicesForResolutionImpl.kt$ServicesForResolutionImpl$// We may need to recursively chase transactions if there are notary changes. fun inner(stateRef: StateRef, forContractClassName: String?): Attachment</ID>
    <ID>ReturnCount:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$override fun retryFlowFromSafePoint(currentState: StateMachineState)</ID>
    <ID>ReturnCount:TransitionExecutorImpl.kt$TransitionExecutorImpl$@Suspendable override fun executeTransition( fiber: FlowFiber, previousState: StateMachineState, event: Event, transition: TransitionResult, actionExecutor: ActionExecutor ): Pair&lt;FlowContinuation, StateMachineState&gt;</ID>
    <ID>SpreadOperator:AbstractNode.kt$FlowStarterImpl$(logicType, *args)</ID>
    <ID>SpreadOperator:AuthenticatedRpcOpsProxy.kt$(methodName, *(args.map(Class&lt;*&gt;::getName).toTypedArray()))</ID>
    <ID>SpreadOperator:AuthenticatedRpcOpsProxy.kt$AuthenticatedRpcOpsProxy$(logicType, *args)</ID>
    <ID>SpreadOperator:ConfigUtilities.kt$(*pairs)</ID>
    <ID>SpreadOperator:CordaRPCOpsImpl.kt$CordaRPCOpsImpl$(logicType, context(), *args)</ID>
    <ID>SpreadOperator:FlowLogicRefFactoryImpl.kt$FlowLogicRefFactoryImpl$(flowClass, *args)</ID>
    <ID>SpreadOperator:HibernateQueryCriteriaParser.kt$AbstractQueryCriteriaParser$(*leftPredicates.toTypedArray())</ID>
    <ID>SpreadOperator:HibernateQueryCriteriaParser.kt$AbstractQueryCriteriaParser$(*leftPredicates.toTypedArray(), *rightPredicates.toTypedArray())</ID>
    <ID>SpreadOperator:HibernateQueryCriteriaParser.kt$AbstractQueryCriteriaParser$(*rightPredicates.toTypedArray())</ID>
    <ID>SpreadOperator:HibernateQueryCriteriaParser.kt$HibernateAttachmentQueryCriteriaParser$(*predicateSet.toTypedArray())</ID>
    <ID>SpreadOperator:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$(*combinedPredicates.toTypedArray())</ID>
    <ID>SpreadOperator:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$(*joinPredicates.toTypedArray())</ID>
    <ID>SpreadOperator:InvocationHandlerTemplate.kt$InvocationHandlerTemplate$(delegate, *args)</ID>
    <ID>SpreadOperator:Kryo.kt$ImmutableClassSerializer$(*args)</ID>
    <ID>SpreadOperator:NetworkMapUpdater.kt$NetworkMapUpdater$(*networkMapDownloadFutures)</ID>
    <ID>SpreadOperator:NodeVaultService.kt$NodeVaultService$(*commonPredicates)</ID>
    <ID>SpreadOperator:NodeVaultService.kt$NodeVaultService$(*commonPredicates, stateRefsPredicate)</ID>
    <ID>SpreadOperator:NodeVaultService.kt$NodeVaultService$(lockUpdateTime, lockIdPredicate, *commonPredicates)</ID>
    <ID>SpreadOperator:NodeVaultService.kt$NodeVaultService$(stateStatusPredication, lockIdPredicate, *commonPredicates)</ID>
    <ID>SpreadOperator:RPCServer.kt$RPCServer$(ops, *arguments.toTypedArray())</ID>
    <ID>SpreadOperator:ReactiveArtemisConsumer.kt$ReactiveArtemisConsumer.Companion$(queueName, *queueNames)</ID>
    <ID>ThrowsCount:AbstractNode.kt$fun CordaPersistence.startHikariPool(hikariProperties: Properties, databaseConfig: DatabaseConfig, schemas: Set&lt;MappedSchema&gt;, metricRegistry: MetricRegistry? = null, cordappLoader: CordappLoader? = null, currentDir: Path? = null, ourName: CordaX500Name)</ID>
    <ID>ThrowsCount:ArtemisMessagingServer.kt$ArtemisMessagingServer$// TODO: Maybe wrap [IOException] on a key store load error so that it's clearly splitting key store loading from // Artemis IO errors @Throws(IOException::class, AddressBindingException::class, KeyStoreException::class) private fun configureAndStartServer()</ID>
    <ID>ThrowsCount:BrokerJaasLoginModule.kt$BaseBrokerJaasLoginModule$protected fun getUsernamePasswordAndCerts(): Triple&lt;String, String, Array&lt;X509Certificate&gt;?&gt;</ID>
    <ID>ThrowsCount:CheckpointVerifier.kt$CheckpointVerifier$ fun verifyCheckpointsCompatible( checkpointStorage: CheckpointStorage, currentCordapps: List&lt;Cordapp&gt;, platformVersion: Int, serviceHub: ServiceHub, tokenizableServices: List&lt;Any&gt; )</ID>
    <ID>ThrowsCount:CheckpointVerifier.kt$CheckpointVerifier$// Throws exception when the flow is incompatible private fun checkFlowCompatible(subFlow: SubFlow, currentCordappsByHash: Map&lt;SecureHash.SHA256, Cordapp&gt;, platformVersion: Int)</ID>
    <ID>ThrowsCount:JarScanningCordappLoader.kt$JarScanningCordappLoader$private fun parseVersion(versionStr: String?, attributeName: String): Int</ID>
    <ID>ThrowsCount:NetworkRegistrationHelper.kt$NetworkRegistrationHelper$private fun validateCertificates(registeringPublicKey: PublicKey, certificates: List&lt;X509Certificate&gt;)</ID>
    <ID>ThrowsCount:NodeVaultService.kt$NodeVaultService$@Throws(VaultQueryException::class) private fun &lt;T : ContractState&gt; _queryBy(criteria: QueryCriteria, paging_: PageSpecification, sorting: Sort, contractStateType: Class&lt;out T&gt;, skipPagingChecks: Boolean): Vault.Page&lt;T&gt;</ID>
    <ID>ThrowsCount:NodeVaultService.kt$NodeVaultService$private fun makeUpdates(batch: Iterable&lt;CoreTransaction&gt;, statesToRecord: StatesToRecord, previouslySeen: Boolean): List&lt;Vault.Update&lt;ContractState&gt;&gt;</ID>
    <ID>ThrowsCount:NonValidatingNotaryFlow.kt$NonValidatingNotaryFlow$ private fun checkNotaryWhitelisted(notary: Party, attachedParameterHash: SecureHash?)</ID>
    <ID>ThrowsCount:RPCServer.kt$RPCServer$private fun invokeRpc(context: RpcAuthContext, methodName: String, arguments: List&lt;Any?&gt;): Try&lt;Any&gt;</ID>
    <ID>ThrowsCount:ServicesForResolutionImpl.kt$ServicesForResolutionImpl$// We may need to recursively chase transactions if there are notary changes. fun inner(stateRef: StateRef, forContractClassName: String?): Attachment</ID>
    <ID>ThrowsCount:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$private fun getInitiatedFlowFactory(message: InitialSessionMessage): InitiatedFlowFactory&lt;*&gt;</ID>
    <ID>TooGenericExceptionCaught:AbstractNode.kt$AbstractNode$e: Exception</ID>
    <ID>TooGenericExceptionCaught:AbstractNode.kt$AbstractNode.&lt;no name provided&gt;$e: Exception</ID>
    <ID>TooGenericExceptionCaught:AbstractNode.kt$ex: Exception</ID>
    <ID>TooGenericExceptionCaught:BrokerJaasLoginModule.kt$BrokerJaasLoginModule$e: Exception</ID>
    <ID>TooGenericExceptionCaught:CheckpointDumper.kt$CheckpointDumper$e: Exception</ID>
    <ID>TooGenericExceptionCaught:CheckpointVerifier.kt$CheckpointVerifier$e: Exception</ID>
    <ID>TooGenericExceptionCaught:CordaClassResolver.kt$LoggingWhitelist.Companion$ioEx: Exception</ID>
    <ID>TooGenericExceptionCaught:CordaRPCOpsImpl.kt$CordaRPCOpsImpl$e: Exception</ID>
    <ID>TooGenericExceptionCaught:DBNetworkParametersStorage.kt$DBNetworkParametersStorage$e: Exception</ID>
    <ID>TooGenericExceptionCaught:ExceptionMaskingRpcOpsProxy.kt$ExceptionMaskingRpcOpsProxy.ErrorObfuscatingInvocationHandler$exception: Exception</ID>
    <ID>TooGenericExceptionCaught:ExceptionSerialisingRpcOpsProxy.kt$ExceptionSerialisingRpcOpsProxy.ErrorSerialisingInvocationHandler$exception: Exception</ID>
    <ID>TooGenericExceptionCaught:FiberDeserializationCheckingInterceptor.kt$FiberDeserializationChecker$exception: Exception</ID>
    <ID>TooGenericExceptionCaught:FlowMessaging.kt$FlowMessagingImpl$exception: Exception</ID>
    <ID>TooGenericExceptionCaught:FlowStateMachineImpl.kt$FlowStateMachineImpl$exception: Exception</ID>
    <ID>TooGenericExceptionCaught:FlowStateMachineImpl.kt$FlowStateMachineImpl$t: Throwable</ID>
    <ID>TooGenericExceptionCaught:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser$e: Exception</ID>
    <ID>TooGenericExceptionCaught:InitialRegistrationCli.kt$InitialRegistration$e: Exception</ID>
    <ID>TooGenericExceptionCaught:InitialRegistrationCli.kt$InitialRegistration.Companion$e: Exception</ID>
    <ID>TooGenericExceptionCaught:JarScanningCordappLoader.kt$JarScanningCordappLoader$e: Exception</ID>
    <ID>TooGenericExceptionCaught:Kryo.kt$ImmutableClassSerializer$e: Exception</ID>
    <ID>TooGenericExceptionCaught:MigrationServicesForResolution.kt$MigrationServicesForResolution$e: Exception</ID>
    <ID>TooGenericExceptionCaught:NetworkMapUpdater.kt$NetworkMapUpdater$e: Exception</ID>
    <ID>TooGenericExceptionCaught:NetworkMapUpdater.kt$NetworkMapUpdater.&lt;no name provided&gt;$e: Exception</ID>
    <ID>TooGenericExceptionCaught:NetworkParametersReader.kt$NetworkParametersReader$e: Exception</ID>
    <ID>TooGenericExceptionCaught:NetworkRegistrationHelper.kt$NetworkRegistrationHelper$e: Exception</ID>
    <ID>TooGenericExceptionCaught:NodeInfoWatcher.kt$NodeInfoWatcher$e: Exception</ID>
    <ID>TooGenericExceptionCaught:NodeSchedulerService.kt$NodeSchedulerService$e: Exception</ID>
    <ID>TooGenericExceptionCaught:NodeStartup.kt$NodeStartup$e: Exception</ID>
    <ID>TooGenericExceptionCaught:NodeVaultService.kt$NodeVaultService$e: Exception</ID>
    <ID>TooGenericExceptionCaught:NonValidatingNotaryFlow.kt$NonValidatingNotaryFlow$e: Exception</ID>
    <ID>TooGenericExceptionCaught:ObjectDiffer.kt$ObjectDiffer$throwable: Exception</ID>
    <ID>TooGenericExceptionCaught:P2PMessagingClient.kt$P2PMessagingClient$e: Exception</ID>
    <ID>TooGenericExceptionCaught:PersistentIdentityMigrationNewTable.kt$PersistentIdentityMigrationNewTable$e: Exception</ID>
    <ID>TooGenericExceptionCaught:PersistentUniquenessProvider.kt$PersistentUniquenessProvider$e: Exception</ID>
    <ID>TooGenericExceptionCaught:RPCServer.kt$RPCServer$e: Exception</ID>
    <ID>TooGenericExceptionCaught:RPCServer.kt$RPCServer$exception: Throwable</ID>
    <ID>TooGenericExceptionCaught:RPCServer.kt$RPCServer$throwable: Throwable</ID>
    <ID>TooGenericExceptionCaught:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$ex: Exception</ID>
    <ID>TooGenericExceptionCaught:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$exception: Exception</ID>
    <ID>TooGenericExceptionCaught:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager$t: Throwable</ID>
    <ID>TooGenericExceptionCaught:StandardConfigValueParsers.kt$e: Exception</ID>
    <ID>TooGenericExceptionCaught:TransitionExecutorImpl.kt$TransitionExecutorImpl$exception: Exception</ID>
    <ID>TooGenericExceptionCaught:V1NodeConfigurationSpec.kt$V1NodeConfigurationSpec$e: Exception</ID>
    <ID>TooGenericExceptionCaught:ValidatingNotaryFlow.kt$ValidatingNotaryFlow$e: Exception</ID>
    <ID>TooGenericExceptionCaught:VaultStateMigration.kt$VaultStateIterator$e: Exception</ID>
    <ID>TooGenericExceptionCaught:VaultStateMigration.kt$VaultStateMigration$e: Exception</ID>
    <ID>TooGenericExceptionThrown:AbstractNode.kt$AbstractNode$throw Error("Unable to locate agent jar file")</ID>
    <ID>TooManyFunctions:AbstractNode.kt$AbstractNode&lt;S&gt; : SingletonSerializeAsToken</ID>
    <ID>TooManyFunctions:ActionExecutorImpl.kt$ActionExecutorImpl : ActionExecutor</ID>
    <ID>TooManyFunctions:AppendOnlyPersistentMap.kt$AppendOnlyPersistentMapBase&lt;K, V, E, out EK&gt;</ID>
    <ID>TooManyFunctions:BFTSmart.kt$BFTSmart$Replica : DefaultRecoverable</ID>
    <ID>TooManyFunctions:CheckpointDumper.kt$CheckpointDumper</ID>
    <ID>TooManyFunctions:CordaRPCOpsImpl.kt$CordaRPCOpsImpl : InternalCordaRPCOpsAutoCloseable</ID>
    <ID>TooManyFunctions:ExceptionMaskingRpcOpsProxy.kt$ExceptionMaskingRpcOpsProxy$ErrorObfuscatingInvocationHandler : InvocationHandlerTemplate</ID>
    <ID>TooManyFunctions:FlowLogicRefFactoryImpl.kt$FlowLogicRefFactoryImpl : SingletonSerializeAsTokenFlowLogicRefFactory</ID>
    <ID>TooManyFunctions:FlowSessionImpl.kt$FlowSessionImpl : FlowSession</ID>
    <ID>TooManyFunctions:FlowStateMachineImpl.kt$FlowStateMachineImpl&lt;R&gt; : FiberFlowStateMachineFlowFiber</ID>
    <ID>TooManyFunctions:HibernateQueryCriteriaParser.kt$HibernateQueryCriteriaParser : AbstractQueryCriteriaParserIQueryCriteriaParser</ID>
    <ID>TooManyFunctions:JarScanningCordappLoader.kt$JarScanningCordappLoader : CordappLoaderTemplate</ID>
    <ID>TooManyFunctions:Node.kt$Node : AbstractNode</ID>
    <ID>TooManyFunctions:NodeAttachmentService.kt$NodeAttachmentService : AttachmentStorageInternalSingletonSerializeAsToken</ID>
    <ID>TooManyFunctions:NodeStartup.kt$NodeStartup : NodeStartupLogging</ID>
    <ID>TooManyFunctions:NodeVaultService.kt$NodeVaultService : SingletonSerializeAsTokenVaultServiceInternal</ID>
    <ID>TooManyFunctions:P2PMessagingClient.kt$P2PMessagingClient : SingletonSerializeAsTokenMessagingServiceAddressToArtemisQueueResolver</ID>
    <ID>TooManyFunctions:PersistentIdentityMigrationNewTable.kt$PersistentIdentityMigrationNewTable : CordaMigration</ID>
    <ID>TooManyFunctions:PersistentIdentityService.kt$PersistentIdentityService : SingletonSerializeAsTokenIdentityService</ID>
    <ID>TooManyFunctions:PersistentNetworkMapCache.kt$PersistentNetworkMapCache : NetworkMapCacheInternalSingletonSerializeAsToken</ID>
    <ID>TooManyFunctions:PersistentUniquenessProvider.kt$PersistentUniquenessProvider : UniquenessProviderSingletonSerializeAsToken</ID>
    <ID>TooManyFunctions:RPCServer.kt$RPCServer</ID>
    <ID>TooManyFunctions:SingleThreadedStateMachineManager.kt$SingleThreadedStateMachineManager : StateMachineManagerStateMachineManagerInternal</ID>
    <ID>TooManyFunctions:StandardConfigValueParsers.kt$net.corda.node.services.config.schema.parsers.StandardConfigValueParsers.kt</ID>
    <ID>TooManyFunctions:StartedFlowTransition.kt$StartedFlowTransition : Transition</ID>
    <ID>TooManyFunctions:TopLevelTransition.kt$TopLevelTransition : Transition</ID>
    <ID>VariableNaming:NodeVaultService.kt$NodeVaultService.InnerState$val _rawUpdatesPublisher = PublishSubject.create&lt;Vault.Update&lt;ContractState&gt;&gt;()!!</ID>
    <ID>VariableNaming:NodeVaultService.kt$NodeVaultService.InnerState$val _updatesInDbTx = _updatesPublisher.wrapWithDatabaseTransaction().asObservable()!!</ID>
    <ID>VariableNaming:NodeVaultService.kt$NodeVaultService.InnerState$val _updatesPublisher = PublishSubject.create&lt;Vault.Update&lt;ContractState&gt;&gt;()!!</ID>
    <ID>WildcardImport:AMQPServerSerializationScheme.kt$import net.corda.serialization.internal.amqp.*</ID>
    <ID>WildcardImport:AbstractNode.kt$import net.corda.core.flows.*</ID>
    <ID>WildcardImport:AbstractNode.kt$import net.corda.core.internal.*</ID>
    <ID>WildcardImport:AbstractNode.kt$import net.corda.core.messaging.*</ID>
    <ID>WildcardImport:AbstractNode.kt$import net.corda.core.node.*</ID>
    <ID>WildcardImport:AbstractNode.kt$import net.corda.core.node.services.*</ID>
    <ID>WildcardImport:AbstractNode.kt$import net.corda.node.internal.cordapp.*</ID>
    <ID>WildcardImport:AbstractNode.kt$import net.corda.node.services.api.*</ID>
    <ID>WildcardImport:AbstractNode.kt$import net.corda.node.services.persistence.*</ID>
    <ID>WildcardImport:AbstractNode.kt$import net.corda.node.services.statemachine.*</ID>
    <ID>WildcardImport:AbstractNode.kt$import net.corda.node.utilities.*</ID>
    <ID>WildcardImport:AbstractNode.kt$import net.corda.nodeapi.internal.persistence.*</ID>
    <ID>WildcardImport:ActionExecutorImpl.kt$import com.codahale.metrics.*</ID>
    <ID>WildcardImport:ArtemisMessagingServer.kt$import net.corda.node.internal.artemis.*</ID>
    <ID>WildcardImport:ArtemisRpcBroker.kt$import net.corda.node.internal.artemis.*</ID>
    <ID>WildcardImport:BFTSmart.kt$import net.corda.core.crypto.*</ID>
    <ID>WildcardImport:BFTSmartNotaryService.kt$import net.corda.core.flows.*</ID>
    <ID>WildcardImport:BasicHSMKeyManagementService.kt$import javax.persistence.*</ID>
    <ID>WildcardImport:BasicHSMKeyManagementService.kt$import net.corda.core.crypto.*</ID>
    <ID>WildcardImport:CertificatesUtils.kt$import net.corda.nodeapi.internal.crypto.*</ID>
    <ID>WildcardImport:CheckpointDumper.kt$import com.fasterxml.jackson.databind.*</ID>
    <ID>WildcardImport:CheckpointDumper.kt$import net.corda.core.internal.*</ID>
    <ID>WildcardImport:CheckpointDumper.kt$import net.corda.node.services.statemachine.*</ID>
    <ID>WildcardImport:CordaClassResolver.kt$import com.esotericsoftware.kryo.*</ID>
    <ID>WildcardImport:CordaClassResolver.kt$import java.nio.file.StandardOpenOption.*</ID>
    <ID>WildcardImport:CordaMigration.kt$import net.corda.node.services.persistence.*</ID>
    <ID>WildcardImport:CordaRPCOpsImpl.kt$import net.corda.core.messaging.*</ID>
    <ID>WildcardImport:CordaRPCOpsImpl.kt$import net.corda.core.node.services.vault.*</ID>
    <ID>WildcardImport:CoreFlowHandlers.kt$import net.corda.core.flows.*</ID>
    <ID>WildcardImport:DBNetworkParametersStorage.kt$import javax.persistence.*</ID>
    <ID>WildcardImport:DBTransactionStorage.kt$import javax.persistence.*</ID>
    <ID>WildcardImport:DBTransactionStorage.kt$import net.corda.core.serialization.*</ID>
    <ID>WildcardImport:DBTransactionStorage.kt$import net.corda.nodeapi.internal.persistence.*</ID>
    <ID>WildcardImport:DefaultKryoCustomizer.kt$import de.javakaffee.kryoserializers.guava.*</ID>
    <ID>WildcardImport:DefaultKryoCustomizer.kt$import net.corda.core.transactions.*</ID>
    <ID>WildcardImport:DoRemainingWorkTransition.kt$import net.corda.node.services.statemachine.*</ID>
    <ID>WildcardImport:E2ETestKeyManagementService.kt$import net.corda.core.crypto.*</ID>
    <ID>WildcardImport:ErrorFlowTransition.kt$import net.corda.node.services.statemachine.*</ID>
    <ID>WildcardImport:ExceptionMaskingRpcOpsProxy.kt$import net.corda.core.*</ID>
    <ID>WildcardImport:ExceptionMaskingRpcOpsProxy.kt$import net.corda.core.messaging.*</ID>
    <ID>WildcardImport:ExceptionSerialisingRpcOpsProxy.kt$import net.corda.core.messaging.*</ID>
    <ID>WildcardImport:FiberDeserializationCheckingInterceptor.kt$import net.corda.node.services.statemachine.*</ID>
    <ID>WildcardImport:FlowLogicRefFactoryImpl.kt$import net.corda.core.flows.*</ID>
    <ID>WildcardImport:FlowStateMachineImpl.kt$import net.corda.core.flows.*</ID>
    <ID>WildcardImport:FlowStateMachineImpl.kt$import net.corda.core.internal.*</ID>
    <ID>WildcardImport:HTTPNetworkRegistrationService.kt$import java.net.HttpURLConnection.*</ID>
    <ID>WildcardImport:HibernateQueryCriteriaParser.kt$import javax.persistence.criteria.*</ID>
    <ID>WildcardImport:HibernateQueryCriteriaParser.kt$import net.corda.core.node.services.vault.*</ID>
    <ID>WildcardImport:HibernateQueryCriteriaParser.kt$import net.corda.core.node.services.vault.BinaryComparisonOperator.*</ID>
    <ID>WildcardImport:HibernateQueryCriteriaParser.kt$import net.corda.core.node.services.vault.CollectionOperator.*</ID>
    <ID>WildcardImport:HibernateQueryCriteriaParser.kt$import net.corda.core.node.services.vault.ColumnPredicate.*</ID>
    <ID>WildcardImport:HibernateQueryCriteriaParser.kt$import net.corda.core.node.services.vault.EqualityComparisonOperator.*</ID>
    <ID>WildcardImport:HibernateQueryCriteriaParser.kt$import net.corda.core.node.services.vault.LikenessOperator.*</ID>
    <ID>WildcardImport:InMemoryIdentityService.kt$import java.security.cert.*</ID>
    <ID>WildcardImport:InitialRegistrationCli.kt$import net.corda.node.internal.*</ID>
    <ID>WildcardImport:JarScanningCordappLoader.kt$import net.corda.core.flows.*</ID>
    <ID>WildcardImport:JarScanningCordappLoader.kt$import net.corda.core.internal.*</ID>
    <ID>WildcardImport:Kryo.kt$import com.esotericsoftware.kryo.*</ID>
    <ID>WildcardImport:Kryo.kt$import net.corda.core.transactions.*</ID>
    <ID>WildcardImport:KryoCheckpointSerializer.kt$import net.corda.core.serialization.*</ID>
    <ID>WildcardImport:KryoCheckpointSerializer.kt$import net.corda.serialization.internal.*</ID>
    <ID>WildcardImport:MigrationServicesForResolution.kt$import net.corda.core.contracts.*</ID>
    <ID>WildcardImport:MigrationServicesForResolution.kt$import net.corda.core.node.services.*</ID>
    <ID>WildcardImport:NetworkMapUpdater.kt$import net.corda.core.internal.*</ID>
    <ID>WildcardImport:NetworkMapUpdater.kt$import net.corda.nodeapi.internal.network.*</ID>
    <ID>WildcardImport:NetworkParametersReader.kt$import net.corda.core.internal.*</ID>
    <ID>WildcardImport:NetworkRegistrationHelper.kt$import net.corda.core.internal.*</ID>
    <ID>WildcardImport:Node.kt$import net.corda.node.services.config.*</ID>
    <ID>WildcardImport:Node.kt$import net.corda.node.utilities.*</ID>
    <ID>WildcardImport:Node.kt$import net.corda.serialization.internal.*</ID>
    <ID>WildcardImport:NodeAttachmentService.kt$import javax.persistence.*</ID>
    <ID>WildcardImport:NodeAttachmentService.kt$import net.corda.core.internal.*</ID>
    <ID>WildcardImport:NodeAttachmentService.kt$import net.corda.core.serialization.*</ID>
    <ID>WildcardImport:NodeInfoSchema.kt$import javax.persistence.*</ID>
    <ID>WildcardImport:NodeInfoWatcher.kt$import net.corda.core.internal.*</ID>
    <ID>WildcardImport:NodeSchedulerService.kt$import net.corda.core.internal.*</ID>
    <ID>WildcardImport:NodeSchemaService.kt$import net.corda.core.schemas.*</ID>
    <ID>WildcardImport:NodeStartup.kt$import net.corda.core.internal.*</ID>
    <ID>WildcardImport:NodeStartup.kt$import net.corda.node.*</ID>
    <ID>WildcardImport:NodeStartup.kt$import net.corda.node.internal.subcommands.*</ID>
    <ID>WildcardImport:NodeVaultService.kt$import net.corda.core.contracts.*</ID>
    <ID>WildcardImport:NodeVaultService.kt$import net.corda.core.internal.*</ID>
    <ID>WildcardImport:NodeVaultService.kt$import net.corda.core.node.services.*</ID>
    <ID>WildcardImport:NodeVaultService.kt$import net.corda.core.node.services.vault.*</ID>
    <ID>WildcardImport:NodeVaultService.kt$import net.corda.core.transactions.*</ID>
    <ID>WildcardImport:NodeVaultService.kt$import net.corda.core.utilities.*</ID>
    <ID>WildcardImport:NodeVaultService.kt$import net.corda.nodeapi.internal.persistence.*</ID>
    <ID>WildcardImport:P2PMessagingClient.kt$import net.corda.core.utilities.*</ID>
    <ID>WildcardImport:P2PMessagingClient.kt$import net.corda.nodeapi.internal.ArtemisMessagingComponent.*</ID>
    <ID>WildcardImport:P2PMessagingClient.kt$import org.apache.activemq.artemis.api.core.client.*</ID>
    <ID>WildcardImport:PersistentIdentityService.kt$import java.security.cert.*</ID>
    <ID>WildcardImport:PersistentIdentityService.kt$import net.corda.core.identity.*</ID>
    <ID>WildcardImport:PersistentIdentityService.kt$import net.corda.core.internal.*</ID>
    <ID>WildcardImport:PersistentUniquenessProvider.kt$import javax.persistence.*</ID>
    <ID>WildcardImport:PersistentUniquenessProvider.kt$import net.corda.core.internal.notary.*</ID>
    <ID>WildcardImport:PublicKeyHashToExternalId.kt$import javax.persistence.*</ID>
    <ID>WildcardImport:RPCSecurityManagerImpl.kt$import org.apache.shiro.authc.*</ID>
    <ID>WildcardImport:RPCServer.kt$import net.corda.core.utilities.*</ID>
    <ID>WildcardImport:RPCServer.kt$import org.apache.activemq.artemis.api.core.client.*</ID>
    <ID>WildcardImport:RaftUniquenessProvider.kt$import javax.persistence.*</ID>
    <ID>WildcardImport:RpcServerObservableSerializer.kt$import net.corda.serialization.internal.amqp.*</ID>
    <ID>WildcardImport:ServiceHubInternal.kt$import net.corda.core.internal.*</ID>
    <ID>WildcardImport:ServicesForResolutionImpl.kt$import net.corda.core.contracts.*</ID>
    <ID>WildcardImport:SingleThreadedStateMachineManager.kt$import net.corda.core.internal.*</ID>
    <ID>WildcardImport:SingleThreadedStateMachineManager.kt$import net.corda.node.services.statemachine.interceptors.*</ID>
    <ID>WildcardImport:StartedFlowTransition.kt$import net.corda.node.services.statemachine.*</ID>
    <ID>WildcardImport:SubFlow.kt$import net.corda.core.flows.*</ID>
    <ID>WildcardImport:TopLevelTransition.kt$import net.corda.node.services.statemachine.*</ID>
    <ID>WildcardImport:TransitionBuilder.kt$import net.corda.node.services.statemachine.*</ID>
    <ID>WildcardImport:V1NodeConfigurationSpec.kt$import net.corda.common.configuration.parsing.internal.*</ID>
    <ID>WildcardImport:V1NodeConfigurationSpec.kt$import net.corda.node.services.config.*</ID>
    <ID>WildcardImport:V1NodeConfigurationSpec.kt$import net.corda.node.services.config.schema.parsers.*</ID>
    <ID>WildcardImport:VaultSchema.kt$import javax.persistence.*</ID>
    <ID>WildcardImport:VaultSchema.kt$import net.corda.core.schemas.*</ID>
    <ID>WildcardImport:VaultStateMigration.kt$import net.corda.core.contracts.*</ID>
    <ID>WildcardImport:VaultStateMigration.kt$import net.corda.core.serialization.internal.*</ID>
  </Whitelist>
</SmellBaseline>
